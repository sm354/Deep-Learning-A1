{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "2.1.1working.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sm354/COL870-Assignment-1/blob/main/2_1_1working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EONe2cYGlj5",
        "outputId": "0769f0ed-6c20-4ccc-a074-90a43561e02a"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 22.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=9d006db90fec78a0db212abef3c07b18486184eb4de8dd9b25e7d2c524632e4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Toj8wCvvypN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import io\n",
        "import sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seqeval\n",
        "from seqeval.metrics import accuracy_score as seq_accuracy_score\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "from seqeval.metrics import f1_score as seq_f1_score\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  device = \"cuda:0\" \n",
        "else:  \n",
        "  device = \"cpu\"  \n",
        "\n",
        "# device = \"cpu\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9M1uW9_xHfE",
        "outputId": "bdc8cfde-b1de-4a43-d5f2-7fa9ebfb9f20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11BCpE2Sw7LL"
      },
      "source": [
        "pretrained = \"glove\" # glove or random\n",
        "# char_embeds = \"Yes\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCOcV-RtvypX"
      },
      "source": [
        "# reading text file in python and making list of sentences (list of lists) and list of tags(list of lists)\n",
        "def load_data(datapath, buildvocab_tags= True, vocab = None, nertags = None):\n",
        "    if(buildvocab_tags == True):\n",
        "        all_words = []\n",
        "        all_tags = []\n",
        "        with open(datapath) as f:\n",
        "            lines = f.readlines()\n",
        "            sent_num = 0\n",
        "            for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "                if(line == \"\\n\"):\n",
        "                    sent_num+=1\n",
        "                else:\n",
        "                    line_sep = line.split(sep = \" \")\n",
        "                    all_words.append(line_sep[0])\n",
        "                    all_tags.append(line_sep[3][:-1])\n",
        "                    \n",
        "        words = list(set(all_words))\n",
        "        tags = list(set(all_tags))\n",
        "\n",
        "        vocab = {}\n",
        "        vocab['<pad>'] = 0 # for padding input sequences\n",
        "        vocab['<oov>'] = 1\n",
        "        for i, word in enumerate(words):\n",
        "            vocab[word] = i+2\n",
        "            \n",
        "        nertags = {}\n",
        "        nertags['padtag'] = 0\n",
        "        for i,nertag in enumerate(tags):\n",
        "            nertags[nertag] = i+1\n",
        "        # nertags['padtag'] = len(nertags)\n",
        "\n",
        "\n",
        "    train_sent = []\n",
        "    train_tags = []\n",
        "    with open(datapath) as f:\n",
        "        lines = f.readlines()\n",
        "        sent_num = 0\n",
        "        sentence = []\n",
        "        tag = []\n",
        "        for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "            if(line == \"\\n\"):\n",
        "                sent_num+=1\n",
        "                train_sent.append(sentence)\n",
        "                train_tags.append(tag)\n",
        "                sentence = []\n",
        "                tag = []\n",
        "            else:\n",
        "                line_sep = line.split(sep = \" \")\n",
        "                if(line_sep[0] in vocab.keys()):\n",
        "                    sentence.append(vocab[line_sep[0]])\n",
        "                else:\n",
        "                    sentence.append(vocab['<oov>'])\n",
        "                    \n",
        "                tag.append(nertags[line_sep[3][:-1]])\n",
        "\n",
        "    # padding the sentences at the end\n",
        "    seq_maxlen = max(len(x) for x in train_sent)\n",
        "    x_lengths = [len(x) for x in train_sent]\n",
        "    Xtrain = []\n",
        "    Ytrain = []\n",
        "    for sent, tags in zip(train_sent, train_tags):\n",
        "        length_toappend = seq_maxlen - len(sent)\n",
        "        Xtrain.append(sent+[nertags['padtag']]*length_toappend)\n",
        "        Ytrain.append(tags+[nertags['padtag']]*length_toappend)\n",
        "\n",
        "\n",
        "    Xtrain = torch.Tensor(Xtrain)\n",
        "    Ytrain = torch.Tensor(Ytrain)\n",
        "    x_lengths = torch.Tensor(x_lengths)\n",
        "    # print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
        "    \n",
        "    return Xtrain, Ytrain, x_lengths, vocab, nertags"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZT58V3Avypa"
      },
      "source": [
        "### Training Data\n",
        "### using dataloader to make data batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPFYsfyNvypb"
      },
      "source": [
        "traindatapath = \"/content/drive/MyDrive/Q2_DL/train.txt\"\n",
        "devdatapath = \"/content/drive/MyDrive/Q2_DL/dev.txt\"\n",
        "\n",
        "Xtrain, Ytrain, x_trainlengths, vocab, nertags = load_data(traindatapath, buildvocab_tags=True)\n",
        "Xdev, Ydev, x_devlengths, _, _ = load_data(devdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
        "\n",
        "traindataset = TensorDataset(Xtrain, Ytrain, x_trainlengths)\n",
        "Trainloader = DataLoader(traindataset, batch_size= 128, shuffle=True)\n",
        "\n",
        "devdataset = TensorDataset(Xdev, Ydev, x_devlengths)\n",
        "Devloader = DataLoader(devdataset, batch_size = 128)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX7N2u5CMLY1"
      },
      "source": [
        "# print(next(iter(Trainloader))[1])"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCO_s9yJgXrG"
      },
      "source": [
        "embedding_size = 100\n",
        "if(pretrained == \"glove\"):\n",
        "    gloveembeddings_index = {}\n",
        "    with io.open(\"/content/drive/MyDrive/Q2_DL/glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:],dtype='float32')\n",
        "            gloveembeddings_index[word] = coefs\n",
        "\n",
        "    #using vocab and Xtrain, Xvalid, get pretrained glove word embeddings\n",
        "    glove_embeds = np.zeros((len(vocab), embedding_size))\n",
        "    for word in vocab.keys():\n",
        "        if(word in gloveembeddings_index.keys()):\n",
        "            # for the pad word let theembedding be all zeros\n",
        "            glove_embeds[vocab[word]] = gloveembeddings_index[word]\n",
        "        else:\n",
        "            glove_embeds[vocab[word]] = np.random.randn(embedding_size)\n",
        "    word_embeds = torch.Tensor(glove_embeds)\n",
        "    # print(glove_embeds.shape) # shape (vocablength , embedding dim)\n",
        "\n",
        "if(pretrained == \"random\"):\n",
        "    num_words = len(vocab)\n",
        "    word_embeds = torch.rand(num_words, embedding_size)\n",
        "\n",
        "# hence we get word_embeds which we could use afterwards"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz-CSE7gQtSr"
      },
      "source": [
        "#weight matrix for cross entropy loss\n",
        "weight = torch.zeros([len(nertags)])\n",
        "for i, tag in enumerate(nertags):\n",
        "    if(tag!='padtag' and tag!='O'):\n",
        "        weight[i] = 20\n",
        "    else:\n",
        "      weight[i] = 1\n",
        "    # weight[i] = 1/((Ytrain.view(-1) == i).sum())\n",
        "# print(weight)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmlPejqErFQ"
      },
      "source": [
        "imp_classes = [nertags[tag] for tag in nertags.keys()]\n",
        "imp_classes.remove(nertags['padtag'])\n",
        "imp_classes.remove(nertags['O'])"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMzf8Y1Bvypc"
      },
      "source": [
        "# BiLSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4KBzpL-vypc"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, total_words, num_class, pretrained = False, pretrained_embed = None):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.wordembed = nn.Embedding.from_pretrained(pretrained_embed, freeze = False)\n",
        "        # self.fcembed = nn.Linear(embedding_size, embedding_size)\n",
        "        # self.for_charembed = forwardLSTM()\n",
        "        # self.back_charembed = bachwardLSTM()\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "        self.bilstm = nn.LSTM(embedding_size,hidden_size, bidirectional = True, batch_first = True)\n",
        "        self.linear = nn.Linear(2*hidden_size, num_class) # 2 because forward and backward concatenate\n",
        "\n",
        "    def forward(self, x, xlengths): #add xchar\n",
        "        x = pack_padded_sequence(x, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        x, _ = pad_packed_sequence(x, batch_first=True)\n",
        "        word_embedding = self.wordembed(x) # x is of size(batchsize, seq_len), out is of size (batchsize, seq_len, embedding_size = 100)\n",
        "        # word_embedding = self.fcembed(word_embedding)\n",
        "        word_embedding = self.dropout(word_embedding) # dropout\n",
        "\n",
        "        out, (h,c) = self.bilstm(word_embedding) #'out' has dimension(batchsize, seq_len, 2*hidden_size)\n",
        "        out = self.linear(out) # now 'out' has dimension(batchsize, seq_len, num_class)\n",
        "        out = out.view(-1, out.shape[2]) # shape (128*seqlen, 18)\n",
        "        out = F.log_softmax(out, dim=1) # take the softmax across the dimension num_class, 'out' has dimension(batchsize, seq_len, num_class)\n",
        "        return out\n",
        "        \n",
        "        "
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6byqGo9vypd"
      },
      "source": [
        "model = BiLSTM(embedding_size = 100, hidden_size = 100, total_words = len(vocab), num_class = 18, pretrained = True, pretrained_embed = word_embeds).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3) \n",
        "# lossfunction = nn.CrossEntropyLoss(weight = weight)\n",
        "lossfunction = nn.CrossEntropyLoss()\n",
        "\n",
        "def performance(y, ypred, nertags):\n",
        "    y = y.numpy()\n",
        "    ypred = ypred.numpy()\n",
        "    mask = (y != nertags['padtag']) * (y != nertags['O'])\n",
        "    y = y*mask\n",
        "    ypred = ypred*mask\n",
        "    acc = ((y==ypred)*mask).sum()/mask.sum()\n",
        "    microf1 = f1_score(y, ypred, labels = imp_classes, average='micro')\n",
        "    macrof1 = f1_score(y, ypred, labels = imp_classes, average='macro')\n",
        "    return acc, microf1, macrof1\n",
        "\n",
        "def validate(model, loader):\n",
        "    with torch.no_grad():\n",
        "        validloss = 0\n",
        "        acc = 0\n",
        "        microf1 = 0\n",
        "        macrof1 = 0\n",
        "        i = 0\n",
        "        for step, (X, Y, xlen) in enumerate(loader):\n",
        "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
        "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
        "            ypred = model(X.long().to(device), xlen.to(device))#.permute(0, 2, 1)\n",
        "            vloss = lossfunction(ypred.to('cpu'), Y.view(-1).type(torch.LongTensor))\n",
        "            validloss+=vloss.item()\n",
        "            acc_, microf1_, macrof1_ = performance(Y.view(-1), torch.argmax(ypred.to('cpu'), dim = 1), nertags)\n",
        "            acc+=acc_\n",
        "            microf1 += microf1_\n",
        "            macrof1 += macrof1_\n",
        "            i+=1\n",
        "\n",
        "    return validloss/i, acc/i, microf1/i, macrof1/i\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e72jKrx3Pjg6"
      },
      "source": [
        "# print(nertags)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seMNHki0D0V2"
      },
      "source": [
        "trainlosslist = []\n",
        "trainacclist = [] #accuracy except pad, O\n",
        "trainmicrof1list = []\n",
        "trainmacrof1list = []\n",
        "\n",
        "\n",
        "validlosslist = []\n",
        "valacclist = []\n",
        "valmicrof1list = []\n",
        "valmacrof1list = []"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_us_70hYvzq"
      },
      "source": [
        "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001) "
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QgudoA7Mvypd",
        "outputId": "c4819e6a-82a6-442f-90d1-fe41f7ebae41"
      },
      "source": [
        "# Model is ready now we have to train using cross entropy loss\n",
        "num_epochs = 35\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    if(epoch == 10):\n",
        "      model.wordembed.weight.requires_grad = True\n",
        "\n",
        "    totalloss, acc, microf1, macrof1 = 0, 0, 0, 0\n",
        "    for step, (Xbatch ,Ybatch, xbatch_len) in enumerate(Trainloader):\n",
        "        #make gradients 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        Ybatch = pack_padded_sequence(Ybatch, xbatch_len, batch_first=True, enforce_sorted=False)\n",
        "        Ybatch, y_lengths = pad_packed_sequence(Ybatch, batch_first=True)\n",
        "\n",
        "        #get output from model and claculate loss\n",
        "        ypred = model(Xbatch.long().to(device), xbatch_len.to(device))#.permute(0, 2, 1)\n",
        "        # print(ypred.shape, Ybatch.shape)\n",
        "\n",
        "        acc_, microf1_, macrof1_ = performance(Ybatch.view(-1), torch.argmax(ypred.to('cpu'), dim = 1), nertags)\n",
        "        acc+= acc_\n",
        "        microf1+=microf1_\n",
        "        macrof1+=macrof1_\n",
        "        if(step%20 == 0 and step !=0):\n",
        "            print(\"training accuracy = {}, microF1 = {}, macroF1 = {}\".format(acc/(step+1), microf1/(step+1), macrof1/(step+1)))\n",
        "        \n",
        "        loss = lossfunction(ypred.to('cpu'), Ybatch.view(-1).type(torch.LongTensor)) #Ybatch has dimension (batchsize, seqlen), ypred has dimension(batchsize, num_classes, seqlen)\n",
        "        totalloss += loss.item()\n",
        "\n",
        "        #backward and step\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
        "        optimizer.step()\n",
        "    \n",
        "    trainlosslist.append(totalloss/(step+1))\n",
        "    trainacclist.append(acc/(step+1))\n",
        "    trainmicrof1list.append(microf1/(step+1))\n",
        "    trainmacrof1list.append(macrof1/(step+1))\n",
        "\n",
        "    # model validation loss and scheduler step for learning rate change if required\n",
        "    val_loss, val_acc, val_microf1, val_macrof1  = validate(model, Devloader)\n",
        "    validlosslist.append(val_loss)\n",
        "    valacclist.append(val_acc)\n",
        "    valmicrof1list.append(val_microf1)\n",
        "    valmacrof1list.append(val_macrof1)\n",
        "\n",
        "    # scheduler.step(val_loss)\n",
        "    print('\\nepoch = {}, training_loss = {}, validation_loss ={}, training_acc = {}, validation_acc ={}'.format(epoch, trainlosslist[-1], validlosslist[-1], trainacclist[-1], valacclist[-1]))            \n",
        "        \n",
        "        "
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy = 0.023228072017384988, microF1 = 0.028788153027838728, macroF1 = 0.010649547060272015\n",
            "training accuracy = 0.011897305179636214, microF1 = 0.014745151550844226, macroF1 = 0.005454646055261276\n",
            "training accuracy = 0.007996549383034176, microF1 = 0.009910675632534643, macroF1 = 0.003666237512552661\n",
            "training accuracy = 0.00602209274524796, microF1 = 0.00746359522943967, macroF1 = 0.0027609936822927447\n",
            "training accuracy = 0.004829599132327572, microF1 = 0.005985655580045676, macroF1 = 0.0022142622600565577\n",
            "training accuracy = 0.004105203097532274, microF1 = 0.005143233192438112, macroF1 = 0.0019177956218452046\n",
            "training accuracy = 0.006105216591432505, microF1 = 0.009222601160813259, macroF1 = 0.0029373960040073627\n",
            "training accuracy = 0.017444516662227415, microF1 = 0.0282167377513879, macroF1 = 0.008180177439885259\n",
            "training accuracy = 0.03641440264831694, microF1 = 0.055849765210576614, macroF1 = 0.01713396978453149\n",
            "training accuracy = 0.061576394994065524, microF1 = 0.08864806999193722, macroF1 = 0.028346847464341657\n",
            "training accuracy = 0.08751787150897763, microF1 = 0.12059846737986535, macroF1 = 0.03971379181006382\n",
            "training accuracy = 0.11267302827462657, microF1 = 0.1503159937939608, macroF1 = 0.05063821832636294\n",
            "training accuracy = 0.1356827899913255, microF1 = 0.17688556101011257, macroF1 = 0.061215005842413836\n",
            "training accuracy = 0.15751933864785247, microF1 = 0.20163867307560784, macroF1 = 0.07192692853994564\n",
            "\n",
            "epoch = 0, training_loss = 0.31905152899600386, validation_loss =0.15109412671671701, training_acc = 0.16805746225652468, validation_acc =0.45543573379465474\n",
            "training accuracy = 0.4817137866757506, microF1 = 0.5623173501379372, macroF1 = 0.24319257482647574\n",
            "training accuracy = 0.4949306784005854, microF1 = 0.5727655167778584, macroF1 = 0.2558922026518114\n",
            "training accuracy = 0.504292674519419, microF1 = 0.5813173194085632, macroF1 = 0.2679212880457608\n",
            "training accuracy = 0.5145794878229191, microF1 = 0.5909731840785231, macroF1 = 0.27884200232745776\n",
            "training accuracy = 0.525652445324415, microF1 = 0.6010382180322741, macroF1 = 0.2883852078522363\n",
            "training accuracy = 0.5348175483877464, microF1 = 0.6093315984810883, macroF1 = 0.29645947238687353\n",
            "training accuracy = 0.5442542939907248, microF1 = 0.6180901845006284, macroF1 = 0.3043520353452349\n",
            "training accuracy = 0.5517898699260914, microF1 = 0.624954464963521, macroF1 = 0.3096822829688155\n",
            "training accuracy = 0.5597847026411528, microF1 = 0.63240962087479, macroF1 = 0.31647729407921377\n",
            "training accuracy = 0.5677137067886866, microF1 = 0.6394167307489964, macroF1 = 0.32220702646830773\n",
            "training accuracy = 0.5739883221393816, microF1 = 0.6452349905499554, macroF1 = 0.327090237741899\n",
            "training accuracy = 0.5803110776009625, microF1 = 0.6509156191927181, macroF1 = 0.33173798142266914\n",
            "training accuracy = 0.5858538363947148, microF1 = 0.6561078954314508, macroF1 = 0.3358006323938114\n",
            "training accuracy = 0.5900878319850806, microF1 = 0.6600045381557847, macroF1 = 0.33917107803442426\n",
            "\n",
            "epoch = 1, training_loss = 0.11486509941595117, validation_loss =0.10759386297353764, training_acc = 0.591865723120186, validation_acc =0.6452889215087836\n",
            "training accuracy = 0.6644932770983474, microF1 = 0.727626191941177, macroF1 = 0.3922092199719842\n",
            "training accuracy = 0.6692324341835553, microF1 = 0.7320866988126957, macroF1 = 0.39533688338054945\n",
            "training accuracy = 0.6700955633939001, microF1 = 0.7319029241001789, macroF1 = 0.395121437763172\n",
            "training accuracy = 0.6732606747002569, microF1 = 0.7348553368654523, macroF1 = 0.3967127800932912\n",
            "training accuracy = 0.6731783738045403, microF1 = 0.7348945204308737, macroF1 = 0.39773789266378556\n",
            "training accuracy = 0.6763043504790092, microF1 = 0.7371797780967666, macroF1 = 0.3994358691783071\n",
            "training accuracy = 0.6793890183979842, microF1 = 0.740093731891206, macroF1 = 0.4004394990498911\n",
            "training accuracy = 0.681711742626095, microF1 = 0.7423064289805211, macroF1 = 0.40151600610644356\n",
            "training accuracy = 0.6832198242941673, microF1 = 0.7435781045411394, macroF1 = 0.40270574352071226\n",
            "training accuracy = 0.6863583212033012, microF1 = 0.7462040868874961, macroF1 = 0.4043828748345345\n",
            "training accuracy = 0.6878271071866653, microF1 = 0.7474637583883847, macroF1 = 0.4051273819957442\n",
            "training accuracy = 0.6897671681389995, microF1 = 0.7491400842805437, macroF1 = 0.40623457438490557\n",
            "training accuracy = 0.6911334022493139, microF1 = 0.7502878933971887, macroF1 = 0.40712178012282707\n",
            "training accuracy = 0.6926880988904281, microF1 = 0.7515806168159399, macroF1 = 0.407806595074352\n",
            "\n",
            "epoch = 2, training_loss = 0.09033993576554089, validation_loss =0.09476265322762667, training_acc = 0.6937290032403598, validation_acc =0.6792686403814283\n",
            "training accuracy = 0.7179718148928526, microF1 = 0.7712271757305857, macroF1 = 0.4250405783379917\n",
            "training accuracy = 0.7194229351717532, microF1 = 0.773288695559184, macroF1 = 0.4235611993945344\n",
            "training accuracy = 0.7235815250702908, microF1 = 0.7772736587521729, macroF1 = 0.42590386599630653\n",
            "training accuracy = 0.7237683224896772, microF1 = 0.7770470359769401, macroF1 = 0.42558000261862877\n",
            "training accuracy = 0.7249644262678773, microF1 = 0.778132042361579, macroF1 = 0.4259228155828614\n",
            "training accuracy = 0.7245180653347788, microF1 = 0.7777840000113982, macroF1 = 0.4260121501612844\n",
            "training accuracy = 0.7240638220079517, microF1 = 0.7772135507931794, macroF1 = 0.4253277299630467\n",
            "training accuracy = 0.7235917866247684, microF1 = 0.7769550879315548, macroF1 = 0.4250993371790635\n",
            "training accuracy = 0.724877954474471, microF1 = 0.7778631805195134, macroF1 = 0.425497374264964\n",
            "training accuracy = 0.7257361857213819, microF1 = 0.7785561803260266, macroF1 = 0.42591294238990546\n",
            "training accuracy = 0.7257544285977229, microF1 = 0.7784868961237612, macroF1 = 0.42596936407759406\n",
            "training accuracy = 0.7263302148957828, microF1 = 0.7790459396567617, macroF1 = 0.42651120531477105\n",
            "training accuracy = 0.7276208697918258, microF1 = 0.7801390294295313, macroF1 = 0.4271471152338745\n",
            "training accuracy = 0.7282296511708863, microF1 = 0.780790714501154, macroF1 = 0.4275438869964202\n",
            "\n",
            "epoch = 3, training_loss = 0.0792268329008748, validation_loss =0.08763185780994671, training_acc = 0.7285516033399136, validation_acc =0.7089166405882672\n",
            "training accuracy = 0.7508683210408174, microF1 = 0.8000091487658352, macroF1 = 0.43819566164982693\n",
            "training accuracy = 0.7496964751313006, microF1 = 0.7981047802654531, macroF1 = 0.4375524299696494\n",
            "training accuracy = 0.7453365602224973, microF1 = 0.7944506104173326, macroF1 = 0.4362172512010308\n",
            "training accuracy = 0.7455213702218996, microF1 = 0.7953363882638497, macroF1 = 0.4362176220602625\n",
            "training accuracy = 0.7456001102118833, microF1 = 0.7948377489624372, macroF1 = 0.4364109874973247\n",
            "training accuracy = 0.7432657054382084, microF1 = 0.7928322605412075, macroF1 = 0.43543053580439234\n",
            "training accuracy = 0.7432778897385298, microF1 = 0.7928707608994904, macroF1 = 0.43579367353891657\n",
            "training accuracy = 0.7447071295903233, microF1 = 0.7940198971835196, macroF1 = 0.4368977000740821\n",
            "training accuracy = 0.7449795860223493, microF1 = 0.7943595944362717, macroF1 = 0.4371309203991655\n",
            "training accuracy = 0.7448443134314888, microF1 = 0.7941573025548045, macroF1 = 0.43727144870083295\n",
            "training accuracy = 0.7466505475987554, microF1 = 0.7957860781624227, macroF1 = 0.4378099717646568\n",
            "training accuracy = 0.7483938365012622, microF1 = 0.7971625112302915, macroF1 = 0.43881208313059067\n",
            "training accuracy = 0.7481135196130442, microF1 = 0.797077895365945, macroF1 = 0.43868097825169244\n",
            "training accuracy = 0.7484500949521049, microF1 = 0.7973958487059503, macroF1 = 0.43899002786899305\n",
            "\n",
            "epoch = 4, training_loss = 0.0719327259027876, validation_loss =0.08233970568813, training_acc = 0.7487729238313449, validation_acc =0.7331635526536359\n",
            "training accuracy = 0.7636911477323937, microF1 = 0.8098335710655081, macroF1 = 0.4491927877572837\n",
            "training accuracy = 0.763960563929781, microF1 = 0.8098776304315303, macroF1 = 0.44841170033809014\n",
            "training accuracy = 0.7614020347555436, microF1 = 0.8075499416765604, macroF1 = 0.446416921119382\n",
            "training accuracy = 0.7601712857638999, microF1 = 0.8065171317174947, macroF1 = 0.4452098736523013\n",
            "training accuracy = 0.7606069027879987, microF1 = 0.8072646647487649, macroF1 = 0.4458804569652692\n",
            "training accuracy = 0.7633466251929482, microF1 = 0.8094624813112627, macroF1 = 0.44707808671893307\n",
            "training accuracy = 0.7625755443965022, microF1 = 0.8088656176685687, macroF1 = 0.4466110462320235\n",
            "training accuracy = 0.7628520837771555, microF1 = 0.8088596114378427, macroF1 = 0.4467390951994207\n",
            "training accuracy = 0.7612720629945129, microF1 = 0.8072378187705549, macroF1 = 0.44573423737129414\n",
            "training accuracy = 0.7611268033647043, microF1 = 0.8071387228133645, macroF1 = 0.44570273412399425\n",
            "training accuracy = 0.7609932090796356, microF1 = 0.806962069840047, macroF1 = 0.44549523891007103\n",
            "training accuracy = 0.7619637278677559, microF1 = 0.8078394145838725, macroF1 = 0.4459734824118865\n",
            "training accuracy = 0.762891881849889, microF1 = 0.8085300430929375, macroF1 = 0.44630670388274873\n",
            "training accuracy = 0.7622285426127836, microF1 = 0.8080227862152011, macroF1 = 0.44605249593285834\n",
            "\n",
            "epoch = 5, training_loss = 0.06754751630844325, validation_loss =0.0799625207161166, training_acc = 0.7622680766625863, validation_acc =0.73228160601558\n",
            "training accuracy = 0.7611782865459414, microF1 = 0.8070076284674425, macroF1 = 0.4480884669191656\n",
            "training accuracy = 0.7707005325247518, microF1 = 0.814587017910251, macroF1 = 0.45201145826903016\n",
            "training accuracy = 0.7682177822891231, microF1 = 0.8126931092441009, macroF1 = 0.4508878606234086\n",
            "training accuracy = 0.7700757867951565, microF1 = 0.8141166787649501, macroF1 = 0.45152520934921964\n",
            "training accuracy = 0.769567506513876, microF1 = 0.8140034480354726, macroF1 = 0.45202474831240563\n",
            "training accuracy = 0.7712008764674889, microF1 = 0.8155256475845957, macroF1 = 0.4522276196464218\n",
            "training accuracy = 0.7723407252557942, microF1 = 0.816395911579569, macroF1 = 0.4528077316935066\n",
            "training accuracy = 0.7743276076807776, microF1 = 0.8180862323423312, macroF1 = 0.454181188101486\n",
            "training accuracy = 0.7739067629954501, microF1 = 0.8175304710414988, macroF1 = 0.45409598062945955\n",
            "training accuracy = 0.7741991879589057, microF1 = 0.8177677030152413, macroF1 = 0.4540423902762324\n",
            "training accuracy = 0.7743943456384087, microF1 = 0.8181398910026078, macroF1 = 0.45413373555775505\n",
            "training accuracy = 0.7744707565710859, microF1 = 0.8182727503641494, macroF1 = 0.4547029162833594\n",
            "training accuracy = 0.774469957418664, microF1 = 0.8182505567936098, macroF1 = 0.4548178832885428\n",
            "training accuracy = 0.7744612137880548, microF1 = 0.8181362568362482, macroF1 = 0.45488090062802733\n",
            "\n",
            "epoch = 6, training_loss = 0.0638592298369842, validation_loss =0.0773064559805639, training_acc = 0.7746566235456314, validation_acc =0.744226818039429\n",
            "training accuracy = 0.7828381038346337, microF1 = 0.826138085752568, macroF1 = 0.45907929780314155\n",
            "training accuracy = 0.7834557291373425, microF1 = 0.8253678442620797, macroF1 = 0.4585130930516227\n",
            "training accuracy = 0.7855865748683081, microF1 = 0.8268284678036352, macroF1 = 0.4589585430769804\n",
            "training accuracy = 0.7862728716443861, microF1 = 0.8276610229065149, macroF1 = 0.4599354636527868\n",
            "training accuracy = 0.786893690734227, microF1 = 0.8280214471129366, macroF1 = 0.46134050154998135\n",
            "training accuracy = 0.7870629074059728, microF1 = 0.8284687309068806, macroF1 = 0.4618063181893057\n",
            "training accuracy = 0.7882421695117611, microF1 = 0.8291969454852104, macroF1 = 0.46286832548472095\n",
            "training accuracy = 0.787363775883445, microF1 = 0.8284982974879563, macroF1 = 0.4623055966460139\n",
            "training accuracy = 0.7861756789520811, microF1 = 0.8275391671109715, macroF1 = 0.4613268900840964\n",
            "training accuracy = 0.7867636837824512, microF1 = 0.8280301814282996, macroF1 = 0.4615956789618643\n",
            "training accuracy = 0.7863987542968388, microF1 = 0.827747366122379, macroF1 = 0.46208034406533693\n",
            "training accuracy = 0.7855744089864233, microF1 = 0.8270275319582366, macroF1 = 0.46214959299870484\n",
            "training accuracy = 0.7862127990882355, microF1 = 0.8277564060153867, macroF1 = 0.4630088859318121\n",
            "training accuracy = 0.7864154728322461, microF1 = 0.8279038679712756, macroF1 = 0.46320919272510674\n",
            "\n",
            "epoch = 7, training_loss = 0.06018777520002164, validation_loss =0.0747578627593124, training_acc = 0.7867688609964599, validation_acc =0.7536163732284678\n",
            "training accuracy = 0.7898756936029426, microF1 = 0.8305569202000272, macroF1 = 0.4699681088293858\n",
            "training accuracy = 0.7902302092709108, microF1 = 0.8306731999206726, macroF1 = 0.46838202581192473\n",
            "training accuracy = 0.7898721620205741, microF1 = 0.8306100927944657, macroF1 = 0.4679630863161012\n",
            "training accuracy = 0.788746648519068, microF1 = 0.829199115991216, macroF1 = 0.4657217421329225\n",
            "training accuracy = 0.7886738098112079, microF1 = 0.8293595630531957, macroF1 = 0.4661348655890638\n",
            "training accuracy = 0.7890381379167167, microF1 = 0.8295813364683282, macroF1 = 0.46561525986647817\n",
            "training accuracy = 0.7889970985131487, microF1 = 0.8295162783815475, macroF1 = 0.46580906670899985\n",
            "training accuracy = 0.79017426415234, microF1 = 0.8304690529890381, macroF1 = 0.46749500009227074\n",
            "training accuracy = 0.7901473537900378, microF1 = 0.8302915290553751, macroF1 = 0.467754760716077\n",
            "training accuracy = 0.7902086277274522, microF1 = 0.8302751394769653, macroF1 = 0.4678165862398901\n",
            "training accuracy = 0.7904842137683418, microF1 = 0.8306061766417991, macroF1 = 0.46834709983323075\n",
            "training accuracy = 0.791310765584919, microF1 = 0.8314895254203893, macroF1 = 0.46869823569595737\n",
            "training accuracy = 0.7916809110407164, microF1 = 0.8316623085384431, macroF1 = 0.4689583382981475\n",
            "training accuracy = 0.7914483986144916, microF1 = 0.8315074490044256, macroF1 = 0.46878412239728307\n",
            "\n",
            "epoch = 8, training_loss = 0.05758926242948398, validation_loss =0.07305036838521663, training_acc = 0.7913833572150737, validation_acc =0.7514138464310133\n",
            "training accuracy = 0.7948504493037751, microF1 = 0.8356192777858004, macroF1 = 0.46458767771099235\n",
            "training accuracy = 0.7965108278556681, microF1 = 0.8354768472220826, macroF1 = 0.47467138605374415\n",
            "training accuracy = 0.7960713543174894, microF1 = 0.8352592448661906, macroF1 = 0.47710210413321047\n",
            "training accuracy = 0.7966155766979162, microF1 = 0.8355448735851916, macroF1 = 0.47631252812503927\n",
            "training accuracy = 0.797094692647971, microF1 = 0.83581531409743, macroF1 = 0.4744447462755378\n",
            "training accuracy = 0.7977295225291817, microF1 = 0.8364345647971622, macroF1 = 0.47547381080010326\n",
            "training accuracy = 0.7999045846788505, microF1 = 0.8381842601404409, macroF1 = 0.47567329154048843\n",
            "training accuracy = 0.7994081646438168, microF1 = 0.8377104729981729, macroF1 = 0.475349437282195\n",
            "training accuracy = 0.7997737433572406, microF1 = 0.838176787828542, macroF1 = 0.4763588540744843\n",
            "training accuracy = 0.7993061141388942, microF1 = 0.837954431695906, macroF1 = 0.4755121111024601\n",
            "training accuracy = 0.7996627776408202, microF1 = 0.8383672024841577, macroF1 = 0.47609847191576804\n",
            "training accuracy = 0.8001028968199176, microF1 = 0.8387742329323185, macroF1 = 0.47688557083695654\n",
            "training accuracy = 0.7995837762861522, microF1 = 0.8384961800972872, macroF1 = 0.4766885358443717\n",
            "training accuracy = 0.8000877081956251, microF1 = 0.838784589897488, macroF1 = 0.47669312074936593\n",
            "\n",
            "epoch = 9, training_loss = 0.05519109250676796, validation_loss =0.071941721032268, training_acc = 0.8003548287037082, validation_acc =0.7507975668824844\n",
            "training accuracy = 0.8088102623957999, microF1 = 0.8472476513625908, macroF1 = 0.48426541782442295\n",
            "training accuracy = 0.8084955591630338, microF1 = 0.8461513736149804, macroF1 = 0.48656356594830835\n",
            "training accuracy = 0.8090660583823637, microF1 = 0.8468469849244883, macroF1 = 0.487392912889058\n",
            "training accuracy = 0.8088362158854355, microF1 = 0.8466911783926765, macroF1 = 0.48786337377948497\n",
            "training accuracy = 0.8082878048485428, microF1 = 0.846072727439629, macroF1 = 0.48855061879261646\n",
            "training accuracy = 0.8080533212667051, microF1 = 0.8459026032384006, macroF1 = 0.4881691536946279\n",
            "training accuracy = 0.8068172027455198, microF1 = 0.8446730380330035, macroF1 = 0.4861550216389893\n",
            "training accuracy = 0.80747077491643, microF1 = 0.8453797640073853, macroF1 = 0.4876634482157985\n",
            "training accuracy = 0.8077803078995052, microF1 = 0.8454218318080847, macroF1 = 0.4874010014249247\n",
            "training accuracy = 0.8074925793927584, microF1 = 0.8451587631595127, macroF1 = 0.48741193802882954\n",
            "training accuracy = 0.8066267703824151, microF1 = 0.8443059880854491, macroF1 = 0.4858677246206735\n",
            "training accuracy = 0.8062586441665651, microF1 = 0.8438688628283414, macroF1 = 0.48589441004302447\n",
            "training accuracy = 0.8064269949920929, microF1 = 0.8438801002485727, macroF1 = 0.48655839586080213\n",
            "training accuracy = 0.8065917832615667, microF1 = 0.843960169346023, macroF1 = 0.48624635373822556\n",
            "\n",
            "epoch = 10, training_loss = 0.0534232053841717, validation_loss =0.0714356749097711, training_acc = 0.8065658485460594, validation_acc =0.7577889253386735\n",
            "training accuracy = 0.812342397452595, microF1 = 0.8504594224378033, macroF1 = 0.49835449994625886\n",
            "training accuracy = 0.8119634194439214, microF1 = 0.8484382219860228, macroF1 = 0.49264410265881914\n",
            "training accuracy = 0.8136210239646773, microF1 = 0.8496877916619386, macroF1 = 0.493588659950802\n",
            "training accuracy = 0.8148045123993917, microF1 = 0.8506871203385429, macroF1 = 0.4922422276439126\n",
            "training accuracy = 0.8148846889236022, microF1 = 0.8506170587295886, macroF1 = 0.49299748573554675\n",
            "training accuracy = 0.8165302615537986, microF1 = 0.8523513419199846, macroF1 = 0.4937654336928836\n",
            "training accuracy = 0.8162707032677449, microF1 = 0.852270707192317, macroF1 = 0.4922483895383953\n",
            "training accuracy = 0.8155080847641387, microF1 = 0.8514015815232783, macroF1 = 0.492426839535678\n",
            "training accuracy = 0.8143702450606968, microF1 = 0.8502481697240095, macroF1 = 0.49330301403555743\n",
            "training accuracy = 0.8132184472444296, microF1 = 0.8492680292299952, macroF1 = 0.49230208916090906\n",
            "training accuracy = 0.8133888695422227, microF1 = 0.8493960741226886, macroF1 = 0.4919341432490458\n",
            "training accuracy = 0.8129106341660921, microF1 = 0.8490375315434076, macroF1 = 0.4914682730558886\n",
            "training accuracy = 0.8132057054639035, microF1 = 0.8493529800030784, macroF1 = 0.49167304148643354\n",
            "training accuracy = 0.8133692560677892, microF1 = 0.8494841385263956, macroF1 = 0.4927515224900611\n",
            "\n",
            "epoch = 11, training_loss = 0.05129569295243299, validation_loss =0.06940011203903512, training_acc = 0.8135522396903678, validation_acc =0.7630074651604352\n",
            "training accuracy = 0.810136548971023, microF1 = 0.8456230462968981, macroF1 = 0.5124087967203202\n",
            "training accuracy = 0.8172099228799348, microF1 = 0.8523717541008098, macroF1 = 0.5023527571814813\n",
            "training accuracy = 0.820218515095903, microF1 = 0.8550584596244007, macroF1 = 0.5062448656636156\n",
            "training accuracy = 0.8193844017671881, microF1 = 0.8542237492651972, macroF1 = 0.5055876065079202\n",
            "training accuracy = 0.815978859856387, microF1 = 0.8514372020861686, macroF1 = 0.5033206375512986\n",
            "training accuracy = 0.8172007630473943, microF1 = 0.8526052817109552, macroF1 = 0.5015460238298242\n",
            "training accuracy = 0.8176395173232616, microF1 = 0.852979212062695, macroF1 = 0.5017159346179659\n",
            "training accuracy = 0.816723480218696, microF1 = 0.852277230480174, macroF1 = 0.5003864523155209\n",
            "training accuracy = 0.8174545516695602, microF1 = 0.8527387726240184, macroF1 = 0.5009866519413251\n",
            "training accuracy = 0.8180031177714097, microF1 = 0.8531948700863062, macroF1 = 0.5002841584783505\n",
            "training accuracy = 0.8180981717479637, microF1 = 0.8532673252129747, macroF1 = 0.500322891674789\n",
            "training accuracy = 0.8183207297448777, microF1 = 0.8533551857364989, macroF1 = 0.4987698122939835\n",
            "training accuracy = 0.8186033173366815, microF1 = 0.8536046000319407, macroF1 = 0.49946248210102284\n",
            "training accuracy = 0.8184230348269621, microF1 = 0.8534832163409869, macroF1 = 0.49953149603143693\n",
            "\n",
            "epoch = 12, training_loss = 0.04991932953883897, validation_loss =0.06998801281310849, training_acc = 0.8190467739702305, validation_acc =0.764865452181364\n",
            "training accuracy = 0.8185491323282997, microF1 = 0.8529444261526974, macroF1 = 0.5084344673824462\n",
            "training accuracy = 0.8212947187436597, microF1 = 0.8551816515518187, macroF1 = 0.5018363613006448\n",
            "training accuracy = 0.8224467313677686, microF1 = 0.8560469180534318, macroF1 = 0.5004021297620738\n",
            "training accuracy = 0.8234656259681592, microF1 = 0.8573574818479655, macroF1 = 0.5006968868430712\n",
            "training accuracy = 0.8234383207160637, microF1 = 0.8575728642137891, macroF1 = 0.5005056707080026\n",
            "training accuracy = 0.8232136687519346, microF1 = 0.8573847570171746, macroF1 = 0.5006302420154068\n",
            "training accuracy = 0.8237179025914338, microF1 = 0.857777317512725, macroF1 = 0.5003021090021462\n",
            "training accuracy = 0.8237580252358202, microF1 = 0.8577087266273451, macroF1 = 0.5020399775262729\n",
            "training accuracy = 0.8229710533380296, microF1 = 0.857282626557638, macroF1 = 0.5021183745098888\n",
            "training accuracy = 0.8232499678150248, microF1 = 0.857480401210702, macroF1 = 0.50382226051008\n",
            "training accuracy = 0.8238566279188969, microF1 = 0.857880457687943, macroF1 = 0.5054755940266907\n",
            "training accuracy = 0.8243336345869566, microF1 = 0.858144778773845, macroF1 = 0.5060586031004805\n",
            "training accuracy = 0.8241060384077877, microF1 = 0.8580457178998144, macroF1 = 0.5062900220467171\n",
            "training accuracy = 0.823493678062748, microF1 = 0.857412513622242, macroF1 = 0.5056363005100099\n",
            "\n",
            "epoch = 13, training_loss = 0.04809185635311292, validation_loss =0.0690776656967463, training_acc = 0.823647933300399, validation_acc =0.7607903658782049\n",
            "training accuracy = 0.8212341465690118, microF1 = 0.8550205789082054, macroF1 = 0.50630119953761\n",
            "training accuracy = 0.8291089603060912, microF1 = 0.8613999832853367, macroF1 = 0.5133022524498648\n",
            "training accuracy = 0.8291299032710245, microF1 = 0.8617115324728498, macroF1 = 0.5162332348388291\n",
            "training accuracy = 0.8290818916540063, microF1 = 0.8617363891946513, macroF1 = 0.5136738892035417\n",
            "training accuracy = 0.8305582081958827, microF1 = 0.862875647805596, macroF1 = 0.5126928401252301\n",
            "training accuracy = 0.8292811394146148, microF1 = 0.8620071083492196, macroF1 = 0.5128332154233826\n",
            "training accuracy = 0.8279107460343864, microF1 = 0.8611700834512059, macroF1 = 0.5137315938705981\n",
            "training accuracy = 0.8274038639121487, microF1 = 0.8607564604614116, macroF1 = 0.5117247176991089\n",
            "training accuracy = 0.8272480679239049, microF1 = 0.8605563738573903, macroF1 = 0.5111231785786341\n",
            "training accuracy = 0.827671106985379, microF1 = 0.8609095889743112, macroF1 = 0.5111732853691299\n",
            "training accuracy = 0.828326830497408, microF1 = 0.8615059682207978, macroF1 = 0.5105272300153726\n",
            "training accuracy = 0.8282446601374678, microF1 = 0.8615262651509803, macroF1 = 0.5101690663111963\n",
            "training accuracy = 0.8283358234954556, microF1 = 0.8615794609529632, macroF1 = 0.5107645203900214\n",
            "training accuracy = 0.8286518013220511, microF1 = 0.8618706833825096, macroF1 = 0.5117686864270337\n",
            "\n",
            "epoch = 14, training_loss = 0.04640456178318389, validation_loss =0.06837430865187005, training_acc = 0.8281922267960139, validation_acc =0.7749262562789868\n",
            "training accuracy = 0.834724595623014, microF1 = 0.8676757605532041, macroF1 = 0.5192325573847576\n",
            "training accuracy = 0.8332551737090647, microF1 = 0.8672002871330446, macroF1 = 0.5112710324455948\n",
            "training accuracy = 0.8356320051854179, microF1 = 0.8686748022857971, macroF1 = 0.5139511009852158\n",
            "training accuracy = 0.835502462893979, microF1 = 0.8689150127534938, macroF1 = 0.5121923597268271\n",
            "training accuracy = 0.835653969390631, microF1 = 0.8681503414122207, macroF1 = 0.5157032946276394\n",
            "training accuracy = 0.8337491666927316, microF1 = 0.8665377468565777, macroF1 = 0.5168988798083198\n",
            "training accuracy = 0.8330201252994758, microF1 = 0.8657692523489767, macroF1 = 0.5160970095325866\n",
            "training accuracy = 0.8334495526223036, microF1 = 0.8661030395355593, macroF1 = 0.5158067357313699\n",
            "training accuracy = 0.833030337864957, microF1 = 0.8657073831107024, macroF1 = 0.5142504257574533\n",
            "training accuracy = 0.8332005732314517, microF1 = 0.8655120349844927, macroF1 = 0.5165137953337555\n",
            "training accuracy = 0.8328875719908264, microF1 = 0.8652129151493192, macroF1 = 0.515787994824608\n",
            "training accuracy = 0.8327842432733084, microF1 = 0.8650471324443961, macroF1 = 0.5159817478749646\n",
            "training accuracy = 0.8322488452317335, microF1 = 0.864617288387171, macroF1 = 0.5159902078011155\n",
            "training accuracy = 0.831971388653973, microF1 = 0.8644102421524325, macroF1 = 0.5153534539031114\n",
            "\n",
            "epoch = 15, training_loss = 0.04540923706342265, validation_loss =0.06907845910676975, training_acc = 0.8320103770566875, validation_acc =0.7767924169891429\n",
            "training accuracy = 0.8389228861365471, microF1 = 0.8710150566583683, macroF1 = 0.5139431401251174\n",
            "training accuracy = 0.8362608678776108, microF1 = 0.8681579759841865, macroF1 = 0.5243388561011275\n",
            "training accuracy = 0.8357505168785062, microF1 = 0.8673751964963877, macroF1 = 0.5209656620499641\n",
            "training accuracy = 0.8344010455322898, microF1 = 0.8658626536930037, macroF1 = 0.5232668688368406\n",
            "training accuracy = 0.8345859042638614, microF1 = 0.8660870551067094, macroF1 = 0.5217104819282494\n",
            "training accuracy = 0.8350196540903826, microF1 = 0.8663861007698949, macroF1 = 0.5203332187864536\n",
            "training accuracy = 0.8350630231193339, microF1 = 0.8667088790023106, macroF1 = 0.5174049698072123\n",
            "training accuracy = 0.8358927318435749, microF1 = 0.8674559934909369, macroF1 = 0.5174775367633169\n",
            "training accuracy = 0.836960033750128, microF1 = 0.868522457688662, macroF1 = 0.5191519145682868\n",
            "training accuracy = 0.8364853525570747, microF1 = 0.8680586030389963, macroF1 = 0.517945869911223\n",
            "training accuracy = 0.8364204875657889, microF1 = 0.8679111842247205, macroF1 = 0.5170571805365637\n",
            "training accuracy = 0.8363553353516194, microF1 = 0.8677663594566194, macroF1 = 0.5182655506317969\n",
            "training accuracy = 0.8363351876931683, microF1 = 0.8678155879318, macroF1 = 0.5187202283544001\n",
            "training accuracy = 0.8365165526007284, microF1 = 0.8678877645318108, macroF1 = 0.5189646332171886\n",
            "\n",
            "epoch = 16, training_loss = 0.04437665221412567, validation_loss =0.06797885272613506, training_acc = 0.836571239224743, validation_acc =0.7709087909272906\n",
            "training accuracy = 0.8456970833127012, microF1 = 0.8766810085407479, macroF1 = 0.5202501309513761\n",
            "training accuracy = 0.8451870384156892, microF1 = 0.8759477204225203, macroF1 = 0.5154245227728015\n",
            "training accuracy = 0.8445115116094261, microF1 = 0.8747488712724794, macroF1 = 0.523114981291809\n",
            "training accuracy = 0.8434063841093645, microF1 = 0.8735822927866268, macroF1 = 0.5255425010472804\n",
            "training accuracy = 0.8422847064380711, microF1 = 0.8727999438816939, macroF1 = 0.5285804926735841\n",
            "training accuracy = 0.8421641709470518, microF1 = 0.8725718684712723, macroF1 = 0.529305182023906\n",
            "training accuracy = 0.8426795937357209, microF1 = 0.8729477175150652, macroF1 = 0.5321790008438133\n",
            "training accuracy = 0.8417089611391033, microF1 = 0.8718842708098321, macroF1 = 0.5306056787891874\n",
            "training accuracy = 0.8412813358463912, microF1 = 0.871695126802204, macroF1 = 0.5309873028424705\n",
            "training accuracy = 0.8407584305820185, microF1 = 0.8712327534813508, macroF1 = 0.529363891103077\n",
            "training accuracy = 0.8400903856496021, microF1 = 0.8709103505891674, macroF1 = 0.5290507721919936\n",
            "training accuracy = 0.8403486780394482, microF1 = 0.8713149688271762, macroF1 = 0.530641543442747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-c51b05356c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# print(ypred.shape, Ybatch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0macc_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicrof1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacrof1_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnertags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0macc_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmicrof1\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mmicrof1_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-9d6de2ac6ca1>\u001b[0m in \u001b[0;36mperformance\u001b[0;34m(y, ypred, nertags)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmicrof1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mmacrof1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmicrof1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmacrof1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m_unique_multiclass\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_unique_multiclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj1cHxizLeXN"
      },
      "source": [
        "print(nertags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ0IjhNavype"
      },
      "source": [
        "plt.plot(trainlosslist, label = \"trainloss\")\n",
        "plt.plot(validlosslist, label = \"validloss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kuOxKLJ2jvT"
      },
      "source": [
        "plt.plot(trainacclist, label = 'train_accuracy')\n",
        "plt.plot(valacclist, label = 'val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZxuqBi0I8Fz"
      },
      "source": [
        "plt.plot(trainmicrof1list, label = 'train_microF1')\n",
        "plt.plot(valmicrof1list, label = 'val_microF1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLbH_sTcI8IS"
      },
      "source": [
        "plt.plot(trainmacrof1list, label = 'train_macroF1')\n",
        "plt.plot(valmacrof1list, label = 'val_macroF1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjJ0UWVXYyeA"
      },
      "source": [
        "#make id2tag\n",
        "id2tag = {}\n",
        "for tag in nertags.keys():\n",
        "    if(tag == 'padtag'):\n",
        "        id2tag[nertags[tag]] = 'O' # because we dont want the model to predict 'padtag' tags\n",
        "    else:\n",
        "        id2tag[nertags[tag]] = tag\n",
        "\n",
        "# print(id2tag)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq96j0gcSshF"
      },
      "source": [
        "def final_metrics(model, loader):\n",
        "    y_predicted = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        for step, (X, Y, xlen) in enumerate(loader):\n",
        "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
        "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
        "            ypred = model(X.long().to(device), xlen.to(device))#.permute(0, 2, 1)\n",
        "            ypred = torch.argmax(ypred.to('cpu'), dim = 1)\n",
        "            ypred = ypred.view(Y.shape[0], -1)\n",
        "\n",
        "            y_predicted.append(ypred)\n",
        "            y_true.append(Y)\n",
        "\n",
        "    y_predicted_list = []\n",
        "    y_true_list = []\n",
        "    for i in range(len(y_predicted)):\n",
        "        for j in range(y_predicted[i].shape[0]):\n",
        "            sent_pred = []\n",
        "            sent_true = []\n",
        "            for x in range(y_predicted[i].shape[1]):\n",
        "                sent_pred.append(id2tag[int(y_predicted[i][j, x])])\n",
        "                sent_true.append(id2tag[int(y_true[i][j, x])])\n",
        "            y_predicted_list.append(sent_pred)\n",
        "            y_true_list.append(sent_true)\n",
        "    print(y_predicted_list[0:5])\n",
        "    print(y_true_list[0:5])\n",
        "    return seq_f1_score(y_true_list, y_predicted_list), seq_accuracy_score(y_true_list, y_predicted_list), seq_classification_report(y_true_list, y_predicted_list)\n",
        "    #CONVERTING y_predicted and y_true lists into tag list\n",
        "    # return y_predicted, y_true"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WF2yxUnHnT2",
        "outputId": "4b3a4da6-fe0c-4843-da1b-4da2e07417ff"
      },
      "source": [
        "# calculate the final metrics usign seq eval\n",
        "# TRAINING DATA\n",
        "loader_train = DataLoader(traindataset, batch_size= 1, shuffle=False)\n",
        "train_f1_conll, train_acc_conll, train_classif_report = final_metrics(model, loader_train)\n",
        "\n",
        "# VALIDATION DATA\n",
        "loader_valid = DataLoader(devdataset, batch_size= 1, shuffle=False)\n",
        "valid_f1_conll, valid_acc_conll, valid_classif_report = final_metrics(model, loader_valid)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'B-per', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'B-geo', 'O', 'B-geo', 'B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "[['O', 'B-org', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'B-org', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'B-geo', 'O', 'B-geo', 'B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "[['O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'B-geo', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O'], ['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "[['O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'B-geo', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'B-org', 'I-org', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-per', 'I-per', 'I-per', 'O', 'O', 'O', 'O'], ['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz32VRN2ZkRG",
        "outputId": "e97d0e01-2381-4b8e-dbee-5d7463829d05"
      },
      "source": [
        "print(train_f1_conll, train_acc_conll)\n",
        "print(valid_f1_conll, valid_acc_conll)\n",
        "print(train_classif_report)\n",
        "print(valid_classif_report)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8221569275170819 0.9702565539687632\n",
            "0.7656507199417809 0.9569929436638981\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.31      0.08      0.13       296\n",
            "         eve       0.35      0.32      0.34       226\n",
            "         geo       0.85      0.88      0.86     29240\n",
            "         gpe       0.92      0.93      0.92     12058\n",
            "         nat       0.47      0.34      0.39       133\n",
            "         org       0.68      0.62      0.65     15803\n",
            "         per       0.79      0.82      0.80     13121\n",
            "         tim       0.89      0.84      0.86     15767\n",
            "\n",
            "   micro avg       0.83      0.82      0.82     86644\n",
            "   macro avg       0.66      0.60      0.62     86644\n",
            "weighted avg       0.82      0.82      0.82     86644\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.19      0.06      0.09       105\n",
            "         eve       0.20      0.24      0.22        78\n",
            "         geo       0.81      0.83      0.82      9724\n",
            "         gpe       0.90      0.90      0.90      4210\n",
            "         nat       0.53      0.38      0.44        50\n",
            "         org       0.58      0.55      0.56      5187\n",
            "         per       0.70      0.69      0.70      4457\n",
            "         tim       0.85      0.82      0.84      5254\n",
            "\n",
            "   micro avg       0.77      0.76      0.77     29065\n",
            "   macro avg       0.60      0.56      0.57     29065\n",
            "weighted avg       0.77      0.76      0.76     29065\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOEZxs9PH3vW"
      },
      "source": [
        "#save train loss, acc, micro, macro\n",
        "#save val loss, acc, micro, macro\n",
        "#save figure train, val - loss, acc, micro, macro\n",
        "#save the sentence level f1 score evaluation which is done using seq eval\n",
        "# save model"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dtYOhPTZeQN"
      },
      "source": [
        "#Test DATASET\n",
        "testdatapath = \"/content/drive/MyDrive/Q2_DL/test.txt\"\n",
        "Xtest, Ytest, x_testlengths, _, _ = load_data(testdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
        "\n",
        "testdataset = TensorDataset(Xtest, Ytest, x_testlengths)\n",
        "loader_test = DataLoader(testdataset, batch_size= 1, shuffle=False)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoJia62fx4FX",
        "outputId": "9af49195-cd58-44e8-e3b3-68d1b36727e3"
      },
      "source": [
        "test_f1_conll, test_acc_conll, test_classif_report = final_metrics(model, loader_test)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-org', 'O'], ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'B-geo', 'O'], ['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'B-geo', 'O'], ['B-per', 'I-per', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwNZ5qQWyoFP",
        "outputId": "64edbc44-6c68-4078-9dad-cc9a61a6751c"
      },
      "source": [
        "print(test_f1_conll, test_acc_conll)\n",
        "print(test_classif_report)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7637296422545881 0.9565811547990711\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.07      0.03      0.04       102\n",
            "         eve       0.22      0.30      0.25        87\n",
            "         geo       0.81      0.83      0.82      9912\n",
            "         gpe       0.90      0.90      0.90      4168\n",
            "         nat       0.43      0.22      0.29        55\n",
            "         org       0.57      0.54      0.56      5205\n",
            "         per       0.70      0.70      0.70      4406\n",
            "         tim       0.85      0.81      0.83      5275\n",
            "\n",
            "   micro avg       0.77      0.76      0.76     29210\n",
            "   macro avg       0.57      0.54      0.55     29210\n",
            "weighted avg       0.77      0.76      0.76     29210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAa6Ik8nLgMm"
      },
      "source": [
        ""
      ],
      "execution_count": 162,
      "outputs": []
    }
  ]
}