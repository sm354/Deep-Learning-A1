{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../NER_Dataset/ner-gmb/train.txt\", sep = \" \", header = None, names = ['token', 'postag', 'word', 'nertag'], skip_blank_lines=False)\n",
    "# df_list = np.split(df, df[df.isnull().all(1)].index) \n",
    "# #add sentence number to each dataframe and then combine. Also for each dataframe remove the first row\n",
    "\n",
    "# def add_sentence_number(df, i):\n",
    "#     '''adds a column to df in which all rows have value i'''\n",
    "#     df['sentence'] = i\n",
    "#     return df\n",
    "\n",
    "# new_dflist = []\n",
    "# for i, df in enumerate(df_list[1:]):\n",
    "#     df.reset_index(drop=True, inplace = True)\n",
    "#     df.dropna(inplace = True)\n",
    "#     df = add_sentence_number(df, i)\n",
    "#     new_dflist.append(df)\n",
    "\n",
    "# len(new_dflist)\n",
    "\n",
    "# def combine_dataframes(df_list):\n",
    "\n",
    "#     return pd.concat(df_list)\n",
    "\n",
    "\n",
    "# df = combine_dataframes(new_dflist)\n",
    "# df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading text file in python and making list of sentences (list of lists) and list of tags(list of lists)\n",
    "\n",
    "traindatapath = \"../NER_Dataset/ner-gmb/train.txt\"\n",
    "# train_sent = []\n",
    "# train_tags = []\n",
    "all_words = []\n",
    "all_tags = []\n",
    "with open(traindatapath) as f:\n",
    "    lines = f.readlines()\n",
    "    sent_num = 0\n",
    "    for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
    "        if(line == \"\\n\"):\n",
    "            sent_num+=1\n",
    "            train_sent.append(sentence)\n",
    "            train_tags.append(tags)\n",
    "            sentence = []\n",
    "            tags = []\n",
    "        else:\n",
    "            line_sep = line.split(sep = \" \")\n",
    "            all_words.append(line_sep[0])\n",
    "            all_tags.append(line_sep[3][:-1])\n",
    "            \n",
    "words = list(set(all_words))\n",
    "tags = list(set(all_tags))\n",
    "\n",
    "vocab = {}\n",
    "vocab['<pad>'] = 0 # for padding input sequences\n",
    "for i, word in enumerate(words):\n",
    "    vocab[word] = i+1\n",
    "    \n",
    "nertags = {}\n",
    "nertags['padtag'] = 0\n",
    "for i,nertag in enumerate(tags):\n",
    "    nertags[nertag] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent = []\n",
    "train_tags = []\n",
    "with open(traindatapath) as f:\n",
    "    lines = f.readlines()\n",
    "    sent_num = 0\n",
    "    sentence = []\n",
    "    tags = []\n",
    "    for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
    "        if(line == \"\\n\"):\n",
    "            sent_num+=1\n",
    "            train_sent.append(sentence)\n",
    "            train_tags.append(tags)\n",
    "            sentence = []\n",
    "            tags = []\n",
    "        else:\n",
    "            line_sep = line.split(sep = \" \")\n",
    "            sentence.append(vocab[line_sep[0]])\n",
    "            tags.append(nertags[line_sep[3][:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4005, 19151, 1187, 3403, 20949, 18982, 11604, 4005, 10587, 17286, 22237, 1010, 9697, 22237, 22227, 17286, 752, 12471, 18281, 6116, 18268, 23439, 16756, 659, 14017, 15937, 13748, 4005, 6014, 22244, 20949, 13748, 12471, 3962, 23439, 2606, 7225, 21870, 20168, 7997, 13403], [14355, 20949, 4005, 699, 12471, 16866, 32, 21932, 6370, 9270, 21870, 7362, 21328, 9878, 14066, 4005, 10281, 23439, 4005, 16677, 8864, 13748, 6200, 13403]]\n",
      "[[16, 9, 16, 16, 16, 4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 6, 16, 16, 16, 16], [16, 16, 16, 16, 16, 16, 16, 16, 16, 6, 16, 6, 16, 16, 16, 16, 16, 16, 16, 13, 16, 16, 9, 16]]\n",
      "24136 unique words\n",
      "0 unique tags\n"
     ]
    }
   ],
   "source": [
    "print(train_sent[:2])\n",
    "print(train_tags[:2])\n",
    "print(len(words), \"unique words\")\n",
    "print(\"{} unique tags\".format(len(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the sentences at the end\n",
    "seq_maxlen = max(len(x) for x in train_sent)\n",
    "x_lengths = [len(x) for x in train_sent]\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "for sent, tags in zip(train_sent, train_tags):\n",
    "    length_toappend = seq_maxlen - len(sent)\n",
    "    Xtrain.append(sent+[0]*length_toappend)\n",
    "    Ytrain.append(tags+[0]*length_toappend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4005, 19151, 1187, 3403, 20949, 18982, 11604, 4005, 10587, 17286, 22237, 1010, 9697, 22237, 22227, 17286, 752, 12471, 18281, 6116, 18268, 23439, 16756, 659, 14017, 15937, 13748, 4005, 6014, 22244, 20949, 13748, 12471, 3962, 23439, 2606, 7225, 21870, 20168, 7997, 13403, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[16, 9, 16, 16, 16, 4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 6, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[0])\n",
    "print(Ytrain[0])\n",
    "print(x_lengths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37206, 104]) torch.Size([37206, 104]) torch.Size([37206])\n"
     ]
    }
   ],
   "source": [
    "Xtrain = torch.Tensor(Xtrain)\n",
    "Ytrain = torch.Tensor(Ytrain)\n",
    "x_lengths = torch.Tensor(x_lengths)\n",
    "print(Xtrain.shape, Ytrain.shape, x_lengths.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "### using dataloader to make data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_lengths(batch):\n",
    "#     print(batch)\n",
    "#     (Xbatch, Ybatch) = zip(*batch)\n",
    "#     xlength = [len(x) for x in Xbatch]\n",
    "#     return Xbatch, Ybatch, xlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(Xtrain, Ytrain, x_lengths)\n",
    "dataloader = DataLoader(dataset, batch_size= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(next(iter(dataloader))))\n",
    "type(next(iter(dataloader)))#shape is (batchsize, seqlen)\n",
    "len(next(iter(dataloader)))\n",
    "\n",
    "# Xbatch, Ybatch, xlength = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104])\n"
     ]
    }
   ],
   "source": [
    "print(Xbatch[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random initialization of word embeddings\n",
    "# # ie define tensor of size (number of words, embedding dimesnion)\n",
    "# embed_dim = 100\n",
    "# num_words = len(vocab)\n",
    "# random_embed = torch.rand(num_words, embed_dim)\n",
    "# print(random_embed.shape)\n",
    "# print(random_embed[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, total_words, num_class, pretrained = False, pretrained_embed = None):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.wordembed = nn.Embedding(total_words, embedding_size) #weights initiallized from std normal dist, randomly\n",
    "        if(pretrained == True):\n",
    "            self.wordembed.weight = nn.Parameter(pretrained_embed) #pretrained embeds have size (total_words, embedding_size)\n",
    "\n",
    "        self.bilstm = nn.LSTM(embedding_size,hidden_size, bidirectional = True, batch_first = True)\n",
    "        self.linear = nn.Linear(2*hidden_size, num_class) # 2 because forward and backward concatenate\n",
    "\n",
    "    def forward(self, x, xlengths):\n",
    "        out = self.wordembed(x) # x is of size(batchsize, seq_len), out is of size (batchsize, seq_len, embedding_size = 100)\n",
    "        \n",
    "#         out = pack_padded_sequence(out, xlengths, batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        out, (h,c) = self.bilstm(out) #'out' has dimension(batchsize, seq_len, hidden_size)\n",
    "        \n",
    "#         out, out_lengths = pad_packed_sequence(out, batch_first=True)\n",
    "#         assert(out.shape[-1] == self.hidden_size)\n",
    "#         print(out.shape)\n",
    "\n",
    "        out = self.linear(out) #now 'out' has dimension(batchsize, seq_len, num_class)\n",
    "\n",
    "        out = F.softmax(out, dim=2) # take the softmax across the dimension num_class, 'out' has dimension(batchsize, seq_len, num_class)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(embedding_size = 100, hidden_size = 100, total_words = len(vocab), num_class = 18, pretrained = False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01) \n",
    "lossfunction = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM(\n",
      "  (wordembed): Embedding(24137, 100)\n",
      "  (bilstm): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=200, out_features=18, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-483e7eaf6907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#backward and step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clip gradient to 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model is ready now we have to train using cross entropy loss\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "total_batches = len(train_sent)//128 +1\n",
    "trainloss = []\n",
    "# validloss = []\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (Xbatch, Ybatch, xbatch_len) in enumerate(dataloader):\n",
    "        #make gradients 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #get output from model and claculate loss\n",
    "        ypred = model(Xbatch.long(), xbatch_len).permute(0, 2, 1)\n",
    "#         print(ypred.shape, Ybatch.shape)\n",
    "        \n",
    "        loss = lossfunction(ypred, Ybatch.type(torch.LongTensor)) #Ybatch has dimension (batchsize, seqlen), ypred has dimension(batchsize, num_classes, seqlen)\n",
    "        trainloss.append(loss)\n",
    "        \n",
    "        #backward and step\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
    "        optimizer.step()\n",
    "    print(trainloss[-1])\n",
    "    print(epoch)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(2.8931, grad_fn=<NllLoss2DBackward>), tensor(2.8929, grad_fn=<NllLoss2DBackward>), tensor(2.8923, grad_fn=<NllLoss2DBackward>), tensor(2.8920, grad_fn=<NllLoss2DBackward>), tensor(2.8919, grad_fn=<NllLoss2DBackward>), tensor(2.8914, grad_fn=<NllLoss2DBackward>), tensor(2.8911, grad_fn=<NllLoss2DBackward>), tensor(2.8905, grad_fn=<NllLoss2DBackward>), tensor(2.8902, grad_fn=<NllLoss2DBackward>), tensor(2.8902, grad_fn=<NllLoss2DBackward>), tensor(2.8899, grad_fn=<NllLoss2DBackward>), tensor(2.8892, grad_fn=<NllLoss2DBackward>), tensor(2.8891, grad_fn=<NllLoss2DBackward>), tensor(2.8887, grad_fn=<NllLoss2DBackward>), tensor(2.8883, grad_fn=<NllLoss2DBackward>), tensor(2.8880, grad_fn=<NllLoss2DBackward>), tensor(2.8874, grad_fn=<NllLoss2DBackward>), tensor(2.8871, grad_fn=<NllLoss2DBackward>), tensor(2.8870, grad_fn=<NllLoss2DBackward>), tensor(2.8867, grad_fn=<NllLoss2DBackward>), tensor(2.8860, grad_fn=<NllLoss2DBackward>), tensor(2.8854, grad_fn=<NllLoss2DBackward>), tensor(2.8852, grad_fn=<NllLoss2DBackward>), tensor(2.8845, grad_fn=<NllLoss2DBackward>), tensor(2.8841, grad_fn=<NllLoss2DBackward>), tensor(2.8840, grad_fn=<NllLoss2DBackward>), tensor(2.8837, grad_fn=<NllLoss2DBackward>), tensor(2.8830, grad_fn=<NllLoss2DBackward>), tensor(2.8826, grad_fn=<NllLoss2DBackward>), tensor(2.8820, grad_fn=<NllLoss2DBackward>), tensor(2.8813, grad_fn=<NllLoss2DBackward>), tensor(2.8811, grad_fn=<NllLoss2DBackward>), tensor(2.8808, grad_fn=<NllLoss2DBackward>), tensor(2.8800, grad_fn=<NllLoss2DBackward>), tensor(2.8798, grad_fn=<NllLoss2DBackward>), tensor(2.8791, grad_fn=<NllLoss2DBackward>), tensor(2.8782, grad_fn=<NllLoss2DBackward>), tensor(2.8780, grad_fn=<NllLoss2DBackward>), tensor(2.8779, grad_fn=<NllLoss2DBackward>), tensor(2.8770, grad_fn=<NllLoss2DBackward>), tensor(2.8762, grad_fn=<NllLoss2DBackward>), tensor(2.8760, grad_fn=<NllLoss2DBackward>), tensor(2.8750, grad_fn=<NllLoss2DBackward>), tensor(2.8748, grad_fn=<NllLoss2DBackward>), tensor(2.8739, grad_fn=<NllLoss2DBackward>), tensor(2.8731, grad_fn=<NllLoss2DBackward>), tensor(2.8729, grad_fn=<NllLoss2DBackward>), tensor(2.8718, grad_fn=<NllLoss2DBackward>)]\n"
     ]
    }
   ],
   "source": [
    "print(trainloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
