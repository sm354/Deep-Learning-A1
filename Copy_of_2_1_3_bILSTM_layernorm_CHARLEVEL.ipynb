{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of 2.1.3_bILSTM_CHARLEVEL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaxn8LyYFURg",
        "outputId": "4b6bb190-de96-456d-e968-69f29f4d4a64"
      },
      "source": [
        "Expname = \"BiLSTM_char_glove_layernorm\"\n",
        "pre_embeddings= \"glove\" # glove or random\n",
        "rootpath = \"/content/drive/MyDrive/Q2_DL/Experiments/\"\n",
        "\n",
        "!pip install seqeval\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import io\n",
        "import sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seqeval\n",
        "from seqeval.metrics import accuracy_score as seq_accuracy_score\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "from seqeval.metrics import f1_score as seq_f1_score\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  device = \"cuda:0\" \n",
        "else:  \n",
        "  device = \"cpu\"  \n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 28.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 21.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 25.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=2f259e7892bf829b92b42f64549082477f8fbc9ec15b7e9159a93fe80ddebc36\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9M1uW9_xHfE",
        "outputId": "6411a472-ca01-451d-9398-5e91a217b736"
      },
      "source": [
        "\n",
        "'''Helper Functions'''\n",
        "# reading text file in python and making list of sentences (list of lists) and list of tags(list of lists)\n",
        "def load_data(datapath, buildvocab_tags= True, vocab = None, nertags = None):\n",
        "    if(buildvocab_tags == True):\n",
        "        all_words = []\n",
        "        all_tags = []\n",
        "        with open(datapath) as f:\n",
        "            lines = f.readlines()\n",
        "            sent_num = 0\n",
        "            for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "                if(line == \"\\n\"):\n",
        "                    sent_num+=1\n",
        "                else:\n",
        "                    line_sep = line.split(sep = \" \")\n",
        "                    all_words.append(line_sep[0])\n",
        "                    all_tags.append(line_sep[3][:-1])\n",
        "                    \n",
        "        words = list(set(all_words))\n",
        "        tags = list(set(all_tags))\n",
        "\n",
        "        vocab = {}\n",
        "        vocab['<pad>'] = 0 # for padding input sequences\n",
        "        vocab['<oov>'] = 1\n",
        "        for i, word in enumerate(words):\n",
        "            vocab[word] = i+2\n",
        "            \n",
        "        nertags = {}\n",
        "        nertags['padtag'] = 0\n",
        "        for i,nertag in enumerate(tags):\n",
        "            nertags[nertag] = i+1\n",
        "\n",
        "    train_sent = []\n",
        "    train_tags = []\n",
        "    with open(datapath) as f:\n",
        "        lines = f.readlines()\n",
        "        sent_num = 0\n",
        "        sentence = []\n",
        "        tag = []\n",
        "        for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "            if(line == \"\\n\"):\n",
        "                sent_num+=1\n",
        "                train_sent.append(sentence)\n",
        "                train_tags.append(tag)\n",
        "                sentence = []\n",
        "                tag = []\n",
        "            else:\n",
        "                line_sep = line.split(sep = \" \")\n",
        "                if(line_sep[0] in vocab.keys()):\n",
        "                    sentence.append(vocab[line_sep[0]])\n",
        "                else:\n",
        "                    sentence.append(vocab['<oov>'])\n",
        "                    \n",
        "                tag.append(nertags[line_sep[3][:-1]])\n",
        "\n",
        "    # padding the sentences at the end\n",
        "    seq_maxlen = max(len(x) for x in train_sent)\n",
        "    x_lengths = [len(x) for x in train_sent]\n",
        "    Xtrain = []\n",
        "    Ytrain = []\n",
        "    for sent, tags in zip(train_sent, train_tags):\n",
        "        length_toappend = seq_maxlen - len(sent)\n",
        "        Xtrain.append(sent+[0]*length_toappend)\n",
        "        Ytrain.append(tags+[0]*length_toappend)\n",
        "\n",
        "\n",
        "    Xtrain = torch.Tensor(Xtrain)\n",
        "    Ytrain = torch.Tensor(Ytrain)\n",
        "    x_lengths = torch.Tensor(x_lengths)\n",
        "    # print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
        "    \n",
        "    return Xtrain, Ytrain, x_lengths, vocab, nertags\n",
        "\n",
        "def load_char_data(words, charvocab):\n",
        "    train_char_sent = []\n",
        "    train_char_label = []\n",
        "    for word in words:\n",
        "        chars = []\n",
        "        char_labels = []\n",
        "\n",
        "        word_sep = list(word)\n",
        "        for c in word_sep[:-1]:\n",
        "            if (c in charvocab.keys()):\n",
        "                chars.append(charvocab[c])\n",
        "            else:\n",
        "                chars.append(charvocab['<oovchar>'])\n",
        "        for c in word_sep[1:]:\n",
        "            if (c in charvocab.keys()):\n",
        "                char_labels.append(charvocab[c])\n",
        "            else:\n",
        "                char_labels.append(charvocab['<oovchar>'])\n",
        "        \n",
        "        train_char_sent.append(chars)\n",
        "        train_char_label.append(char_labels)\n",
        "\n",
        "    # padding the char_sents at the end\n",
        "    seq_maxlen = max(len(x) for x in train_char_sent)\n",
        "    x_lengths_char = [len(x) for x in train_char_sent]\n",
        "    Xtrain_char = []\n",
        "    Ytrain_char = []\n",
        "    for char_sent, char_label in zip(train_char_sent, train_char_label):\n",
        "        length_toappend = seq_maxlen - len(char_sent)\n",
        "        Xtrain_char.append(char_sent+[0]*length_toappend)\n",
        "        Ytrain_char.append(char_label+[0]*length_toappend) # 0 is padchar\n",
        "\n",
        "\n",
        "    Xtrain_char = torch.Tensor(Xtrain_char)\n",
        "    Ytrain_char = torch.Tensor(Ytrain_char)\n",
        "    x_lengths_char = torch.Tensor(x_lengths_char)\n",
        "    # print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
        "    \n",
        "    return Xtrain_char, Ytrain_char, x_lengths_char\n",
        "\n",
        "def pad_chars(topadlist, maxlen):\n",
        "    topadlist = topadlist + [0]*(maxlen-len(topadlist))\n",
        "\n",
        "    return topadlist\n",
        "\n",
        "def make_id2word_charvocab(vocab, charvocab):\n",
        "    max_charlen = max(len(word) for word in vocab.keys())\n",
        "    word_charlevel_vocab = {}\n",
        "    wordid2wordlen = {}\n",
        "    for word in vocab.keys():\n",
        "        word_charlevel_vocab[vocab[word]] = [charvocab[w] if w in charvocab.keys() else charvocab['<oovchar>'] for w in word]\n",
        "        word_charlevel_vocab[vocab[word]] = pad_chars(word_charlevel_vocab[vocab[word]], max_charlen)\n",
        "\n",
        "        wordid2wordlen[vocab[word]] = len(word)\n",
        "        # word_charlevel_vocab[vocab[word]] = word_charlevel_vocab[vocab[word]].extend([charvocab['<padchar>']]*(max_charlen-len(word_charlevel_vocab[vocab[word]])))\n",
        "    return word_charlevel_vocab, wordid2wordlen\n",
        "\n",
        "\n",
        "def load_char_level(X, wordid2word_charlevel_vocab, wordid2wordlen):\n",
        "    #X is of shape (no.of.sentences, 104)\n",
        "    Xcharlevel = [] # will finally be fo shape (total.sentences, max_sent.len, )\n",
        "    Xcharlevel_lengths = []\n",
        "    for i in range(X.shape[0]):\n",
        "        sentence = []\n",
        "        wordlengths = []\n",
        "        for j in range(X.shape[1]):\n",
        "            sentence.append(torch.tensor([wordid2word_charlevel_vocab[int(X[i, j].item())]]))\n",
        "            wordlengths.append(wordid2wordlen[int(X[i, j].item())])\n",
        "            # sentences = pad_sequence(sentences)\n",
        "        # print(i)\n",
        "        Xcharlevel_lengths.append(wordlengths)\n",
        "        Xcharlevel.append(torch.stack(sentence))\n",
        "    \n",
        "    return torch.squeeze(torch.stack(Xcharlevel)), torch.tensor(Xcharlevel_lengths)\n",
        "\n",
        "def get_charvocab(vocab):\n",
        "    # using vocab make charvocab\n",
        "    words = list(vocab.keys())\n",
        "    characters = [char for word in words for char in word]\n",
        "    characters = list(set(characters))\n",
        "    char_vocab = {}\n",
        "    char_vocab[\"<padchar>\"] = 0\n",
        "    char_vocab[\"<oovchar>\"] = 1\n",
        "    for i, char in enumerate(characters):\n",
        "        char_vocab[char] = i+2\n",
        "\n",
        "    return char_vocab\n",
        "\n",
        "\n",
        "\"\"\"### Training Data\n",
        "### using dataloader to make data batches\"\"\"\n",
        "\n",
        "traindatapath = \"/content/drive/MyDrive/Q2_DL/train.txt\"\n",
        "devdatapath = \"/content/drive/MyDrive/Q2_DL/dev.txt\"\n",
        "\n",
        "Xtrain, Ytrain, x_trainlengths, vocab, nertags = load_data(traindatapath, buildvocab_tags=True)\n",
        "Xdev, Ydev, x_devlengths, _, _ = load_data(devdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
        "\n",
        "# Character Level training data making\n",
        "# make vocabulary of characters from train vocabulary\n",
        "char_vocab = get_charvocab(vocab)\n",
        "wordid2word_charlevel_vocab, wordid2wordlen = make_id2word_charvocab(vocab, char_vocab) # of the form {word:[1,2,3,4]}, {wordnum:wordlen}\n",
        "#make char level train data for the char embeddings \n",
        "Xtrain_char, xlength_char = load_char_level(Xtrain, wordid2word_charlevel_vocab, wordid2wordlen)\n",
        "#finally make the dataloader for train\n",
        "traindataset = TensorDataset(Xtrain, Xtrain_char, Ytrain, x_trainlengths, xlength_char)\n",
        "Trainloader = DataLoader(traindataset, batch_size= 128, shuffle=True)\n",
        "\n",
        "\n",
        "# Character Level validation data making\n",
        "Xdev_temp, Ydev_temp, x_devlengths_temp, devvocab, devnertags = load_data(devdatapath, buildvocab_tags=True)\n",
        "wordid2word_charlevel_vocab_dev, wordid2wordlen_dev = make_id2word_charvocab(devvocab, char_vocab) # of the form {word:[1,2,3,4]}, {wordnum:wordlen}\n",
        "#make char level train data for the char embeddings \n",
        "Xdev_char, xdevlength_char = load_char_level(Xdev_temp, wordid2word_charlevel_vocab_dev, wordid2wordlen_dev)\n",
        "#finally make the dataloader for train\n",
        "devdataset = TensorDataset(Xdev, Xdev_char, Ydev, x_devlengths, xdevlength_char)\n",
        "Devloader = DataLoader(devdataset, batch_size= 128, shuffle=True)\n",
        "\n",
        "# LOAD EMBEDDINGS\n",
        "embedding_size = 100\n",
        "if(pre_embeddings == \"glove\"):\n",
        "    gloveembeddings_index = {}\n",
        "    with io.open(\"/content/drive/MyDrive/Q2_DL/glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:],dtype='float32')\n",
        "            gloveembeddings_index[word] = coefs\n",
        "\n",
        "    #using vocab and Xtrain, Xvalid, get pretrained glove word embeddings\n",
        "    glove_embeds = np.zeros((len(vocab), embedding_size))\n",
        "    for word in vocab.keys():\n",
        "        if(word in gloveembeddings_index.keys()):\n",
        "            # for the pad word let theembedding be all zeros\n",
        "            glove_embeds[vocab[word]] = gloveembeddings_index[word]\n",
        "        else:\n",
        "            glove_embeds[vocab[word]] = np.random.randn(embedding_size)\n",
        "    word_embeds = torch.Tensor(glove_embeds)\n",
        "    # print(glove_embeds.shape) # shape (vocablength , embedding dim)\n",
        "\n",
        "if(pre_embeddings == \"random\"):\n",
        "    num_words = len(vocab)\n",
        "    word_embeds = torch.rand(num_words, embedding_size)\n",
        "\n",
        "# hence we get word_embeds which we could use afterwards\n",
        "\n",
        "\n",
        "# character level onehot embeddings and important classes for performance metrics\n",
        "char_onehot = torch.eye(len(char_vocab))\n",
        "imp_classes = [nertags[tag] for tag in nertags.keys()]\n",
        "imp_classes.remove(nertags['padtag'])\n",
        "imp_classes.remove(nertags['O'])\n",
        "print(nertags)\n",
        "\n",
        "\n",
        "\"\"\"# LSTM models for character **level**\n",
        "\"\"\"\n",
        "class forLSTM(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, pretr_char_embed):\n",
        "        super(forLSTM, self).__init__()\n",
        "        self.charembed = nn.Embedding.from_pretrained(pretr_char_embed, freeze = False) #size of pretrained = (totalchars,embedding size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, bidirectional = True, batch_first = True)\n",
        "\n",
        "    def forward(self, xchar, xlength_char):\n",
        "        #xchar is of shape(batchsize, seqlen_maxinbatch, maxwordlen-ie max char = 6)\n",
        "\n",
        "        shape = xchar.shape\n",
        "        xchar = xchar.view(-1, shape[2])\n",
        "        xlength_char = xlength_char.view(-1)\n",
        "        input = pack_padded_sequence(xchar, xlength_char.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        input, _ = pad_packed_sequence(input, batch_first=True)\n",
        "        embed = self.charembed(input)\n",
        "        _, (h,_) = self.lstm(embed) #h is of size (2, 128*maxno. of words in a sentence in the batch, 25)\n",
        "        h = h.view(h.shape[1], 50)\n",
        "        h = h.view(shape[0], shape[1], 50)\n",
        "        return h\n",
        "\n",
        "\n",
        "\"\"\"# BiLSTM Model\"\"\"\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, total_words, num_class, pretrained = False, pretrained_embed = None, char_embed_size = 0, pretr_char_embed = None):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.wordembed = nn.Embedding.from_pretrained(pretrained_embed, freeze = False)\n",
        "        self.for_charembed = forLSTM(embedding_size = char_embed_size, hidden_size = 25, pretr_char_embed = pretr_char_embed)\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "        self.bilstm = LSTM(embedding_size + 50,hidden_size, bidirectional = True, batch_first = True)\n",
        "        self.linear = nn.Linear(2*hidden_size, num_class) # 2 because forward and backward concatenate\n",
        "\n",
        "    def forward(self, x, xchar, xlengths, xlength_char):\n",
        "        x = pack_padded_sequence(x, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        x, _ = pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "        xlength_char = pack_padded_sequence(xlength_char, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        xlength_char, _ = pad_packed_sequence(xlength_char, batch_first=True, padding_value = len(\"<pad>\")) \n",
        "        # above this line padding value is taken as len of pad word becasue that is what we pad sentences \n",
        "        # with hance at a character level it should be the length\n",
        "\n",
        "        xchar = pack_padded_sequence(xchar, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        xchar, _ = pad_packed_sequence(xchar, batch_first=True)\n",
        "\n",
        "        word_embedding = self.wordembed(x) # x is of size(batchsize, seq_len), wordembed is of size (batchsize, seq_len, embedding_size = 100)\n",
        "        forwardchar= self.for_charembed(xchar, xlength_char) #forwardchar and backwardchar would be of size (batchsize, seqlen. embedding_size = 25each) \n",
        "        word_embedding = torch.cat((word_embedding, forwardchar), dim = 2)\n",
        "\n",
        "        word_embedding = self.dropout(word_embedding) #dropout\n",
        "        out, (h,c) = self.bilstm(word_embedding) #'out' has dimension(batchsize, seq_len, 2*hidden_size)\n",
        "\n",
        "        out = self.linear(out) #now 'out' has dimension(batchsize, seq_len, num_class)\n",
        "        out = out.view(-1, out.shape[2]) # shape (128*seqlen, 18)\n",
        "        out = F.log_softmax(out, dim=1) # take the softmax across the dimension num_class, 'out' has dimension(batchsize, seq_len, num_class)\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "model = BiLSTM(embedding_size = 100, hidden_size = 100, total_words = len(vocab), num_class = 18, pretrained = True, pretrained_embed = word_embeds, char_embed_size = len(char_vocab), pretr_char_embed = char_onehot).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3) \n",
        "lossfunction = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# print(model)\n",
        "def performance(y, ypred, nertags):\n",
        "    y = y.numpy()\n",
        "    ypred = ypred.numpy()\n",
        "    mask = (y != nertags['padtag']) * (y != nertags['O'])\n",
        "    y = y*mask\n",
        "    ypred = ypred*mask\n",
        "    acc = ((y==ypred)*mask).sum()/mask.sum()\n",
        "    microf1 = f1_score(y, ypred, labels = imp_classes, average='micro')\n",
        "    macrof1 = f1_score(y, ypred, labels = imp_classes, average='macro')\n",
        "\n",
        "    return acc, microf1, macrof1\n",
        "\n",
        "def validate(model, loader):\n",
        "    with torch.no_grad():\n",
        "        validloss = 0\n",
        "        acc = 0\n",
        "        microf1 = 0\n",
        "        macrof1 = 0\n",
        "        i = 0\n",
        "        for step, (X, Xchar, Y, xlen, xlen_char) in enumerate(loader):\n",
        "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
        "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
        "            ypred = model(X.long().to(device), Xchar.to(device), xlen.to(device), xlen_char.to(device))#.permute(0, 2, 1)\n",
        "            vloss = lossfunction(ypred.to('cpu'), Y.view(-1).type(torch.LongTensor))\n",
        "            validloss+=vloss.item()\n",
        "            acc_, microf1_, macrof1_ = performance(Y.view(-1), torch.argmax(ypred.to('cpu'), dim = 1), nertags)\n",
        "            acc+=acc_\n",
        "            microf1 += microf1_\n",
        "            macrof1 += macrof1_\n",
        "            i+=1\n",
        "\n",
        "    return validloss/i, acc/i, microf1/i, macrof1/i\n",
        "\n",
        "\n",
        "trainlosslist = []\n",
        "trainacclist = [] #accuracy except pad, O\n",
        "trainmicrof1list = []\n",
        "trainmacrof1list = []\n",
        "\n",
        "\n",
        "validlosslist = []\n",
        "valacclist = []\n",
        "valmicrof1list = []\n",
        "valmacrof1list = []\n",
        "\n",
        "\n",
        "# Model is ready now we have to train using cross entropy loss\n",
        "num_epochs = 50\n",
        "# validloss = []\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    if(epoch == 35):\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "    \n",
        "    totalloss, acc, microf1, macrof1 = 0, 0, 0, 0\n",
        "    for step, (Xbatch , Xchar ,Ybatch, xbatch_len, xlength_char) in enumerate(Trainloader):\n",
        "        #make gradients 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        Ybatch = pack_padded_sequence(Ybatch, xbatch_len, batch_first=True, enforce_sorted=False)\n",
        "        Ybatch, y_lengths = pad_packed_sequence(Ybatch, batch_first=True)\n",
        "\n",
        "        #get output from model and claculate loss\n",
        "        ypred = model(Xbatch.long().to(device), Xchar.to(device), xbatch_len.to(device), xlength_char.to(device))#.permute(0, 2, 1)\n",
        "        acc_, microf1_, macrof1_ = performance(Ybatch.view(-1), torch.argmax(ypred.to('cpu'), dim = 1), nertags)\n",
        "        acc+= acc_\n",
        "        microf1+=microf1_\n",
        "        macrof1+=macrof1_\n",
        "        if(step%20 == 0 and step !=0):\n",
        "            print(\"training accuracy = {}, microF1 = {}, macroF1 = {}\".format(acc/(step+1), microf1/(step+1), macrof1/(step+1)))\n",
        "        \n",
        "        loss = lossfunction(ypred.to('cpu'), Ybatch.view(-1).type(torch.LongTensor)) #Ybatch has dimension (batchsize, seqlen), ypred has dimension(batchsize, num_classes, seqlen)\n",
        "        totalloss += loss.item()\n",
        "\n",
        "        #backward and step\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
        "        optimizer.step()\n",
        "    \n",
        "    trainlosslist.append(totalloss/(step+1))\n",
        "    trainacclist.append(acc/(step+1))\n",
        "    trainmicrof1list.append(microf1/(step+1))\n",
        "    trainmacrof1list.append(macrof1/(step+1))\n",
        "\n",
        "    # model validation loss and scheduler step for learning rate change if required\n",
        "    val_loss, val_acc, val_microf1, val_macrof1  = validate(model, Devloader)\n",
        "    validlosslist.append(val_loss)\n",
        "    valacclist.append(val_acc)\n",
        "    valmicrof1list.append(val_microf1)\n",
        "    valmacrof1list.append(val_macrof1)\n",
        "    \n",
        "    # scheduler.step(val_loss)\n",
        "    print('\\nepoch = {}, training_loss = {}, validation_loss ={}, training_acc = {}, validation_acc ={}'.format(epoch, trainlosslist[-1], validlosslist[-1], trainacclist[-1], valacclist[-1]))        \n",
        "        \n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import os\n",
        "if not os.path.exists(rootpath):\n",
        "    os.mkdir(rootpath)\n",
        "\n",
        "if not os.path.exists(rootpath+Expname):\n",
        "    os.mkdir(rootpath+Expname)\n",
        "\n",
        "\n",
        "def SavePlots(y1, y2, metric, rootpath, Expname):\n",
        "    try:\n",
        "        plt.clf()\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    \"\"\"y2 should be validation\"\"\"\n",
        "    epochs=np.arange(1,len(y1)+1,1)\n",
        "    plt.title(Expname + \" \" + metric + \" plot\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric)\n",
        "    plt.plot(epochs,y1,label='Training %s'%metric, linewidth = 2)\n",
        "    plt.plot(epochs,y2,label='Validation %s'%metric, linewidth = 2)\n",
        "    if(metric == \"Loss\"):\n",
        "        ep=np.argmin(y2)\n",
        "    elif(metric != \"Loss\"):\n",
        "        ep =np.argmax(y2)\n",
        "    plt.plot(ep+1,y2[ep],'r*',label='bestvalue@(%.i,%.2f)'%(ep+1,y2[ep]))\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.savefig(rootpath+Expname+\"/{}\".format(metric), dpi=300)\n",
        "\n",
        "SavePlots(trainlosslist, validlosslist, \"Loss\", rootpath, Expname)\n",
        "SavePlots(trainacclist, valacclist, \"Accuracy\", rootpath, Expname)\n",
        "SavePlots(trainmicrof1list, valmicrof1list, \"Micro F1\", rootpath, Expname)\n",
        "SavePlots(trainmacrof1list, valmacrof1list, \"Macro F1\", rootpath, Expname)\n",
        "\n",
        "#make id2tag\n",
        "id2tag = {}\n",
        "for tag in nertags.keys():\n",
        "    if(tag == 'padtag'):\n",
        "        id2tag[nertags[tag]] = 'O' # because we dont want the model to predict 'padtag' tags\n",
        "    else:\n",
        "        id2tag[nertags[tag]] = tag\n",
        "\n",
        "\n",
        "def final_metrics(model, loader):\n",
        "    y_predicted = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        for step, (X, Xchar, Y, xlen, xlen_char) in enumerate(loader):\n",
        "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
        "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
        "            ypred = model(X.long().to(device), Xchar.to(device), xlen.to(device), xlen_char.to(device))#.permute(0, 2, 1)\n",
        "            ypred = torch.argmax(ypred.to('cpu'), dim = 1)\n",
        "            ypred = ypred.view(Y.shape[0], -1)\n",
        "            # print(ypred.shape)\n",
        "\n",
        "            y_predicted.append(ypred)\n",
        "            y_true.append(Y)\n",
        "\n",
        "    y_predicted_list = []\n",
        "    y_true_list = []\n",
        "    for i in range(len(y_predicted)):\n",
        "        for j in range(y_predicted[i].shape[0]):\n",
        "            sent_pred = []\n",
        "            sent_true = []\n",
        "            for x in range(y_predicted[i].shape[1]):\n",
        "                sent_pred.append(id2tag[int(y_predicted[i][j, x])])\n",
        "                sent_true.append(id2tag[int(y_true[i][j, x])])\n",
        "            y_predicted_list.append(sent_pred)\n",
        "            y_true_list.append(sent_true)\n",
        "    # print(y_predicted_list[0:5])\n",
        "    # print(y_true_list[0:5])\n",
        "    return seq_f1_score(y_true_list, y_predicted_list), seq_accuracy_score(y_true_list, y_predicted_list), seq_classification_report(y_true_list, y_predicted_list, digits = 3)\n",
        "    #CONVERTING y_predicted and y_true lists into tag list\n",
        "    # return y_predicted, y_true\n",
        "\n",
        "\n",
        "# calculate the final metrics usign seq eval\n",
        "# TRAINING DATA\n",
        "loader_train = DataLoader(traindataset, batch_size= 1, shuffle=False)\n",
        "train_f1_conll, train_acc_conll, train_classif_report = final_metrics(model, loader_train)\n",
        "\n",
        "# VALIDATION DATA\n",
        "loader_valid = DataLoader(devdataset, batch_size= 1, shuffle=False)\n",
        "valid_f1_conll, valid_acc_conll, valid_classif_report = final_metrics(model, loader_valid)\n",
        "\n",
        "print(\"PERFORMANCE ON Train DATA\")\n",
        "print('MicroF1 = {} '.format(train_f1_conll))\n",
        "print('Accuracy = {}'.format(train_acc_conll))\n",
        "print('------------Classification Report-------------')\n",
        "print(train_classif_report)\n",
        "\n",
        "print(\"PERFORMANCE ON Validation DATA\")\n",
        "print('MicroF1 = {} '.format(valid_f1_conll))\n",
        "print('Accuracy = {}'.format(valid_acc_conll))\n",
        "print('------------Classification Report-------------')\n",
        "print(valid_classif_report)\n",
        "\n",
        "#Test DATASET\n",
        "testdatapath = \"/content/drive/MyDrive/Q2_DL/test.txt\"\n",
        "char_vocab = get_charvocab(vocab)\n",
        "Xtest, Ytest, x_testlengths, _, _ = load_data(testdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
        "\n",
        "Xtest_temp, Ytest_temp, x_testlengths_temp, testvocab, testnertags = load_data(testdatapath, buildvocab_tags=True)\n",
        "wordid2word_charlevel_vocab_test, wordid2wordlen_test = make_id2word_charvocab(testvocab, char_vocab) # of the form {word:[1,2,3,4]}, {wordnum:wordlen}\n",
        "#make char level train data for the char embeddings \n",
        "Xtest_char, xtestlength_char = load_char_level(Xtest_temp, wordid2word_charlevel_vocab_test, wordid2wordlen_test)\n",
        "#finally make the dataloader for train\n",
        "testdataset = TensorDataset(Xtest, Xtest_char, Ytest, x_testlengths, xtestlength_char)\n",
        "loader_test = DataLoader(testdataset, batch_size= 1, shuffle=False)\n",
        "test_f1_conll, test_acc_conll, test_classif_report = final_metrics(model, loader_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"PERFORMANCE ON Test DATA\")\n",
        "print('MicroF1 = {}'.format(test_f1_conll))\n",
        "print('Accuracy = {}'.format(test_acc_conll))\n",
        "print('------------Classification Report-------------')\n",
        "print(test_classif_report)\n",
        "\n",
        "\n",
        "\"\"\"SAVING DATA\"\"\"\n",
        "\n",
        "# save performance metrics dictionaries\n",
        "# save train loss, acc, micro, macro\n",
        "# save val loss, acc, micro, macro\n",
        "# save model\n",
        "import pickle\n",
        "#train\n",
        "pickle.dump(train_classif_report, open(rootpath+Expname+\"/train_classif_report.dict.pickle\", \"wb\" ))\n",
        "np.save(rootpath+Expname+\"/train_losslist.npy\", np.asarray(trainlosslist))\n",
        "np.save(rootpath+Expname+\"/train_acclist.npy\", np.asarray(trainacclist))\n",
        "np.save(rootpath+Expname+\"/train_microf1list.npy\", np.asarray(trainmicrof1list))\n",
        "np.save(rootpath+Expname+\"/train_macrof1list.npy\", np.asarray(trainmacrof1list))\n",
        "\n",
        "#valid\n",
        "pickle.dump(valid_classif_report, open(rootpath+Expname+\"/valid_classif_report.dict.pickle\", \"wb\" ))\n",
        "np.save(rootpath+Expname+\"/val_losslist.npy\", np.asarray(validlosslist))\n",
        "np.save(rootpath+Expname+\"/val_acclist.npy\", np.asarray(valacclist))\n",
        "np.save(rootpath+Expname+\"/val_microf1list.npy\", np.asarray(valmicrof1list))\n",
        "np.save(rootpath+Expname+\"/val_macrof1list.npy\", np.asarray(valmacrof1list))\n",
        "\n",
        "#test\n",
        "pickle.dump(test_classif_report, open(rootpath+Expname+\"/test_classif_report.dict.pickle\", \"wb\" ))\n",
        "\n",
        "\n",
        "#Save Model\n",
        "torch.save(model, rootpath+Expname+\"/{}_model.pth\".format(Expname))    \n",
        "        "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'padtag': 0, 'O': 1, 'B-nat': 2, 'I-geo': 3, 'I-art': 4, 'I-per': 5, 'B-per': 6, 'B-gpe': 7, 'I-gpe': 8, 'I-eve': 9, 'B-geo': 10, 'B-eve': 11, 'B-org': 12, 'I-tim': 13, 'B-tim': 14, 'I-org': 15, 'I-nat': 16, 'B-art': 17}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy = 0.002725939118069592, microF1 = 0.0030547870556673377, macroF1 = 0.001168642314475648\n",
            "training accuracy = 0.0013962127190112546, microF1 = 0.0015646470285125389, macroF1 = 0.0005985728927802099\n",
            "training accuracy = 0.0009384380570403514, microF1 = 0.0010516480027707227, macroF1 = 0.0004023194853112886\n",
            "training accuracy = 0.0007067249565365609, microF1 = 0.0007919818292470875, macroF1 = 0.0003029813407899828\n",
            "training accuracy = 0.0046633599324646755, microF1 = 0.008206575528562125, macroF1 = 0.002625442755359579\n",
            "training accuracy = 0.025233849549417747, microF1 = 0.04051862605182762, macroF1 = 0.012753639004128363\n",
            "training accuracy = 0.06270417340363912, microF1 = 0.09012072169676245, macroF1 = 0.030175874387084627\n",
            "training accuracy = 0.10003961473184919, microF1 = 0.13611696048421237, macroF1 = 0.04784704317172525\n",
            "training accuracy = 0.13641209363858822, microF1 = 0.1785415858778966, macroF1 = 0.06511219999247377\n",
            "training accuracy = 0.1697292118796275, microF1 = 0.21635255730268851, macroF1 = 0.0816228466491154\n",
            "training accuracy = 0.2002095480798809, microF1 = 0.2503731128547754, macroF1 = 0.09776445472872002\n",
            "training accuracy = 0.22741313102675592, microF1 = 0.280486697177162, macroF1 = 0.11402903278315113\n",
            "training accuracy = 0.2528985858663838, microF1 = 0.3082408548928953, macroF1 = 0.1301552592127798\n",
            "training accuracy = 0.275313540598005, microF1 = 0.33233624190068384, macroF1 = 0.1450149506279699\n",
            "\n",
            "epoch = 0, training_loss = 0.2617617747474372, validation_loss =0.1198851333297405, training_acc = 0.2863241560565446, validation_acc =0.5821772257920954\n",
            "training accuracy = 0.6039482384654837, microF1 = 0.6793780150706836, macroF1 = 0.3615066360434346\n",
            "training accuracy = 0.6172367042492319, microF1 = 0.6917259315287578, macroF1 = 0.3694253605359358\n",
            "training accuracy = 0.6241553796050543, microF1 = 0.6979463182404214, macroF1 = 0.3727087897727782\n",
            "training accuracy = 0.6295637116859849, microF1 = 0.7025742947262624, macroF1 = 0.37563878928444433\n",
            "training accuracy = 0.6347403082933126, microF1 = 0.7071518119292391, macroF1 = 0.37803127092327293\n",
            "training accuracy = 0.6395335786024955, microF1 = 0.7110818448507067, macroF1 = 0.3808138844101328\n",
            "training accuracy = 0.644184513264703, microF1 = 0.7150131284446717, macroF1 = 0.38352166892378736\n",
            "training accuracy = 0.6476580391155183, microF1 = 0.7177802458197388, macroF1 = 0.38520917930233917\n",
            "training accuracy = 0.6512839743352417, microF1 = 0.7208261322657609, macroF1 = 0.38735397418265977\n",
            "training accuracy = 0.654956429895032, microF1 = 0.7240779543956058, macroF1 = 0.3894481278404099\n",
            "training accuracy = 0.6589963292448207, microF1 = 0.727536580800836, macroF1 = 0.391798968267117\n",
            "training accuracy = 0.6618085701257065, microF1 = 0.7298642172757379, macroF1 = 0.39369566660732425\n",
            "training accuracy = 0.6648001428796907, microF1 = 0.7321617036768642, macroF1 = 0.39495491890725853\n",
            "training accuracy = 0.6674257252670481, microF1 = 0.7343830892598161, macroF1 = 0.39639479476860323\n",
            "\n",
            "epoch = 1, training_loss = 0.09698675277153242, validation_loss =0.09155678307426345, training_acc = 0.6679669985688316, validation_acc =0.6793348727647581\n",
            "training accuracy = 0.7159630936620504, microF1 = 0.7723097316194224, macroF1 = 0.4192774712741062\n",
            "training accuracy = 0.7149344595648014, microF1 = 0.7721183744154446, macroF1 = 0.42015979697074635\n",
            "training accuracy = 0.7154592486647989, microF1 = 0.7729816115852532, macroF1 = 0.42237967905594026\n",
            "training accuracy = 0.7128798612978223, microF1 = 0.7708469009010454, macroF1 = 0.42085723856453\n",
            "training accuracy = 0.7145806385998772, microF1 = 0.7719007604806803, macroF1 = 0.42165965643267095\n",
            "training accuracy = 0.7166554180398365, microF1 = 0.7733382495031141, macroF1 = 0.42235213462189786\n",
            "training accuracy = 0.716765393770678, microF1 = 0.773528999637367, macroF1 = 0.42260337819605504\n",
            "training accuracy = 0.7172139102048063, microF1 = 0.774177977999298, macroF1 = 0.4230735178161283\n",
            "training accuracy = 0.7188941986962439, microF1 = 0.7756629451672973, macroF1 = 0.4243273634300039\n",
            "training accuracy = 0.7196542063807546, microF1 = 0.7762825931086379, macroF1 = 0.4245550785436757\n",
            "training accuracy = 0.7206008355042932, microF1 = 0.7767997254298141, macroF1 = 0.4250290185029252\n",
            "training accuracy = 0.7224252993442023, microF1 = 0.7783202305802176, macroF1 = 0.4259780196412375\n",
            "training accuracy = 0.724080986681225, microF1 = 0.7796284239892631, macroF1 = 0.42671124619651324\n",
            "training accuracy = 0.7248531193659498, microF1 = 0.7803301673633781, macroF1 = 0.4270978310051657\n",
            "\n",
            "epoch = 2, training_loss = 0.08003253292586796, validation_loss =0.08085669723060943, training_acc = 0.7248656597387033, validation_acc =0.7164033106114018\n",
            "training accuracy = 0.7502820139068614, microF1 = 0.8016417378325769, macroF1 = 0.43947888043652017\n",
            "training accuracy = 0.7462217413755993, microF1 = 0.7980918260704174, macroF1 = 0.4380302433715818\n",
            "training accuracy = 0.747255810735939, microF1 = 0.7985491628350585, macroF1 = 0.4393656138714095\n",
            "training accuracy = 0.7501610618230719, microF1 = 0.8004436770852876, macroF1 = 0.4402144053274934\n",
            "training accuracy = 0.7501117221069418, microF1 = 0.8007044882543698, macroF1 = 0.44038990662007843\n",
            "training accuracy = 0.7506804589711938, microF1 = 0.8010944169908462, macroF1 = 0.44017112785208223\n",
            "training accuracy = 0.7496322020145719, microF1 = 0.8000168208520887, macroF1 = 0.4401153356464428\n",
            "training accuracy = 0.7492914829518613, microF1 = 0.7996432293708374, macroF1 = 0.4398735412454151\n",
            "training accuracy = 0.7481516574053113, microF1 = 0.7985204629780852, macroF1 = 0.43930777799096216\n",
            "training accuracy = 0.7485543174385272, microF1 = 0.7987430710503982, macroF1 = 0.4397447855010502\n",
            "training accuracy = 0.7487666783953869, microF1 = 0.7989300271395066, macroF1 = 0.4396317701391725\n",
            "training accuracy = 0.7489128708928126, microF1 = 0.7990428486477485, macroF1 = 0.4395440740040948\n",
            "training accuracy = 0.7496022064883348, microF1 = 0.7996471836656798, macroF1 = 0.44023829221727856\n",
            "training accuracy = 0.7499725472034687, microF1 = 0.7998258561003978, macroF1 = 0.440374607477432\n",
            "\n",
            "epoch = 3, training_loss = 0.07114021499285993, validation_loss =0.07643517083728436, training_acc = 0.7501730753918593, validation_acc =0.7375951104375013\n",
            "training accuracy = 0.7710431230803881, microF1 = 0.8176920099639744, macroF1 = 0.45350392343880147\n",
            "training accuracy = 0.7668713664476103, microF1 = 0.8125641141482031, macroF1 = 0.4503247411959801\n",
            "training accuracy = 0.7675889778443208, microF1 = 0.8140763238432498, macroF1 = 0.4523427371996031\n",
            "training accuracy = 0.767332514428652, microF1 = 0.8135449566993393, macroF1 = 0.4513626907179892\n",
            "training accuracy = 0.7683141001407473, microF1 = 0.8145362836234545, macroF1 = 0.4512040393404167\n",
            "training accuracy = 0.7668839279412117, microF1 = 0.813135928989468, macroF1 = 0.45045176088341204\n",
            "training accuracy = 0.7660638349106474, microF1 = 0.8121904355864538, macroF1 = 0.44968964914338017\n",
            "training accuracy = 0.7650086090570571, microF1 = 0.8116320639676946, macroF1 = 0.449444468583629\n",
            "training accuracy = 0.7654911329183031, microF1 = 0.8119328305800844, macroF1 = 0.4495332845934005\n",
            "training accuracy = 0.7653033625312462, microF1 = 0.811848987677, macroF1 = 0.4503157507329933\n",
            "training accuracy = 0.7653890427322771, microF1 = 0.8119704827707432, macroF1 = 0.4501602728802141\n",
            "training accuracy = 0.7661592235530121, microF1 = 0.8126197399924816, macroF1 = 0.45048232203526584\n",
            "training accuracy = 0.7661996462186195, microF1 = 0.8128506186553142, macroF1 = 0.4506731340275814\n",
            "training accuracy = 0.7662143796260198, microF1 = 0.8127433556852265, macroF1 = 0.45056178785668777\n",
            "\n",
            "epoch = 4, training_loss = 0.06585267667508207, validation_loss =0.07340363820189054, training_acc = 0.7662495536067547, validation_acc =0.7485228105062616\n",
            "training accuracy = 0.7860690472760294, microF1 = 0.8312440563732435, macroF1 = 0.47474142994196733\n",
            "training accuracy = 0.7830005497161034, microF1 = 0.8283837763268928, macroF1 = 0.4664875154480742\n",
            "training accuracy = 0.779249185761384, microF1 = 0.8239433497886123, macroF1 = 0.46384521854253513\n",
            "training accuracy = 0.7770058847592416, microF1 = 0.821791849997283, macroF1 = 0.4610142785417951\n",
            "training accuracy = 0.7767994984390245, microF1 = 0.8217738399902204, macroF1 = 0.4602997697840592\n",
            "training accuracy = 0.7771230553769883, microF1 = 0.8219441191502872, macroF1 = 0.4614895046865087\n",
            "training accuracy = 0.7771187786245555, microF1 = 0.8217476040733334, macroF1 = 0.4603328856779363\n",
            "training accuracy = 0.7768981162701608, microF1 = 0.8212467911178924, macroF1 = 0.4614712627189003\n",
            "training accuracy = 0.77651059081614, microF1 = 0.8207598099633261, macroF1 = 0.461339510555215\n",
            "training accuracy = 0.777594763605769, microF1 = 0.8217619693437489, macroF1 = 0.46117973358092046\n",
            "training accuracy = 0.7783663719380136, microF1 = 0.8223972879129237, macroF1 = 0.46191543089627524\n",
            "training accuracy = 0.7790572208058458, microF1 = 0.8229300640343701, macroF1 = 0.46187193988290093\n",
            "training accuracy = 0.7798310511639326, microF1 = 0.8235017063159498, macroF1 = 0.46197271454743793\n",
            "training accuracy = 0.7799306437238541, microF1 = 0.823551168665128, macroF1 = 0.46192697093741997\n",
            "\n",
            "epoch = 5, training_loss = 0.06170031689491469, validation_loss =0.07257750131113012, training_acc = 0.780580315856802, validation_acc =0.7563863708119649\n",
            "training accuracy = 0.7895617875341039, microF1 = 0.8302849297034831, macroF1 = 0.4739827221787601\n",
            "training accuracy = 0.7958478283179179, microF1 = 0.8362581872229273, macroF1 = 0.4767703945855427\n",
            "training accuracy = 0.7932640125795023, microF1 = 0.8343968515159196, macroF1 = 0.4733420410396351\n",
            "training accuracy = 0.7931396856855463, microF1 = 0.8341585226309131, macroF1 = 0.4728143809249943\n",
            "training accuracy = 0.7910795445447675, microF1 = 0.8326236599129913, macroF1 = 0.47385607484882825\n",
            "training accuracy = 0.7915695279453387, microF1 = 0.8331382619384637, macroF1 = 0.47420791007447777\n",
            "training accuracy = 0.7906369229754431, microF1 = 0.8319799877601861, macroF1 = 0.47310370873169894\n",
            "training accuracy = 0.7905649711898217, microF1 = 0.8319257122960679, macroF1 = 0.4742321045658434\n",
            "training accuracy = 0.7921463209255447, microF1 = 0.8331087905327021, macroF1 = 0.47575828178235086\n",
            "training accuracy = 0.7916192050660253, microF1 = 0.8327801615973549, macroF1 = 0.47532401941221364\n",
            "training accuracy = 0.791002416017305, microF1 = 0.8322418604515441, macroF1 = 0.4759534660605191\n",
            "training accuracy = 0.7908673368348461, microF1 = 0.8321010253419169, macroF1 = 0.47515321633306173\n",
            "training accuracy = 0.7904618944877354, microF1 = 0.8318432126510803, macroF1 = 0.47520788759451865\n",
            "training accuracy = 0.7900941176241891, microF1 = 0.8316830843117886, macroF1 = 0.47515604970448894\n",
            "\n",
            "epoch = 6, training_loss = 0.05841256245407452, validation_loss =0.06948341851689152, training_acc = 0.7903472343309879, validation_acc =0.7514211927158904\n",
            "training accuracy = 0.7879293544143687, microF1 = 0.8303021832086985, macroF1 = 0.4785925812890541\n",
            "training accuracy = 0.7887469208431063, microF1 = 0.8304459096731576, macroF1 = 0.47714723668082887\n",
            "training accuracy = 0.7901728121494308, microF1 = 0.8319002429878216, macroF1 = 0.4750831401129977\n",
            "training accuracy = 0.7909580450530543, microF1 = 0.8323085500486305, macroF1 = 0.4754707235002995\n",
            "training accuracy = 0.7903446275529706, microF1 = 0.8316958949935005, macroF1 = 0.475391520072894\n",
            "training accuracy = 0.7933783281797464, microF1 = 0.8342998455912416, macroF1 = 0.4791449956350368\n",
            "training accuracy = 0.7941424765138421, microF1 = 0.8348418907037112, macroF1 = 0.47845775568855464\n",
            "training accuracy = 0.7948129265460132, microF1 = 0.8354404205088993, macroF1 = 0.4812118363863538\n",
            "training accuracy = 0.795465008947051, microF1 = 0.8360128683818072, macroF1 = 0.48096598972790183\n",
            "training accuracy = 0.7949272043661105, microF1 = 0.8354124177479885, macroF1 = 0.4810586840852864\n",
            "training accuracy = 0.7952590470198221, microF1 = 0.835593311649758, macroF1 = 0.48160443580215645\n",
            "training accuracy = 0.7955137010891002, microF1 = 0.8357300975647802, macroF1 = 0.48257020049126176\n",
            "training accuracy = 0.7959031497675857, microF1 = 0.8360759571067388, macroF1 = 0.48237330437835124\n",
            "training accuracy = 0.7965878079921729, microF1 = 0.8366339256536236, macroF1 = 0.4830439717117015\n",
            "\n",
            "epoch = 7, training_loss = 0.055781694090704326, validation_loss =0.06843351718691207, training_acc = 0.7966619906852332, validation_acc =0.7703759447277765\n",
            "training accuracy = 0.8165808976234968, microF1 = 0.8536173268855866, macroF1 = 0.4926634582650542\n",
            "training accuracy = 0.8099422321426746, microF1 = 0.8477925321658678, macroF1 = 0.490632651958705\n",
            "training accuracy = 0.8097275483895511, microF1 = 0.8472921987733526, macroF1 = 0.4895286284831842\n",
            "training accuracy = 0.810272916916552, microF1 = 0.8481873088849812, macroF1 = 0.49202283968305616\n",
            "training accuracy = 0.8089420157365617, microF1 = 0.846881616343693, macroF1 = 0.49259579139195003\n",
            "training accuracy = 0.8075335628953451, microF1 = 0.8458584906972743, macroF1 = 0.492756261348457\n",
            "training accuracy = 0.806321942328851, microF1 = 0.8445431483246176, macroF1 = 0.49190440044202816\n",
            "training accuracy = 0.806557929086886, microF1 = 0.8448634821875607, macroF1 = 0.49292645744938446\n",
            "training accuracy = 0.8065290565940583, microF1 = 0.8448766220598164, macroF1 = 0.49370553397328043\n",
            "training accuracy = 0.8064704128977399, microF1 = 0.8447354138277796, macroF1 = 0.4926342753594379\n",
            "training accuracy = 0.8062835712557349, microF1 = 0.844613737608471, macroF1 = 0.49145539607046046\n",
            "training accuracy = 0.8053753480973574, microF1 = 0.8437791064065188, macroF1 = 0.4903672055085457\n",
            "training accuracy = 0.8054671647129784, microF1 = 0.8438685633095083, macroF1 = 0.4909790645619073\n",
            "training accuracy = 0.8055252502687669, microF1 = 0.8439136352667616, macroF1 = 0.49090300669306897\n",
            "\n",
            "epoch = 8, training_loss = 0.05379053379354608, validation_loss =0.06641405187163156, training_acc = 0.8054108875583751, validation_acc =0.7670731790968028\n",
            "training accuracy = 0.8060390531141479, microF1 = 0.8420650304781833, macroF1 = 0.4868039370140232\n",
            "training accuracy = 0.8103635242754731, microF1 = 0.8465337284831408, macroF1 = 0.49779002406150763\n",
            "training accuracy = 0.8092608033008384, microF1 = 0.8461345016925319, macroF1 = 0.5013464179671221\n",
            "training accuracy = 0.8110344886297558, microF1 = 0.8478782876099923, macroF1 = 0.5023478990649677\n",
            "training accuracy = 0.8107177776072557, microF1 = 0.8478741568611741, macroF1 = 0.4991780773762235\n",
            "training accuracy = 0.8111806025642542, microF1 = 0.8480619200639047, macroF1 = 0.49937196079678553\n",
            "training accuracy = 0.8102538761404905, microF1 = 0.8475036700850431, macroF1 = 0.49822326429253805\n",
            "training accuracy = 0.8104663678602806, microF1 = 0.8475659445229844, macroF1 = 0.4982119956119518\n",
            "training accuracy = 0.8109279021434517, microF1 = 0.8479001715428632, macroF1 = 0.4980061674610149\n",
            "training accuracy = 0.8106939163982254, microF1 = 0.8477569685171886, macroF1 = 0.4977756373696265\n",
            "training accuracy = 0.8111814300883712, microF1 = 0.8480838678127687, macroF1 = 0.49840564684584204\n",
            "training accuracy = 0.8113008168253169, microF1 = 0.8481741626653958, macroF1 = 0.49975994194637774\n",
            "training accuracy = 0.8108742272346421, microF1 = 0.8479294229920495, macroF1 = 0.4995907151294015\n",
            "training accuracy = 0.8111871945369473, microF1 = 0.8480423977223298, macroF1 = 0.49968835882625134\n",
            "\n",
            "epoch = 9, training_loss = 0.05163291794379143, validation_loss =0.0661825234281648, training_acc = 0.8112109571831324, validation_acc =0.7737571540283632\n",
            "training accuracy = 0.8218377958392942, microF1 = 0.8552459088528247, macroF1 = 0.5080300108068707\n",
            "training accuracy = 0.8196009562972073, microF1 = 0.8546171351193997, macroF1 = 0.5083460402238094\n",
            "training accuracy = 0.8194930510271647, microF1 = 0.8541825845770263, macroF1 = 0.5091487953889564\n",
            "training accuracy = 0.8200011110784663, microF1 = 0.8551631886851763, macroF1 = 0.5088164671324317\n",
            "training accuracy = 0.8193353170358403, microF1 = 0.8547779230537582, macroF1 = 0.5074048495466793\n",
            "training accuracy = 0.8196443053658923, microF1 = 0.8548225105048751, macroF1 = 0.5078896481855587\n",
            "training accuracy = 0.8204512158325379, microF1 = 0.8554588683381735, macroF1 = 0.5062493739929063\n",
            "training accuracy = 0.8185959521826267, microF1 = 0.8541645178729922, macroF1 = 0.5067208434106817\n",
            "training accuracy = 0.8189218450217357, microF1 = 0.8543658613768786, macroF1 = 0.5056921950885835\n",
            "training accuracy = 0.8193541174823946, microF1 = 0.8548777865891639, macroF1 = 0.5063566573548636\n",
            "training accuracy = 0.819126241950455, microF1 = 0.8545510193962533, macroF1 = 0.5058192633178907\n",
            "training accuracy = 0.8185877534846119, microF1 = 0.8541109437757055, macroF1 = 0.5048591857978112\n",
            "training accuracy = 0.817881606981324, microF1 = 0.8536064496555233, macroF1 = 0.5047216693983847\n",
            "training accuracy = 0.8173069274904562, microF1 = 0.8531004701626717, macroF1 = 0.504831790048564\n",
            "\n",
            "epoch = 10, training_loss = 0.050075570716685856, validation_loss =0.06656092232496467, training_acc = 0.8171869210906725, validation_acc =0.772981381044594\n",
            "training accuracy = 0.8234740977252596, microF1 = 0.8580531686591528, macroF1 = 0.51599795313869\n",
            "training accuracy = 0.820587345814817, microF1 = 0.8557456066155205, macroF1 = 0.5122190498524748\n",
            "training accuracy = 0.8211306760818201, microF1 = 0.8560040878264029, macroF1 = 0.5114705838582956\n",
            "training accuracy = 0.8228950976991701, microF1 = 0.8569917009104046, macroF1 = 0.5137970733528362\n",
            "training accuracy = 0.823096589428805, microF1 = 0.8572248236583075, macroF1 = 0.5119087984928851\n",
            "training accuracy = 0.8231503223971569, microF1 = 0.8576596369331106, macroF1 = 0.5125456856433322\n",
            "training accuracy = 0.8232717092868255, microF1 = 0.8577872446891093, macroF1 = 0.5121215425726001\n",
            "training accuracy = 0.8230430202225104, microF1 = 0.857595545325908, macroF1 = 0.5113676901742038\n",
            "training accuracy = 0.8233146889277964, microF1 = 0.8579206410762817, macroF1 = 0.5105051822805795\n",
            "training accuracy = 0.8233656567850869, microF1 = 0.857857412716025, macroF1 = 0.5100504693795199\n",
            "training accuracy = 0.8236196937233179, microF1 = 0.8580889207397036, macroF1 = 0.5096217331149214\n",
            "training accuracy = 0.8239074659564632, microF1 = 0.858429968643376, macroF1 = 0.5086421229546513\n",
            "training accuracy = 0.8241299007477824, microF1 = 0.8585816286575997, macroF1 = 0.5088132068664942\n",
            "training accuracy = 0.8237235574858611, microF1 = 0.8581628982932279, macroF1 = 0.5086895542985787\n",
            "\n",
            "epoch = 11, training_loss = 0.04784301679286965, validation_loss =0.06780828151506246, training_acc = 0.8233766051832789, validation_acc =0.7809294121145984\n",
            "training accuracy = 0.8266922370921677, microF1 = 0.8598515805752933, macroF1 = 0.49852770619267806\n",
            "training accuracy = 0.8258985259852202, microF1 = 0.8600433213775852, macroF1 = 0.507185665810263\n",
            "training accuracy = 0.8282064090393811, microF1 = 0.8622432012102341, macroF1 = 0.5099352056387781\n",
            "training accuracy = 0.8279256429436594, microF1 = 0.8619212756348823, macroF1 = 0.5107965661157708\n",
            "training accuracy = 0.8282591856390218, microF1 = 0.8622920276756357, macroF1 = 0.509501846792534\n",
            "training accuracy = 0.8287343033638908, microF1 = 0.8628110170094532, macroF1 = 0.5114605926506888\n",
            "training accuracy = 0.8280126134431562, microF1 = 0.8618449224993172, macroF1 = 0.5125624426295851\n",
            "training accuracy = 0.8278377112801728, microF1 = 0.861562041494314, macroF1 = 0.5117519155942166\n",
            "training accuracy = 0.8268798834102874, microF1 = 0.8606845548224401, macroF1 = 0.5114379063300941\n",
            "training accuracy = 0.8271452566451146, microF1 = 0.8607041040797646, macroF1 = 0.5116029535168126\n",
            "training accuracy = 0.8269164289749628, microF1 = 0.8605583514890971, macroF1 = 0.5132263520029139\n",
            "training accuracy = 0.8264543879855628, microF1 = 0.8601429030149861, macroF1 = 0.5122534461657536\n",
            "training accuracy = 0.8264864790809487, microF1 = 0.860165252845918, macroF1 = 0.5132581331926166\n",
            "training accuracy = 0.8266790095311507, microF1 = 0.860324860160287, macroF1 = 0.512920029053514\n",
            "\n",
            "epoch = 12, training_loss = 0.04656489610774411, validation_loss =0.06509320652976479, training_acc = 0.826409583308055, validation_acc =0.783727809472076\n",
            "training accuracy = 0.8343234855094851, microF1 = 0.8664351130394672, macroF1 = 0.5144548518492579\n",
            "training accuracy = 0.8343003477443945, microF1 = 0.86718795904971, macroF1 = 0.5219206606250966\n",
            "training accuracy = 0.8346464594862704, microF1 = 0.8672601060636149, macroF1 = 0.518938944802956\n",
            "training accuracy = 0.8337841390445133, microF1 = 0.8666416980756951, macroF1 = 0.5215395862709036\n",
            "training accuracy = 0.8338007692996059, microF1 = 0.8665534270194364, macroF1 = 0.5241049417666676\n",
            "training accuracy = 0.8328384556129173, microF1 = 0.8660251214592036, macroF1 = 0.5205228796494561\n",
            "training accuracy = 0.8315407318619366, microF1 = 0.8648536560207312, macroF1 = 0.5200573939404141\n",
            "training accuracy = 0.8313615256636584, microF1 = 0.864550761713507, macroF1 = 0.5193720188157045\n",
            "training accuracy = 0.8319414113778891, microF1 = 0.8650990587126011, macroF1 = 0.5195658981806759\n",
            "training accuracy = 0.8322153386332566, microF1 = 0.8653316565191408, macroF1 = 0.5178263108145474\n",
            "training accuracy = 0.8321904040387549, microF1 = 0.8653560258057124, macroF1 = 0.5188661790594579\n",
            "training accuracy = 0.8323932951207769, microF1 = 0.8653521797652123, macroF1 = 0.5193909653273715\n",
            "training accuracy = 0.8318133627507394, microF1 = 0.864794532601765, macroF1 = 0.5189470025394786\n",
            "training accuracy = 0.8319869668049347, microF1 = 0.8649152886525369, macroF1 = 0.5198771091424872\n",
            "\n",
            "epoch = 13, training_loss = 0.0451662024591899, validation_loss =0.06617064512882036, training_acc = 0.8322684132105123, validation_acc =0.7716350228656775\n",
            "training accuracy = 0.8395488305764198, microF1 = 0.8714096719076555, macroF1 = 0.5400727871360941\n",
            "training accuracy = 0.8386014664726565, microF1 = 0.8702311290914604, macroF1 = 0.5286081634614982\n",
            "training accuracy = 0.8394732635972834, microF1 = 0.8700965730497457, macroF1 = 0.5258284076683485\n",
            "training accuracy = 0.8391988297449302, microF1 = 0.8703348034881722, macroF1 = 0.5234218564727304\n",
            "training accuracy = 0.8383473840501582, microF1 = 0.8696418072656619, macroF1 = 0.5253379361677375\n",
            "training accuracy = 0.8384775467441002, microF1 = 0.8698289577333131, macroF1 = 0.5251480577928378\n",
            "training accuracy = 0.8372797221672778, microF1 = 0.8688649680026951, macroF1 = 0.5250123185296637\n",
            "training accuracy = 0.8373275939468379, microF1 = 0.8689378949057356, macroF1 = 0.526078438215086\n",
            "training accuracy = 0.8365681799558514, microF1 = 0.8684870282641127, macroF1 = 0.5234906574611026\n",
            "training accuracy = 0.8366630314733363, microF1 = 0.8684416173604946, macroF1 = 0.5224589305917828\n",
            "training accuracy = 0.835823999606499, microF1 = 0.867558748149641, macroF1 = 0.5219073049649323\n",
            "training accuracy = 0.8356589926412813, microF1 = 0.8674095633587231, macroF1 = 0.5227955848275606\n",
            "training accuracy = 0.835443599897618, microF1 = 0.8671487592816685, macroF1 = 0.521497062383643\n",
            "training accuracy = 0.83531447614937, microF1 = 0.8669896371170736, macroF1 = 0.5220981069518972\n",
            "\n",
            "epoch = 14, training_loss = 0.044434269947796756, validation_loss =0.06529110201548055, training_acc = 0.8353089358517947, validation_acc =0.7912603062507391\n",
            "training accuracy = 0.8439873318577801, microF1 = 0.8740660133048973, macroF1 = 0.5237587886285705\n",
            "training accuracy = 0.8445505345729047, microF1 = 0.874185421223572, macroF1 = 0.5198496169189772\n",
            "training accuracy = 0.8431323614183172, microF1 = 0.8728289526972821, macroF1 = 0.5233332821136958\n",
            "training accuracy = 0.8411010253626016, microF1 = 0.8708992735370626, macroF1 = 0.5262301529028068\n",
            "training accuracy = 0.8413827340410851, microF1 = 0.8709933681846249, macroF1 = 0.5276032270204193\n",
            "training accuracy = 0.840898483528634, microF1 = 0.8708884034992067, macroF1 = 0.5302802950010634\n",
            "training accuracy = 0.8410033703437054, microF1 = 0.8712364450000945, macroF1 = 0.5350503734961116\n",
            "training accuracy = 0.8414144396730389, microF1 = 0.87166344250285, macroF1 = 0.5309249943672736\n",
            "training accuracy = 0.8400795527430345, microF1 = 0.870550423193337, macroF1 = 0.5301104316351402\n",
            "training accuracy = 0.8398853788449581, microF1 = 0.8705164799979078, macroF1 = 0.530258181964903\n",
            "training accuracy = 0.8397489933146038, microF1 = 0.8704703177895976, macroF1 = 0.5292652290831268\n",
            "training accuracy = 0.8395996855302823, microF1 = 0.870386060285034, macroF1 = 0.5294355022761373\n",
            "training accuracy = 0.8397311832981096, microF1 = 0.8706135900281259, macroF1 = 0.5314316804853707\n",
            "training accuracy = 0.8403382244823706, microF1 = 0.8710883480663444, macroF1 = 0.5321395293188556\n",
            "\n",
            "epoch = 15, training_loss = 0.04263578627348151, validation_loss =0.0646293616479205, training_acc = 0.8400729974109383, validation_acc =0.7830651371015697\n",
            "training accuracy = 0.8496263476371902, microF1 = 0.8775237912592069, macroF1 = 0.5426631736353897\n",
            "training accuracy = 0.8475130510757988, microF1 = 0.8766354888812626, macroF1 = 0.5382680503830805\n",
            "training accuracy = 0.8471805587107752, microF1 = 0.8764211830027511, macroF1 = 0.5394829539560683\n",
            "training accuracy = 0.8470807349745548, microF1 = 0.8765422711396859, macroF1 = 0.5366019822300859\n",
            "training accuracy = 0.846687294299955, microF1 = 0.876502969991361, macroF1 = 0.5354898473956264\n",
            "training accuracy = 0.8474829982115277, microF1 = 0.8772222931367352, macroF1 = 0.5340772270211935\n",
            "training accuracy = 0.84747216580663, microF1 = 0.877391693827233, macroF1 = 0.5338809980580461\n",
            "training accuracy = 0.8474514878458553, microF1 = 0.8774633282546215, macroF1 = 0.5345442606345887\n",
            "training accuracy = 0.8469127144950149, microF1 = 0.8770426836677919, macroF1 = 0.5351790919059866\n",
            "training accuracy = 0.8465454000760446, microF1 = 0.876562621745054, macroF1 = 0.536561131159198\n",
            "training accuracy = 0.8459395837107606, microF1 = 0.8760080401465536, macroF1 = 0.5367918185512172\n",
            "training accuracy = 0.8460567149747763, microF1 = 0.8760620767429103, macroF1 = 0.535886489607636\n",
            "training accuracy = 0.8459829880775482, microF1 = 0.875974601144283, macroF1 = 0.5360225790619222\n",
            "training accuracy = 0.8459648124056965, microF1 = 0.8759337639531274, macroF1 = 0.5358417286678756\n",
            "\n",
            "epoch = 16, training_loss = 0.041868413020808674, validation_loss =0.0637115747811868, training_acc = 0.8460519286939826, validation_acc =0.7846867709080807\n",
            "training accuracy = 0.8470416285652344, microF1 = 0.8776420873745048, macroF1 = 0.5387749948273898\n",
            "training accuracy = 0.8470802766223732, microF1 = 0.8769045333195977, macroF1 = 0.5401915536569815\n",
            "training accuracy = 0.8457612799696893, microF1 = 0.8751671518986504, macroF1 = 0.5384289167956392\n",
            "training accuracy = 0.8476074443399203, microF1 = 0.8768964609555967, macroF1 = 0.5399936532309699\n",
            "training accuracy = 0.8473480149527574, microF1 = 0.8765061689261289, macroF1 = 0.5453404889450493\n",
            "training accuracy = 0.8471705571617854, microF1 = 0.8761159474881105, macroF1 = 0.5430986348703085\n",
            "training accuracy = 0.848554738402394, microF1 = 0.8772831253107781, macroF1 = 0.5416151743504659\n",
            "training accuracy = 0.8484768697891025, microF1 = 0.8771595686065906, macroF1 = 0.5416449503707568\n",
            "training accuracy = 0.8486835171956986, microF1 = 0.8774645927969663, macroF1 = 0.5387912166590179\n",
            "training accuracy = 0.8495379763192566, microF1 = 0.8782695243574558, macroF1 = 0.537734195012594\n",
            "training accuracy = 0.849325282011835, microF1 = 0.8780358829888885, macroF1 = 0.5388066559451694\n",
            "training accuracy = 0.8483918442495765, microF1 = 0.8772681350882094, macroF1 = 0.5404090890539224\n",
            "training accuracy = 0.8481054655661969, microF1 = 0.8771654041233997, macroF1 = 0.5383156992234415\n",
            "training accuracy = 0.8480461582461106, microF1 = 0.8770715529640968, macroF1 = 0.5394439026954685\n",
            "\n",
            "epoch = 17, training_loss = 0.04058090114767609, validation_loss =0.06504437434919101, training_acc = 0.848383520341304, validation_acc =0.7831926182593727\n",
            "training accuracy = 0.8544423617148705, microF1 = 0.8824990874455088, macroF1 = 0.5436974325364476\n",
            "training accuracy = 0.8553210559483025, microF1 = 0.8835233414067752, macroF1 = 0.5420093632803225\n",
            "training accuracy = 0.8546543201094887, microF1 = 0.8828547641328304, macroF1 = 0.5451001031389207\n",
            "training accuracy = 0.854443555942903, microF1 = 0.8826918944586171, macroF1 = 0.546112173301015\n",
            "training accuracy = 0.8537648013623389, microF1 = 0.8821455965991533, macroF1 = 0.5431292389582518\n",
            "training accuracy = 0.8534558130218248, microF1 = 0.8818101871573993, macroF1 = 0.5429526826537712\n",
            "training accuracy = 0.8519201589982811, microF1 = 0.8807032786482423, macroF1 = 0.5439913411420142\n",
            "training accuracy = 0.8521285764151517, microF1 = 0.8806791547237155, macroF1 = 0.5444288492089502\n",
            "training accuracy = 0.8517104095413439, microF1 = 0.88028243090941, macroF1 = 0.5449798570036587\n",
            "training accuracy = 0.8515379756567713, microF1 = 0.8802198487512616, macroF1 = 0.5431954953349172\n",
            "training accuracy = 0.8512881269385875, microF1 = 0.8800504642438359, macroF1 = 0.543830509653587\n",
            "training accuracy = 0.8512275420781922, microF1 = 0.8799335463415004, macroF1 = 0.5443797785895639\n",
            "training accuracy = 0.8507162869796656, microF1 = 0.8793380317676317, macroF1 = 0.5454703766728805\n",
            "training accuracy = 0.8508898626630462, microF1 = 0.8794231128954847, macroF1 = 0.5445952020059935\n",
            "\n",
            "epoch = 18, training_loss = 0.0398574379493588, validation_loss =0.06575448603666935, training_acc = 0.8509011241780144, validation_acc =0.790192939251653\n",
            "training accuracy = 0.8558296478851077, microF1 = 0.8836648573954387, macroF1 = 0.5353924049083202\n",
            "training accuracy = 0.8564859022996177, microF1 = 0.8845757093888909, macroF1 = 0.5630150916486136\n",
            "training accuracy = 0.8560155429404719, microF1 = 0.8841294452988062, macroF1 = 0.5587779123620403\n",
            "training accuracy = 0.8553767794905489, microF1 = 0.8837393626944887, macroF1 = 0.5546800882588225\n",
            "training accuracy = 0.8555796770277644, microF1 = 0.8839574901927145, macroF1 = 0.5509660878583024\n",
            "training accuracy = 0.8565722464090666, microF1 = 0.8847496525925795, macroF1 = 0.5481025136267431\n",
            "training accuracy = 0.8568024482558331, microF1 = 0.8849299017521022, macroF1 = 0.5474943079216137\n",
            "training accuracy = 0.8561886275508717, microF1 = 0.8842817970616903, macroF1 = 0.5455182932544869\n",
            "training accuracy = 0.8566129594230217, microF1 = 0.8845403807989154, macroF1 = 0.5466467326382759\n",
            "training accuracy = 0.856094122043706, microF1 = 0.8841035913796399, macroF1 = 0.5477497927693389\n",
            "training accuracy = 0.856220948839335, microF1 = 0.8842062039726205, macroF1 = 0.5483112860652247\n",
            "training accuracy = 0.8556529863620796, microF1 = 0.8836140952286928, macroF1 = 0.5480343350136896\n",
            "training accuracy = 0.8556741530695303, microF1 = 0.8836677499227198, macroF1 = 0.5493312276019521\n",
            "training accuracy = 0.8555421636158476, microF1 = 0.8835512172104966, macroF1 = 0.5479733096691629\n",
            "\n",
            "epoch = 19, training_loss = 0.038772398260297235, validation_loss =0.0645290974181952, training_acc = 0.8554346590228747, validation_acc =0.7861416506718806\n",
            "training accuracy = 0.8601067931798574, microF1 = 0.8878470687239461, macroF1 = 0.5653681910096137\n",
            "training accuracy = 0.8599940124779933, microF1 = 0.8879773690489406, macroF1 = 0.558712311789629\n",
            "training accuracy = 0.8615600865577415, microF1 = 0.8889516222950407, macroF1 = 0.5568959545014281\n",
            "training accuracy = 0.8612899950438802, microF1 = 0.8886352742464414, macroF1 = 0.559160618345781\n",
            "training accuracy = 0.8609217002134598, microF1 = 0.8883490009231259, macroF1 = 0.5605732603880963\n",
            "training accuracy = 0.8601558082433407, microF1 = 0.8875629046154947, macroF1 = 0.5577038581909086\n",
            "training accuracy = 0.860405990340715, microF1 = 0.8874624520368224, macroF1 = 0.5552343191405651\n",
            "training accuracy = 0.8606522216903342, microF1 = 0.8877300963932363, macroF1 = 0.5541044105268367\n",
            "training accuracy = 0.8606758537144462, microF1 = 0.8877952178358051, macroF1 = 0.5537991029152969\n",
            "training accuracy = 0.8600054108112575, microF1 = 0.8870834512665872, macroF1 = 0.5555288933625477\n",
            "training accuracy = 0.8591187623487837, microF1 = 0.8862555791427856, macroF1 = 0.5553830128302127\n",
            "training accuracy = 0.859200226747667, microF1 = 0.8863852824360504, macroF1 = 0.5565363627797604\n",
            "training accuracy = 0.8591619060598052, microF1 = 0.8864595295652652, macroF1 = 0.5568340164896904\n",
            "training accuracy = 0.8593791283828008, microF1 = 0.8865626454035904, macroF1 = 0.5559975408617149\n",
            "\n",
            "epoch = 20, training_loss = 0.03765835395383671, validation_loss =0.06574046197011299, training_acc = 0.8592332394128669, validation_acc =0.7917146060613796\n",
            "training accuracy = 0.8615228311999479, microF1 = 0.8899400451656903, macroF1 = 0.5532654571124136\n",
            "training accuracy = 0.8637050279119989, microF1 = 0.8910961828124583, macroF1 = 0.5471838297493028\n",
            "training accuracy = 0.8637383018555436, microF1 = 0.890897720335233, macroF1 = 0.5494656339200037\n",
            "training accuracy = 0.8627120764615314, microF1 = 0.8899404854796213, macroF1 = 0.5475685800759946\n",
            "training accuracy = 0.8617988975447768, microF1 = 0.8888211003172711, macroF1 = 0.5527836526134311\n",
            "training accuracy = 0.8610273835721378, microF1 = 0.8880641077070512, macroF1 = 0.5516422958311277\n",
            "training accuracy = 0.8614932347161625, microF1 = 0.8882457602036258, macroF1 = 0.5501743295806644\n",
            "training accuracy = 0.8620359586876304, microF1 = 0.8889362365895533, macroF1 = 0.5506557080395083\n",
            "training accuracy = 0.8616717609140607, microF1 = 0.8886395634525542, macroF1 = 0.5498941044730942\n",
            "training accuracy = 0.861928988430884, microF1 = 0.8887862712608817, macroF1 = 0.5516311726940832\n",
            "training accuracy = 0.861379784424643, microF1 = 0.888143201691021, macroF1 = 0.551407720962027\n",
            "training accuracy = 0.8617884899355466, microF1 = 0.8884012640601757, macroF1 = 0.5514550686467662\n",
            "training accuracy = 0.8619867419714019, microF1 = 0.8886576377173826, macroF1 = 0.5535938180997118\n",
            "training accuracy = 0.8612454956335379, microF1 = 0.8879066753364634, macroF1 = 0.5531817355631534\n",
            "\n",
            "epoch = 21, training_loss = 0.036899364377368765, validation_loss =0.06578631917994048, training_acc = 0.8614244331691612, validation_acc =0.7838675420620477\n",
            "training accuracy = 0.8606461378491408, microF1 = 0.887766477270199, macroF1 = 0.5530220873931934\n",
            "training accuracy = 0.861999119355975, microF1 = 0.8884734167073096, macroF1 = 0.5654135494565649\n",
            "training accuracy = 0.8654219033597688, microF1 = 0.8915504254998492, macroF1 = 0.5666467186692651\n",
            "training accuracy = 0.866014507543887, microF1 = 0.892054631526153, macroF1 = 0.5663803590638168\n",
            "training accuracy = 0.8661381869215876, microF1 = 0.8918453919812084, macroF1 = 0.5677360476826508\n",
            "training accuracy = 0.8650621768812929, microF1 = 0.8909659558354723, macroF1 = 0.5638075400058958\n",
            "training accuracy = 0.8647215928452752, microF1 = 0.8907538677895857, macroF1 = 0.5632455888797098\n",
            "training accuracy = 0.8642042645608341, microF1 = 0.8901716227334555, macroF1 = 0.5609670611173807\n",
            "training accuracy = 0.864140420661547, microF1 = 0.8899371449986523, macroF1 = 0.5612737043424518\n",
            "training accuracy = 0.8636511661160544, microF1 = 0.88959435969656, macroF1 = 0.5624711398537203\n",
            "training accuracy = 0.8640585778354478, microF1 = 0.8899855597310717, macroF1 = 0.5639624694030672\n",
            "training accuracy = 0.8640638920817979, microF1 = 0.8899528155780887, macroF1 = 0.5625228469692459\n",
            "training accuracy = 0.8634099052971888, microF1 = 0.8895229328352668, macroF1 = 0.561794206629771\n",
            "training accuracy = 0.8631688915990687, microF1 = 0.8893474249892773, macroF1 = 0.5612244982360113\n",
            "\n",
            "epoch = 22, training_loss = 0.036439638994506134, validation_loss =0.06518082912127997, training_acc = 0.8631111040740469, validation_acc =0.7852529534447659\n",
            "training accuracy = 0.862856378272126, microF1 = 0.8901022677158188, macroF1 = 0.558276585665701\n",
            "training accuracy = 0.8643849023407804, microF1 = 0.8915081483683989, macroF1 = 0.552912732598659\n",
            "training accuracy = 0.864918038287572, microF1 = 0.8918410876217431, macroF1 = 0.5525352787645118\n",
            "training accuracy = 0.8678213123717863, microF1 = 0.894012228225412, macroF1 = 0.5595660041287368\n",
            "training accuracy = 0.8683189265967846, microF1 = 0.8942776018944075, macroF1 = 0.5628269748747472\n",
            "training accuracy = 0.8684477192470135, microF1 = 0.8943390878763564, macroF1 = 0.5599490542309571\n",
            "training accuracy = 0.8677800541040827, microF1 = 0.8936707506289734, macroF1 = 0.559315547059863\n",
            "training accuracy = 0.8670772910776392, microF1 = 0.8928545481341961, macroF1 = 0.5595797651479699\n",
            "training accuracy = 0.8670363715878352, microF1 = 0.8927559896382385, macroF1 = 0.5604989077618988\n",
            "training accuracy = 0.8670117711793803, microF1 = 0.8927122364211818, macroF1 = 0.5608816924636696\n",
            "training accuracy = 0.8664346265375958, microF1 = 0.8921791474238471, macroF1 = 0.5616138135555745\n",
            "training accuracy = 0.8668488768924546, microF1 = 0.8923826102222282, macroF1 = 0.560832404489993\n",
            "training accuracy = 0.866716960593793, microF1 = 0.8921533654417749, macroF1 = 0.5618080663197883\n",
            "training accuracy = 0.8666393418008107, microF1 = 0.8920752989021762, macroF1 = 0.5629465399721444\n",
            "\n",
            "epoch = 23, training_loss = 0.03519053798156096, validation_loss =0.06640568671306384, training_acc = 0.8668358633921233, validation_acc =0.793012449337538\n",
            "training accuracy = 0.873008391814093, microF1 = 0.898817420162622, macroF1 = 0.5580923518268142\n",
            "training accuracy = 0.8754975909183553, microF1 = 0.9004576800762358, macroF1 = 0.5700810223429505\n",
            "training accuracy = 0.873049210635291, microF1 = 0.8977955395652852, macroF1 = 0.5716210407712825\n",
            "training accuracy = 0.8727577458328247, microF1 = 0.8975046992713047, macroF1 = 0.5686814723564593\n",
            "training accuracy = 0.8720896114187914, microF1 = 0.8969566319504643, macroF1 = 0.5674548558141208\n",
            "training accuracy = 0.8704143091218408, microF1 = 0.8955541177862987, macroF1 = 0.563976664053608\n",
            "training accuracy = 0.8696725138115526, microF1 = 0.8948751605048533, macroF1 = 0.5630464362819176\n",
            "training accuracy = 0.8693755455318607, microF1 = 0.894416786306261, macroF1 = 0.5631481016004678\n",
            "training accuracy = 0.8687488521249547, microF1 = 0.8937848869014773, macroF1 = 0.565573955086862\n",
            "training accuracy = 0.8688740561984776, microF1 = 0.8938657815352408, macroF1 = 0.5647316985352416\n",
            "training accuracy = 0.8685371923473159, microF1 = 0.893559554543977, macroF1 = 0.565658419868778\n",
            "training accuracy = 0.8682963906025729, microF1 = 0.8933408198827995, macroF1 = 0.5648519007411326\n",
            "training accuracy = 0.8683704762228788, microF1 = 0.8932859755673502, macroF1 = 0.5645286347490907\n",
            "training accuracy = 0.8684341871229885, microF1 = 0.8934215797992239, macroF1 = 0.5635486388541545\n",
            "\n",
            "epoch = 24, training_loss = 0.03450144067585878, validation_loss =0.06666833123902685, training_acc = 0.8685043469540052, validation_acc =0.7871092885631895\n",
            "training accuracy = 0.8723397374795266, microF1 = 0.8957235263582338, macroF1 = 0.5735612668846792\n",
            "training accuracy = 0.8741132773274662, microF1 = 0.897476728868306, macroF1 = 0.5697225122458973\n",
            "training accuracy = 0.8762018108004539, microF1 = 0.8997141106836816, macroF1 = 0.5680558802191014\n",
            "training accuracy = 0.875942965420518, microF1 = 0.8997566057101186, macroF1 = 0.5675166441254945\n",
            "training accuracy = 0.8751071474516701, microF1 = 0.8988197077620911, macroF1 = 0.5668408167484716\n",
            "training accuracy = 0.8742423004240659, microF1 = 0.8978671676646186, macroF1 = 0.5678094406018497\n",
            "training accuracy = 0.8740793792270524, microF1 = 0.8978069472439164, macroF1 = 0.569379163190375\n",
            "training accuracy = 0.87395385807261, microF1 = 0.8978432218346909, macroF1 = 0.5694967970984489\n",
            "training accuracy = 0.8740904220635264, microF1 = 0.8980727129458459, macroF1 = 0.5685980640138139\n",
            "training accuracy = 0.8737176818110737, microF1 = 0.8978276737726324, macroF1 = 0.5693649896150792\n",
            "training accuracy = 0.8736696714827054, microF1 = 0.8977039082896957, macroF1 = 0.5672109932102083\n",
            "training accuracy = 0.8732842172714399, microF1 = 0.8973453300243684, macroF1 = 0.5673181957803713\n",
            "training accuracy = 0.8731987965122383, microF1 = 0.8972114236912224, macroF1 = 0.5664687516078379\n",
            "training accuracy = 0.8726306781077781, microF1 = 0.8967267490870486, macroF1 = 0.5672539794532305\n",
            "\n",
            "epoch = 25, training_loss = 0.03372327493074833, validation_loss =0.06497450401411228, training_acc = 0.8724576121720369, validation_acc =0.7932304946833723\n",
            "training accuracy = 0.8706809391407178, microF1 = 0.8949527413866402, macroF1 = 0.5803789677302837\n",
            "training accuracy = 0.8771434450310399, microF1 = 0.9004231101911839, macroF1 = 0.5936934392739389\n",
            "training accuracy = 0.8780871852729176, microF1 = 0.9014433614294621, macroF1 = 0.583086528167452\n",
            "training accuracy = 0.8779003438919368, microF1 = 0.9014502583251653, macroF1 = 0.5843864149071203\n",
            "training accuracy = 0.8781592964273105, microF1 = 0.9015280804070451, macroF1 = 0.5793215886429167\n",
            "training accuracy = 0.878389360068895, microF1 = 0.90153439492837, macroF1 = 0.5773818258678597\n",
            "training accuracy = 0.8769167059890459, microF1 = 0.9003804208172262, macroF1 = 0.5755324434690322\n",
            "training accuracy = 0.8769838978496003, microF1 = 0.9003745288479955, macroF1 = 0.5744042404255824\n",
            "training accuracy = 0.8758769952952514, microF1 = 0.8993538930090749, macroF1 = 0.5723345915635389\n",
            "training accuracy = 0.8752176447344279, microF1 = 0.8987971656180145, macroF1 = 0.5728511760468342\n",
            "training accuracy = 0.8751983756595961, microF1 = 0.8987723981983128, macroF1 = 0.5734444309988719\n",
            "training accuracy = 0.8744228945245607, microF1 = 0.898162815380224, macroF1 = 0.5726138082992934\n",
            "training accuracy = 0.8745640497492746, microF1 = 0.8982548956613063, macroF1 = 0.5742254062762501\n",
            "training accuracy = 0.8748050247450633, microF1 = 0.8984057984831818, macroF1 = 0.574352731429698\n",
            "\n",
            "epoch = 26, training_loss = 0.03324858481992561, validation_loss =0.06584608854399514, training_acc = 0.8748401568220723, validation_acc =0.7921219400978312\n",
            "training accuracy = 0.8779172132264224, microF1 = 0.9006807746602047, macroF1 = 0.5474383942222095\n",
            "training accuracy = 0.8734531577395719, microF1 = 0.8961876590134238, macroF1 = 0.5509457843602776\n",
            "training accuracy = 0.8753938268944003, microF1 = 0.8986581742837393, macroF1 = 0.5627768448132904\n",
            "training accuracy = 0.8770377268760967, microF1 = 0.9000758257426956, macroF1 = 0.5772422840021808\n",
            "training accuracy = 0.8772567881143107, microF1 = 0.9004021119969515, macroF1 = 0.5787972320160228\n",
            "training accuracy = 0.8760265897478202, microF1 = 0.8994370593096904, macroF1 = 0.5768579707493428\n",
            "training accuracy = 0.8757733373027028, microF1 = 0.8992233698664535, macroF1 = 0.5734516097381532\n",
            "training accuracy = 0.8767605472848129, microF1 = 0.9001469647473666, macroF1 = 0.5735373333922791\n",
            "training accuracy = 0.8771730874494827, microF1 = 0.9004408727718305, macroF1 = 0.571229754206397\n",
            "training accuracy = 0.8771663104570521, microF1 = 0.900376361581451, macroF1 = 0.574964830017934\n",
            "training accuracy = 0.8769212884133885, microF1 = 0.9001664246239376, macroF1 = 0.5731818616485456\n",
            "training accuracy = 0.876883179815205, microF1 = 0.9000941603002344, macroF1 = 0.5728587803748795\n",
            "training accuracy = 0.8766065801342703, microF1 = 0.8997809419569238, macroF1 = 0.5731010904200141\n",
            "training accuracy = 0.8764538312601983, microF1 = 0.8995993804987218, macroF1 = 0.5710158041912299\n",
            "\n",
            "epoch = 27, training_loss = 0.032501018945370955, validation_loss =0.06664326049617886, training_acc = 0.8763643847160688, validation_acc =0.7872771030873266\n",
            "training accuracy = 0.8815246169707687, microF1 = 0.9033145433139228, macroF1 = 0.5723041946014444\n",
            "training accuracy = 0.8799070724194917, microF1 = 0.9018911003064582, macroF1 = 0.5750100489094401\n",
            "training accuracy = 0.8795876444499795, microF1 = 0.9019857241756045, macroF1 = 0.5673582812454165\n",
            "training accuracy = 0.8781084891235302, microF1 = 0.9010115619606589, macroF1 = 0.5735692111976546\n",
            "training accuracy = 0.8779157482388301, microF1 = 0.9009176177141853, macroF1 = 0.574492285136304\n",
            "training accuracy = 0.8782237811020444, microF1 = 0.9008750804837056, macroF1 = 0.5735068728854661\n",
            "training accuracy = 0.8786392704844638, microF1 = 0.9010403075694411, macroF1 = 0.5719132057423241\n",
            "training accuracy = 0.8796739164059836, microF1 = 0.9019508676608364, macroF1 = 0.5726700307160121\n",
            "training accuracy = 0.8795090572807689, microF1 = 0.9019262675807601, macroF1 = 0.5731872362357054\n",
            "training accuracy = 0.8794958534138707, microF1 = 0.9019311627766404, macroF1 = 0.575057489795547\n",
            "training accuracy = 0.8792806425958588, microF1 = 0.9017359071501435, macroF1 = 0.5746990843932767\n",
            "training accuracy = 0.8792111708969793, microF1 = 0.9017322383441885, macroF1 = 0.5742256496049188\n",
            "training accuracy = 0.8787947855822176, microF1 = 0.9014773406954038, macroF1 = 0.5743394470328044\n",
            "training accuracy = 0.8787451596996018, microF1 = 0.9014633812578898, macroF1 = 0.574161402615393\n",
            "\n",
            "epoch = 28, training_loss = 0.03171133479148252, validation_loss =0.06635071425554678, training_acc = 0.8780768967790409, validation_acc =0.7958541459641193\n",
            "training accuracy = 0.8821537760638778, microF1 = 0.903907270069895, macroF1 = 0.5867033560456242\n",
            "training accuracy = 0.8851711462190492, microF1 = 0.9067191564358299, macroF1 = 0.5898058561258744\n",
            "training accuracy = 0.8840111584307421, microF1 = 0.9054889842385647, macroF1 = 0.5930217918954249\n",
            "training accuracy = 0.8850282280880319, microF1 = 0.9064958412434604, macroF1 = 0.5872801980816224\n",
            "training accuracy = 0.8844862390004118, microF1 = 0.9065242230306723, macroF1 = 0.5848248634941581\n",
            "training accuracy = 0.884860994833818, microF1 = 0.9066962067923295, macroF1 = 0.5855119204207454\n",
            "training accuracy = 0.8838864605330788, microF1 = 0.9057863035751683, macroF1 = 0.5847485164957577\n",
            "training accuracy = 0.882749388948064, microF1 = 0.9047111358660016, macroF1 = 0.5829309213632876\n",
            "training accuracy = 0.882694871301484, microF1 = 0.9048047097947355, macroF1 = 0.5811456182180926\n",
            "training accuracy = 0.8818766479004022, microF1 = 0.9039453703901424, macroF1 = 0.5801707267314165\n",
            "training accuracy = 0.8816525014131675, microF1 = 0.9038002626703945, macroF1 = 0.5807935718397477\n",
            "training accuracy = 0.8811893393940534, microF1 = 0.9033806424312842, macroF1 = 0.5820664269720359\n",
            "training accuracy = 0.8813184533783956, microF1 = 0.9035178913271734, macroF1 = 0.5810771165944024\n",
            "training accuracy = 0.8815741095928955, microF1 = 0.9036982461074118, macroF1 = 0.5825194978683329\n",
            "\n",
            "epoch = 29, training_loss = 0.031137036601292717, validation_loss =0.06597947271675178, training_acc = 0.8816027563202704, validation_acc =0.7922620401910739\n",
            "training accuracy = 0.8826876547432811, microF1 = 0.9043677660801088, macroF1 = 0.5609021793396404\n",
            "training accuracy = 0.884778228117049, microF1 = 0.9059544797025768, macroF1 = 0.56873214222291\n",
            "training accuracy = 0.883888858392917, microF1 = 0.9056018667962781, macroF1 = 0.5675531316625473\n",
            "training accuracy = 0.8845899383842567, microF1 = 0.9061230404800082, macroF1 = 0.5718478626922779\n",
            "training accuracy = 0.8849775261437488, microF1 = 0.9068906879095949, macroF1 = 0.5772312902322718\n",
            "training accuracy = 0.8854279494294522, microF1 = 0.907281760913138, macroF1 = 0.5823407356692746\n",
            "training accuracy = 0.8853932972358793, microF1 = 0.9072156166575975, macroF1 = 0.5852318475217647\n",
            "training accuracy = 0.8852196280820043, microF1 = 0.9070591920065759, macroF1 = 0.5861805075791651\n",
            "training accuracy = 0.885337255302181, microF1 = 0.9070998052561251, macroF1 = 0.5872907136641262\n",
            "training accuracy = 0.8851347757015903, microF1 = 0.9068855346438536, macroF1 = 0.5892401338913437\n",
            "training accuracy = 0.8844338198137006, microF1 = 0.9062783165987763, macroF1 = 0.5868635594828981\n",
            "training accuracy = 0.8839206003251991, microF1 = 0.905830143773732, macroF1 = 0.5845352365666104\n",
            "training accuracy = 0.8836186121465022, microF1 = 0.9054606012873272, macroF1 = 0.5843148833029361\n",
            "training accuracy = 0.8839440209559635, microF1 = 0.9057622921417459, macroF1 = 0.5850979265656143\n",
            "\n",
            "epoch = 30, training_loss = 0.0303925085857613, validation_loss =0.0684081284502118, training_acc = 0.8837778191130558, validation_acc =0.7913161562219447\n",
            "training accuracy = 0.8885890257650517, microF1 = 0.9110189979464204, macroF1 = 0.5953415138950786\n",
            "training accuracy = 0.8873193739380434, microF1 = 0.9095589223196513, macroF1 = 0.6132314673777934\n",
            "training accuracy = 0.8868605098623494, microF1 = 0.9084253990153666, macroF1 = 0.6034543883217137\n",
            "training accuracy = 0.8872799913931497, microF1 = 0.9092005765538291, macroF1 = 0.6025135668145216\n",
            "training accuracy = 0.8878444167096824, microF1 = 0.9095572162777348, macroF1 = 0.5962154400847779\n",
            "training accuracy = 0.8878131325030526, microF1 = 0.9092851088875132, macroF1 = 0.5938458819267797\n",
            "training accuracy = 0.8869089169662356, microF1 = 0.9083073809983506, macroF1 = 0.5921379668256043\n",
            "training accuracy = 0.8866589859310668, microF1 = 0.9080091881960144, macroF1 = 0.5913081302398255\n",
            "training accuracy = 0.886586576844408, microF1 = 0.9080208954147113, macroF1 = 0.5903802032137477\n",
            "training accuracy = 0.8868862086734938, microF1 = 0.9082834448847741, macroF1 = 0.5908253551845286\n",
            "training accuracy = 0.886323581519059, microF1 = 0.9077334992760296, macroF1 = 0.589489296292262\n",
            "training accuracy = 0.8863135771992591, microF1 = 0.9077193176128799, macroF1 = 0.5878433611121413\n",
            "training accuracy = 0.8866256462837734, microF1 = 0.9081579415616139, macroF1 = 0.588113340206464\n",
            "training accuracy = 0.8864058021605901, microF1 = 0.9078690922857836, macroF1 = 0.5880419309439963\n",
            "\n",
            "epoch = 31, training_loss = 0.02964772398605994, validation_loss =0.0685161274963433, training_acc = 0.8862088714694171, validation_acc =0.7868405722203785\n",
            "training accuracy = 0.8852559370600884, microF1 = 0.9074736735559331, macroF1 = 0.6086256068071427\n",
            "training accuracy = 0.8878132190836131, microF1 = 0.909064350226273, macroF1 = 0.5991968743820554\n",
            "training accuracy = 0.8900910864839328, microF1 = 0.9111283985011105, macroF1 = 0.6036486252606823\n",
            "training accuracy = 0.8880992054902114, microF1 = 0.9093632968578995, macroF1 = 0.5950341736189737\n",
            "training accuracy = 0.8884713246192804, microF1 = 0.9095377980586864, macroF1 = 0.5955325706607667\n",
            "training accuracy = 0.8874466597138635, microF1 = 0.9084779731968855, macroF1 = 0.5971418114708259\n",
            "training accuracy = 0.8875737488854165, microF1 = 0.9085555749797258, macroF1 = 0.5960055512880154\n",
            "training accuracy = 0.8872717501002282, microF1 = 0.9084334753062262, macroF1 = 0.5948361496745169\n",
            "training accuracy = 0.8875904472720204, microF1 = 0.9087506337371215, macroF1 = 0.5941839015055809\n",
            "training accuracy = 0.8881619055613285, microF1 = 0.9092216408499598, macroF1 = 0.5951307336190865\n",
            "training accuracy = 0.8882004034303835, microF1 = 0.9092355693856067, macroF1 = 0.5959586245072545\n",
            "training accuracy = 0.8882106015115029, microF1 = 0.9091549273497602, macroF1 = 0.5953086058238483\n",
            "training accuracy = 0.8884635790613465, microF1 = 0.9093929835013347, macroF1 = 0.594782656169034\n",
            "training accuracy = 0.8881317917266114, microF1 = 0.9090276120416337, macroF1 = 0.5928659557900919\n",
            "\n",
            "epoch = 32, training_loss = 0.02940579493533295, validation_loss =0.06852190384698897, training_acc = 0.8881840544946631, validation_acc =0.7947666132727955\n",
            "training accuracy = 0.8928942711715125, microF1 = 0.913140086169244, macroF1 = 0.5948552845115087\n",
            "training accuracy = 0.8936170202412009, microF1 = 0.9135954147201921, macroF1 = 0.5900030084124351\n",
            "training accuracy = 0.8951419649297553, microF1 = 0.915041551369075, macroF1 = 0.5883713853730578\n",
            "training accuracy = 0.8929411343503741, microF1 = 0.9130252914233662, macroF1 = 0.5938926947909773\n",
            "training accuracy = 0.8935050995834535, microF1 = 0.9136341686424532, macroF1 = 0.586397827921157\n",
            "training accuracy = 0.892296478080147, microF1 = 0.9127991886334671, macroF1 = 0.5834742338623004\n",
            "training accuracy = 0.8922617585445831, microF1 = 0.912787054625484, macroF1 = 0.5867199742127694\n",
            "training accuracy = 0.8914332611651786, microF1 = 0.9120364973006286, macroF1 = 0.5872291414851085\n",
            "training accuracy = 0.8918757683070525, microF1 = 0.9123715997476272, macroF1 = 0.591147414559764\n",
            "training accuracy = 0.8919350158201766, microF1 = 0.912451652549569, macroF1 = 0.5910277821625609\n",
            "training accuracy = 0.8919314941228074, microF1 = 0.9124890996680649, macroF1 = 0.5919368105216368\n",
            "training accuracy = 0.8911345701996607, microF1 = 0.9117917947074732, macroF1 = 0.5915153508025345\n",
            "training accuracy = 0.8909123974187362, microF1 = 0.9115738626792185, macroF1 = 0.5921692370000857\n",
            "training accuracy = 0.8905799523522628, microF1 = 0.9112003621129698, macroF1 = 0.5938269456989639\n",
            "\n",
            "epoch = 33, training_loss = 0.028757264427968728, validation_loss =0.07006044221139446, training_acc = 0.8905892574124148, validation_acc =0.7910483775661818\n",
            "training accuracy = 0.8933521670245093, microF1 = 0.9115968366153634, macroF1 = 0.6101908174275581\n",
            "training accuracy = 0.8926772926293677, microF1 = 0.9116814254370503, macroF1 = 0.611589211450294\n",
            "training accuracy = 0.892520449360806, microF1 = 0.9118963281231031, macroF1 = 0.6009911024964303\n",
            "training accuracy = 0.8927439709620903, microF1 = 0.9117196960483197, macroF1 = 0.5949779990997023\n",
            "training accuracy = 0.892031790382977, microF1 = 0.9115998937861848, macroF1 = 0.5945497191151584\n",
            "training accuracy = 0.8918399379499424, microF1 = 0.9115456507704254, macroF1 = 0.5950971947646028\n",
            "training accuracy = 0.8923109620958949, microF1 = 0.912138574163035, macroF1 = 0.5936094730382522\n",
            "training accuracy = 0.8914511546213847, microF1 = 0.9114401407196863, macroF1 = 0.5927203904723054\n",
            "training accuracy = 0.8915050673920897, microF1 = 0.9115652349256493, macroF1 = 0.5921487807514237\n",
            "training accuracy = 0.8913751876030224, microF1 = 0.9114046843564925, macroF1 = 0.5921184726327267\n",
            "training accuracy = 0.8912620795571267, microF1 = 0.9114208601970182, macroF1 = 0.591203931015224\n",
            "training accuracy = 0.8908287982145262, microF1 = 0.911157391750271, macroF1 = 0.5935312468723063\n",
            "training accuracy = 0.8909454784686963, microF1 = 0.911254677535942, macroF1 = 0.5959627708256948\n",
            "training accuracy = 0.8910765707880719, microF1 = 0.9113037372081646, macroF1 = 0.5950735773816413\n",
            "\n",
            "epoch = 34, training_loss = 0.028714783105653587, validation_loss =0.06900976901662718, training_acc = 0.8912740945722359, validation_acc =0.789709094755176\n",
            "training accuracy = 0.8965189146749556, microF1 = 0.9157631201733734, macroF1 = 0.5936559111353441\n",
            "training accuracy = 0.8992855806791678, microF1 = 0.9182994021232936, macroF1 = 0.5883921856585318\n",
            "training accuracy = 0.8980674587306843, microF1 = 0.9177756820801527, macroF1 = 0.5982332265452047\n",
            "training accuracy = 0.898569836231534, microF1 = 0.9182051679973121, macroF1 = 0.6031064653040602\n",
            "training accuracy = 0.8983410282395834, microF1 = 0.9177661521773122, macroF1 = 0.6064513422506951\n",
            "training accuracy = 0.898370673805069, microF1 = 0.9178405751408857, macroF1 = 0.604307009731013\n",
            "training accuracy = 0.8993539219514258, microF1 = 0.9185714364609319, macroF1 = 0.6033532479077239\n",
            "training accuracy = 0.8986825894825823, microF1 = 0.9178225904418789, macroF1 = 0.6067897334125273\n",
            "training accuracy = 0.8989057933292353, microF1 = 0.9178679611341921, macroF1 = 0.6049778769683233\n",
            "training accuracy = 0.8984974305538174, microF1 = 0.9174915498403861, macroF1 = 0.6053943387669255\n",
            "training accuracy = 0.8983482967926534, microF1 = 0.917361082883764, macroF1 = 0.6029317724535095\n",
            "training accuracy = 0.8978159452702463, microF1 = 0.9169712854610121, macroF1 = 0.600498306966393\n",
            "training accuracy = 0.8985827202888146, microF1 = 0.9177453956985072, macroF1 = 0.6013685045505193\n",
            "training accuracy = 0.8981360114400664, microF1 = 0.9173767533080555, macroF1 = 0.6011352547406265\n",
            "\n",
            "epoch = 35, training_loss = 0.026670378213588315, validation_loss =0.06935338656773272, training_acc = 0.8979773132849056, validation_acc =0.7968490515200489\n",
            "training accuracy = 0.8994720383107614, microF1 = 0.9183889811472016, macroF1 = 0.6045129587338165\n",
            "training accuracy = 0.8981519184045279, microF1 = 0.9169284846788288, macroF1 = 0.6054218205138988\n",
            "training accuracy = 0.8982645948670053, microF1 = 0.9172650495814206, macroF1 = 0.6119994706281888\n",
            "training accuracy = 0.8981563688761836, microF1 = 0.9171239835686197, macroF1 = 0.6206089178165227\n",
            "training accuracy = 0.8980763728089949, microF1 = 0.9169060711376067, macroF1 = 0.6232782126675563\n",
            "training accuracy = 0.8984833289542576, microF1 = 0.917168027838732, macroF1 = 0.6187399430104474\n",
            "training accuracy = 0.8986398731955334, microF1 = 0.9173659826161693, macroF1 = 0.6179604654358328\n",
            "training accuracy = 0.8991152573946991, microF1 = 0.9177680695705898, macroF1 = 0.6185814369697012\n",
            "training accuracy = 0.8989923207081181, microF1 = 0.9177822610004106, macroF1 = 0.6173060598192788\n",
            "training accuracy = 0.8989752768520916, microF1 = 0.9176380965804516, macroF1 = 0.6182808779471709\n",
            "training accuracy = 0.8989730991941421, microF1 = 0.9175373403622719, macroF1 = 0.6145034849800804\n",
            "training accuracy = 0.8990628739322912, microF1 = 0.9176338835875797, macroF1 = 0.614327474791136\n",
            "training accuracy = 0.8990305210044379, microF1 = 0.9176161574861471, macroF1 = 0.6121382030309576\n",
            "training accuracy = 0.8991282325405925, microF1 = 0.9176723667122192, macroF1 = 0.6103853193461504\n",
            "\n",
            "epoch = 36, training_loss = 0.026192774279267108, validation_loss =0.06911788058956873, training_acc = 0.8994439430283623, validation_acc =0.7909521932304812\n",
            "training accuracy = 0.9023134699225794, microF1 = 0.9200709287985115, macroF1 = 0.6035855147680546\n",
            "training accuracy = 0.901286110939296, microF1 = 0.9193539956823692, macroF1 = 0.5809044444329572\n",
            "training accuracy = 0.9008556198160138, microF1 = 0.9185525260256241, macroF1 = 0.5890637974073469\n",
            "training accuracy = 0.9015445922220917, microF1 = 0.9196393948180664, macroF1 = 0.5924405275971691\n",
            "training accuracy = 0.9011327031422528, microF1 = 0.9192466722149432, macroF1 = 0.5936090135530036\n",
            "training accuracy = 0.9015841587111516, microF1 = 0.9196468614778567, macroF1 = 0.5978377714599659\n",
            "training accuracy = 0.9010331205965554, microF1 = 0.919075950344546, macroF1 = 0.601318032158331\n",
            "training accuracy = 0.9011579202235949, microF1 = 0.9192477768713325, macroF1 = 0.6046339154633622\n",
            "training accuracy = 0.9009963246222373, microF1 = 0.9192734032848174, macroF1 = 0.601905666630842\n",
            "training accuracy = 0.9009556411241261, microF1 = 0.9193601205001776, macroF1 = 0.601782299286522\n",
            "training accuracy = 0.9005086220647889, microF1 = 0.9190898004023912, macroF1 = 0.6011292852593102\n",
            "training accuracy = 0.9005845911096856, microF1 = 0.9191297092894221, macroF1 = 0.6028989709154001\n",
            "training accuracy = 0.9006495860696508, microF1 = 0.9191469200725366, macroF1 = 0.6034020263054812\n",
            "training accuracy = 0.9007291977163282, microF1 = 0.9191661967573449, macroF1 = 0.6041379865831035\n",
            "\n",
            "epoch = 37, training_loss = 0.02584749702172181, validation_loss =0.07056543327023074, training_acc = 0.9007806244154569, validation_acc =0.7940512803837985\n",
            "training accuracy = 0.8975780535351606, microF1 = 0.9163976174230907, macroF1 = 0.6052438698203015\n",
            "training accuracy = 0.8978319217516089, microF1 = 0.9162737927045247, macroF1 = 0.5974066516386838\n",
            "training accuracy = 0.8981334854410359, microF1 = 0.9167656352230352, macroF1 = 0.6017265170465123\n",
            "training accuracy = 0.8981270328120502, microF1 = 0.9170025952541179, macroF1 = 0.60079982135808\n",
            "training accuracy = 0.8981612603017686, microF1 = 0.9169917678537155, macroF1 = 0.6058484784487458\n",
            "training accuracy = 0.8981120269109447, microF1 = 0.9170037929225592, macroF1 = 0.6047951757496679\n",
            "training accuracy = 0.8995187266893426, microF1 = 0.9182343416241585, macroF1 = 0.6072814233514371\n",
            "training accuracy = 0.8999286426691505, microF1 = 0.9184107521350328, macroF1 = 0.6067487568690962\n",
            "training accuracy = 0.9000371683956238, microF1 = 0.9184944669804508, macroF1 = 0.6033558757520963\n",
            "training accuracy = 0.9011839469278431, microF1 = 0.9193813615974076, macroF1 = 0.6052132709960769\n",
            "training accuracy = 0.9013384523187428, microF1 = 0.9196396033528433, macroF1 = 0.6059188266168555\n",
            "training accuracy = 0.9011584712684554, microF1 = 0.9195205010373012, macroF1 = 0.6045331389712157\n",
            "training accuracy = 0.9015157354295057, microF1 = 0.919686594648195, macroF1 = 0.6062248336265179\n",
            "training accuracy = 0.9015808211490848, microF1 = 0.9198606783826392, macroF1 = 0.6059329950083253\n",
            "\n",
            "epoch = 38, training_loss = 0.02549669998169867, validation_loss =0.07007098942995071, training_acc = 0.9015575640901208, validation_acc =0.7917728210950955\n",
            "training accuracy = 0.8999123506403482, microF1 = 0.9192931371328534, macroF1 = 0.6160642752636799\n",
            "training accuracy = 0.9006440095730357, microF1 = 0.9197584209961607, macroF1 = 0.6165464249131087\n",
            "training accuracy = 0.9018055599636138, microF1 = 0.9202262854570471, macroF1 = 0.6111073537140251\n",
            "training accuracy = 0.9008813667383571, microF1 = 0.9197955321810246, macroF1 = 0.6072015640305843\n",
            "training accuracy = 0.9003903113047346, microF1 = 0.9190900151365484, macroF1 = 0.6100023344969192\n",
            "training accuracy = 0.900080532862229, microF1 = 0.9186946216269745, macroF1 = 0.6061052413943154\n",
            "training accuracy = 0.9012159189248975, microF1 = 0.919457806526843, macroF1 = 0.6082777346534728\n",
            "training accuracy = 0.9015116756355562, microF1 = 0.919821968579532, macroF1 = 0.611795460588975\n",
            "training accuracy = 0.9011407146291621, microF1 = 0.9195013203944891, macroF1 = 0.6108333009270313\n",
            "training accuracy = 0.9019165650449417, microF1 = 0.9200949679793365, macroF1 = 0.6080728021771892\n",
            "training accuracy = 0.9015344957950941, microF1 = 0.9199138916997205, macroF1 = 0.6091263343143704\n",
            "training accuracy = 0.9020202768695574, microF1 = 0.9202980139957744, macroF1 = 0.6062822259189835\n",
            "training accuracy = 0.9019413600797882, microF1 = 0.9201213419156505, macroF1 = 0.6048609349512264\n",
            "training accuracy = 0.9017194478953259, microF1 = 0.9199799658132987, macroF1 = 0.6041117281420524\n",
            "\n",
            "epoch = 39, training_loss = 0.025533159781900263, validation_loss =0.06986474157455042, training_acc = 0.9021789013846623, validation_acc =0.7937429108328481\n",
            "training accuracy = 0.9046149408726057, microF1 = 0.9237694158372424, macroF1 = 0.616216505015082\n",
            "training accuracy = 0.9032552610568134, microF1 = 0.9218548675650015, macroF1 = 0.6188657844725386\n",
            "training accuracy = 0.9039256038844968, microF1 = 0.9222824745750071, macroF1 = 0.6155501558225674\n",
            "training accuracy = 0.9038062917951329, microF1 = 0.9216654839272785, macroF1 = 0.6158238116099161\n",
            "training accuracy = 0.9035815777948277, microF1 = 0.9214482181462228, macroF1 = 0.6131736724138536\n",
            "training accuracy = 0.9037937037801784, microF1 = 0.9216874446630502, macroF1 = 0.6103049113595371\n",
            "training accuracy = 0.9036716316257337, microF1 = 0.9216114559762404, macroF1 = 0.6116681468480822\n",
            "training accuracy = 0.9037153386816942, microF1 = 0.9216631744771127, macroF1 = 0.6134391401685421\n",
            "training accuracy = 0.9031198835062263, microF1 = 0.9210753753356862, macroF1 = 0.6126698099306749\n",
            "training accuracy = 0.9022681847628313, microF1 = 0.9202280035103206, macroF1 = 0.6107837679173848\n",
            "training accuracy = 0.9017260317416869, microF1 = 0.919745571027419, macroF1 = 0.6105589070071981\n",
            "training accuracy = 0.9021036447746542, microF1 = 0.9200068682380715, macroF1 = 0.6115265523849305\n",
            "training accuracy = 0.9023923435021285, microF1 = 0.9202625727441001, macroF1 = 0.6114050103590457\n",
            "training accuracy = 0.9020126774614652, microF1 = 0.9199870023413477, macroF1 = 0.6088998365816417\n",
            "\n",
            "epoch = 40, training_loss = 0.025309990941069994, validation_loss =0.06940159712409236, training_acc = 0.9020533166970093, validation_acc =0.7960002647345914\n",
            "training accuracy = 0.9020991598465496, microF1 = 0.9207410438350107, macroF1 = 0.6085104554248895\n",
            "training accuracy = 0.9034267085661685, microF1 = 0.922201342961698, macroF1 = 0.6156203244092757\n",
            "training accuracy = 0.9033533357889535, microF1 = 0.9217249898565121, macroF1 = 0.6180282217544603\n",
            "training accuracy = 0.9025020713369811, microF1 = 0.9207630958675009, macroF1 = 0.6116603747294586\n",
            "training accuracy = 0.9008153630940846, microF1 = 0.9191710435379443, macroF1 = 0.6047715322181568\n",
            "training accuracy = 0.9020144174378594, microF1 = 0.9201881005990956, macroF1 = 0.6053231866096201\n",
            "training accuracy = 0.9006735493687932, microF1 = 0.9190961991887358, macroF1 = 0.6046910111732038\n",
            "training accuracy = 0.9014743200681955, microF1 = 0.9199379671483257, macroF1 = 0.6116888875279632\n",
            "training accuracy = 0.9022873763260643, microF1 = 0.9205819807465223, macroF1 = 0.6093223705630261\n",
            "training accuracy = 0.9025066141560117, microF1 = 0.9207622948428921, macroF1 = 0.6085933868216764\n",
            "training accuracy = 0.9025067772069589, microF1 = 0.9208958805312661, macroF1 = 0.608897835757727\n",
            "training accuracy = 0.9029476678816151, microF1 = 0.9212592721245024, macroF1 = 0.6087343692992927\n",
            "training accuracy = 0.9030588284088868, microF1 = 0.9214052724582917, macroF1 = 0.6102436898095762\n",
            "training accuracy = 0.9030354955036031, microF1 = 0.9212351934059785, macroF1 = 0.6109996249527343\n",
            "\n",
            "epoch = 41, training_loss = 0.025424838648577735, validation_loss =0.07122436434645013, training_acc = 0.9029155479323261, validation_acc =0.7918949434895339\n",
            "training accuracy = 0.9050235720187939, microF1 = 0.9227206970173806, macroF1 = 0.6202151639314726\n",
            "training accuracy = 0.9039751377269842, microF1 = 0.9213416276969296, macroF1 = 0.6135170411685071\n",
            "training accuracy = 0.9005820201498912, microF1 = 0.9186937783940567, macroF1 = 0.6011638814062882\n",
            "training accuracy = 0.9019681650698015, microF1 = 0.9198854345494185, macroF1 = 0.6051834789261549\n",
            "training accuracy = 0.9021053974225319, microF1 = 0.9199033507290733, macroF1 = 0.6063644112740845\n",
            "training accuracy = 0.9033222887238923, microF1 = 0.9212013279371507, macroF1 = 0.6107191140948707\n",
            "training accuracy = 0.9029218704252359, microF1 = 0.9209598417817247, macroF1 = 0.6108783692635078\n",
            "training accuracy = 0.9023076803897194, microF1 = 0.9202720242380502, macroF1 = 0.610515367565999\n",
            "training accuracy = 0.9028608403014741, microF1 = 0.9208383133649192, macroF1 = 0.6118807602122307\n",
            "training accuracy = 0.9029006977663434, microF1 = 0.9209470705402317, macroF1 = 0.6109696045812021\n",
            "training accuracy = 0.9027246793866367, microF1 = 0.9207779000730177, macroF1 = 0.6105273525610866\n",
            "training accuracy = 0.903042176462697, microF1 = 0.921042099480301, macroF1 = 0.6120301690341658\n",
            "training accuracy = 0.9027702656377203, microF1 = 0.9208017218936256, macroF1 = 0.610640669177678\n",
            "training accuracy = 0.9024291223669145, microF1 = 0.9205137722540703, macroF1 = 0.6112058510136408\n",
            "\n",
            "epoch = 42, training_loss = 0.025191063118964126, validation_loss =0.0704457208744644, training_acc = 0.9023328985297155, validation_acc =0.795210375445411\n",
            "training accuracy = 0.9082267687196174, microF1 = 0.9246291759745314, macroF1 = 0.6331846281905491\n",
            "training accuracy = 0.9084044539339563, microF1 = 0.925044070949868, macroF1 = 0.6419278803247744\n",
            "training accuracy = 0.9063067919380094, microF1 = 0.923376630814394, macroF1 = 0.6285209123682387\n",
            "training accuracy = 0.9058652519694717, microF1 = 0.9229806112682799, macroF1 = 0.6242065970522993\n",
            "training accuracy = 0.9036537883549279, microF1 = 0.9210297035616447, macroF1 = 0.6182905272363995\n",
            "training accuracy = 0.9034029518529484, microF1 = 0.9205316949031955, macroF1 = 0.6139301139370096\n",
            "training accuracy = 0.90371265421973, microF1 = 0.9209354241557773, macroF1 = 0.6109230030313536\n",
            "training accuracy = 0.9037014397360218, microF1 = 0.9209952279627182, macroF1 = 0.6099829262566323\n",
            "training accuracy = 0.9032164244890654, microF1 = 0.920737461455106, macroF1 = 0.6122714261245437\n",
            "training accuracy = 0.9035661031290496, microF1 = 0.9210724147071017, macroF1 = 0.6129738734119623\n",
            "training accuracy = 0.9038867104895956, microF1 = 0.9213903943173091, macroF1 = 0.6114210303506118\n",
            "training accuracy = 0.9041101759704028, microF1 = 0.9215995860977069, macroF1 = 0.6121959224033775\n",
            "training accuracy = 0.9042265916446838, microF1 = 0.9218670619549538, macroF1 = 0.6122472318933708\n",
            "training accuracy = 0.9041427489915544, microF1 = 0.9217680998239046, macroF1 = 0.61073823270748\n",
            "\n",
            "epoch = 43, training_loss = 0.024888644439785956, validation_loss =0.0712640664933883, training_acc = 0.9040275616522312, validation_acc =0.7920136409296036\n",
            "training accuracy = 0.9009689164100647, microF1 = 0.9189915648952555, macroF1 = 0.6209247452043235\n",
            "training accuracy = 0.9072630750291492, microF1 = 0.9244212219097947, macroF1 = 0.6283598777006999\n",
            "training accuracy = 0.906558988752021, microF1 = 0.9241560642280338, macroF1 = 0.6321782883955014\n",
            "training accuracy = 0.9060849645276686, microF1 = 0.9234015731505241, macroF1 = 0.6234051892202997\n",
            "training accuracy = 0.9056533530798776, microF1 = 0.9233402150069532, macroF1 = 0.6159038311221603\n",
            "training accuracy = 0.9061833059060402, microF1 = 0.9240479448353119, macroF1 = 0.6136436910484512\n",
            "training accuracy = 0.9068573434504431, microF1 = 0.9243374999346378, macroF1 = 0.6097987895782295\n",
            "training accuracy = 0.9059532896414112, microF1 = 0.923636780702675, macroF1 = 0.6104044188953388\n",
            "training accuracy = 0.9056567351940609, microF1 = 0.9232919617419858, macroF1 = 0.6081363828593676\n",
            "training accuracy = 0.9053063251147001, microF1 = 0.9229559653462522, macroF1 = 0.6062399477380491\n",
            "training accuracy = 0.9048655070326376, microF1 = 0.9224987325906977, macroF1 = 0.607616879382077\n",
            "training accuracy = 0.9053223316403111, microF1 = 0.9227977426949444, macroF1 = 0.6082331759465154\n",
            "training accuracy = 0.905624087563817, microF1 = 0.9231809719305067, macroF1 = 0.6097073473725331\n",
            "training accuracy = 0.9053913561827438, microF1 = 0.9229404590227718, macroF1 = 0.6106965839664641\n",
            "\n",
            "epoch = 44, training_loss = 0.02467226430364081, validation_loss =0.06994094373178236, training_acc = 0.9052835316837174, validation_acc =0.7950800729842347\n",
            "training accuracy = 0.9030025219749785, microF1 = 0.9212015444994653, macroF1 = 0.5977221290524879\n",
            "training accuracy = 0.9036649055059491, microF1 = 0.9212142910812047, macroF1 = 0.5957124425936787\n",
            "training accuracy = 0.9028702516964006, microF1 = 0.9204861483236374, macroF1 = 0.6023291856092182\n",
            "training accuracy = 0.9024259887997106, microF1 = 0.9200403958730274, macroF1 = 0.6043909597905767\n",
            "training accuracy = 0.9033845918164832, microF1 = 0.9210659656126196, macroF1 = 0.6059137090970452\n",
            "training accuracy = 0.9036566688562322, microF1 = 0.9211686612713053, macroF1 = 0.6040964320956953\n",
            "training accuracy = 0.9044867177144532, microF1 = 0.9219369206729262, macroF1 = 0.6070345105433866\n",
            "training accuracy = 0.9047914364481855, microF1 = 0.9222695026782081, macroF1 = 0.6070016531031601\n",
            "training accuracy = 0.9043345290154109, microF1 = 0.9217039703834037, macroF1 = 0.6076388247395778\n",
            "training accuracy = 0.9045717490569916, microF1 = 0.9219349687484741, macroF1 = 0.6101694551686827\n",
            "training accuracy = 0.9044162513206015, microF1 = 0.9218243201864467, macroF1 = 0.6093378376823002\n",
            "training accuracy = 0.9039371945987528, microF1 = 0.9214575044327904, macroF1 = 0.6112369827651369\n",
            "training accuracy = 0.9039844069392917, microF1 = 0.9215391089006192, macroF1 = 0.6152074893668392\n",
            "training accuracy = 0.9042305590568875, microF1 = 0.9217760961854139, macroF1 = 0.6135960639306851\n",
            "\n",
            "epoch = 45, training_loss = 0.024846807323857068, validation_loss =0.07060604765243136, training_acc = 0.9042507607015715, validation_acc =0.7938380855996132\n",
            "training accuracy = 0.9084314151355318, microF1 = 0.9262286220316562, macroF1 = 0.6108932309393642\n",
            "training accuracy = 0.9084642253247602, microF1 = 0.9262500772482705, macroF1 = 0.6101825927465822\n",
            "training accuracy = 0.907086125336544, microF1 = 0.9247797723800271, macroF1 = 0.6066726819568843\n",
            "training accuracy = 0.9079604468340083, microF1 = 0.9254275139239708, macroF1 = 0.6092809785933905\n",
            "training accuracy = 0.9067809097050439, microF1 = 0.924528527885191, macroF1 = 0.611542136486894\n",
            "training accuracy = 0.9062557905711567, microF1 = 0.92382782729342, macroF1 = 0.6093604622972476\n",
            "training accuracy = 0.9068886090027608, microF1 = 0.9242195979632801, macroF1 = 0.6087263315172228\n",
            "training accuracy = 0.9067574963930894, microF1 = 0.9240969991175058, macroF1 = 0.6099120552824865\n",
            "training accuracy = 0.90608758511671, microF1 = 0.9233958301152085, macroF1 = 0.6132964947891252\n",
            "training accuracy = 0.9061166010727738, microF1 = 0.9235894776626877, macroF1 = 0.6119249884404584\n",
            "training accuracy = 0.9051428684561027, microF1 = 0.9228303971964829, macroF1 = 0.6137658162595756\n",
            "training accuracy = 0.9057063092534337, microF1 = 0.923162987660941, macroF1 = 0.6140840117756858\n",
            "training accuracy = 0.9058975829600716, microF1 = 0.9233237304616643, macroF1 = 0.6139584454692267\n",
            "training accuracy = 0.9057278475436359, microF1 = 0.9232383952388981, macroF1 = 0.6127745977363885\n",
            "\n",
            "epoch = 46, training_loss = 0.024789763524923538, validation_loss =0.0703434840843235, training_acc = 0.9057607864660977, validation_acc =0.7967044153067335\n",
            "training accuracy = 0.9019742658182794, microF1 = 0.9209533098041375, macroF1 = 0.6074808879451453\n",
            "training accuracy = 0.9019311963192452, microF1 = 0.9207508331753548, macroF1 = 0.6125050562164617\n",
            "training accuracy = 0.9038867885808464, microF1 = 0.9220935930968575, macroF1 = 0.60973522588385\n",
            "training accuracy = 0.903757374608237, microF1 = 0.9218347936250485, macroF1 = 0.609484274800632\n",
            "training accuracy = 0.903290130691027, microF1 = 0.9213473125947146, macroF1 = 0.610799067718786\n",
            "training accuracy = 0.9039834601878165, microF1 = 0.9221164174042787, macroF1 = 0.6138744152159414\n",
            "training accuracy = 0.9042476625319106, microF1 = 0.9222084281005921, macroF1 = 0.6093527689128961\n",
            "training accuracy = 0.904508189845233, microF1 = 0.9223925845420115, macroF1 = 0.6101906466009007\n",
            "training accuracy = 0.9049063468251658, microF1 = 0.9226968562882154, macroF1 = 0.6098371772780183\n",
            "training accuracy = 0.9052527766957074, microF1 = 0.9229780422898894, macroF1 = 0.6109017121277367\n",
            "training accuracy = 0.9050149318340938, microF1 = 0.9227575334958845, macroF1 = 0.6105095374879389\n",
            "training accuracy = 0.9048689496143318, microF1 = 0.9227688437241027, macroF1 = 0.6115259003519703\n",
            "training accuracy = 0.9048975190044161, microF1 = 0.9227640440154092, macroF1 = 0.6122602242491585\n",
            "training accuracy = 0.9051652696077024, microF1 = 0.9231046140281336, macroF1 = 0.6125207226585084\n",
            "\n",
            "epoch = 47, training_loss = 0.024800107471926517, validation_loss =0.07148961085326892, training_acc = 0.905141182604306, validation_acc =0.7926934776461362\n",
            "training accuracy = 0.902841996224548, microF1 = 0.9201194072912012, macroF1 = 0.6128427982713818\n",
            "training accuracy = 0.9073385614690287, microF1 = 0.9238124457281811, macroF1 = 0.6237100697704813\n",
            "training accuracy = 0.9064726861687272, microF1 = 0.9237302645428681, macroF1 = 0.6137812193228616\n",
            "training accuracy = 0.9062496657086591, microF1 = 0.9236043094090883, macroF1 = 0.6110260143165747\n",
            "training accuracy = 0.9057246589269894, microF1 = 0.9232816536355308, macroF1 = 0.6118757833118023\n",
            "training accuracy = 0.9059267058457605, microF1 = 0.9235146199816731, macroF1 = 0.6165826070432439\n",
            "training accuracy = 0.9065518323869513, microF1 = 0.924056974610824, macroF1 = 0.6132730955982499\n",
            "training accuracy = 0.9064051078189802, microF1 = 0.9238398541699, macroF1 = 0.6136008699392503\n",
            "training accuracy = 0.9066791748352224, microF1 = 0.9241004588841233, macroF1 = 0.6129922214237441\n",
            "training accuracy = 0.9060830028342669, microF1 = 0.9235008221406349, macroF1 = 0.6137009457920096\n",
            "training accuracy = 0.9061458030994385, microF1 = 0.9234662487639098, macroF1 = 0.6137905890576599\n",
            "training accuracy = 0.9061275124716848, microF1 = 0.9236076761430446, macroF1 = 0.6130700334061986\n",
            "training accuracy = 0.9060255708142688, microF1 = 0.9235601655090065, macroF1 = 0.6131837049125237\n",
            "training accuracy = 0.905943550936476, microF1 = 0.923411725790707, macroF1 = 0.6135657972039017\n",
            "\n",
            "epoch = 48, training_loss = 0.024626044617306532, validation_loss =0.07070153037604597, training_acc = 0.9056563676209457, validation_acc =0.7951518812103151\n",
            "training accuracy = 0.9044373960943707, microF1 = 0.9212664221687348, macroF1 = 0.6104593937045757\n",
            "training accuracy = 0.9050113328042648, microF1 = 0.922132549549225, macroF1 = 0.6092682881260751\n",
            "training accuracy = 0.9041402032960575, microF1 = 0.9219047460052171, macroF1 = 0.6162997760329956\n",
            "training accuracy = 0.9041077083569625, microF1 = 0.92204949040152, macroF1 = 0.6189598758628891\n",
            "training accuracy = 0.904439788397742, microF1 = 0.9223982746618777, macroF1 = 0.6163220892713872\n",
            "training accuracy = 0.905444213224979, microF1 = 0.923091918480945, macroF1 = 0.6193658612038418\n",
            "training accuracy = 0.9048823576442188, microF1 = 0.92258401117621, macroF1 = 0.6189219489560444\n",
            "training accuracy = 0.9046216791178782, microF1 = 0.9224658057317685, macroF1 = 0.6183592098045244\n",
            "training accuracy = 0.9047219096742954, microF1 = 0.9224726693897133, macroF1 = 0.6185003395657966\n",
            "training accuracy = 0.9054934870603684, microF1 = 0.9230862037820092, macroF1 = 0.6183899762179453\n",
            "training accuracy = 0.9053007488795123, microF1 = 0.9229626555608017, macroF1 = 0.6173988384990957\n",
            "training accuracy = 0.9055840813581296, microF1 = 0.9230612899700347, macroF1 = 0.617655062286384\n",
            "training accuracy = 0.9051749246439925, microF1 = 0.9227556380977875, macroF1 = 0.614302661813264\n",
            "training accuracy = 0.9051804250035388, microF1 = 0.9228267319363165, macroF1 = 0.6142825237407634\n",
            "\n",
            "epoch = 49, training_loss = 0.02456623866603649, validation_loss =0.07071585304190203, training_acc = 0.9055055509740568, validation_acc =0.7942609105555166\n",
            "PERFORMANCE ON Train DATA\n",
            "MicroF1 = 0.9233053568152632 \n",
            "Accuracy = 0.9887547920269522\n",
            "------------Classification Report-------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art      0.779     0.713     0.744       296\n",
            "         eve      0.683     0.752     0.716       226\n",
            "         geo      0.915     0.958     0.936     29240\n",
            "         gpe      0.972     0.955     0.964     12058\n",
            "         nat      0.673     0.789     0.727       133\n",
            "         org      0.875     0.848     0.861     15803\n",
            "         per      0.918     0.917     0.917     13121\n",
            "         tim      0.931     0.955     0.943     15767\n",
            "\n",
            "   micro avg      0.917     0.929     0.923     86644\n",
            "   macro avg      0.843     0.861     0.851     86644\n",
            "weighted avg      0.917     0.929     0.923     86644\n",
            "\n",
            "PERFORMANCE ON Validation DATA\n",
            "MicroF1 = 0.7989299742652038 \n",
            "Accuracy = 0.9626003097543034\n",
            "------------Classification Report-------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art      0.385     0.190     0.255       105\n",
            "         eve      0.289     0.282     0.286        78\n",
            "         geo      0.810     0.874     0.841      9724\n",
            "         gpe      0.940     0.912     0.926      4210\n",
            "         nat      0.460     0.460     0.460        50\n",
            "         org      0.597     0.643     0.620      5187\n",
            "         per      0.767     0.736     0.752      4457\n",
            "         tim      0.850     0.870     0.860      5254\n",
            "\n",
            "   micro avg      0.786     0.812     0.799     29065\n",
            "   macro avg      0.637     0.621     0.625     29065\n",
            "weighted avg      0.788     0.812     0.799     29065\n",
            "\n",
            "PERFORMANCE ON Test DATA\n",
            "MicroF1 = 0.801542399137873\n",
            "Accuracy = 0.9631102766081157\n",
            "------------Classification Report-------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art      0.245     0.118     0.159       102\n",
            "         eve      0.361     0.402     0.380        87\n",
            "         geo      0.822     0.881     0.850      9912\n",
            "         gpe      0.936     0.910     0.923      4168\n",
            "         nat      0.535     0.418     0.469        55\n",
            "         org      0.598     0.645     0.621      5205\n",
            "         per      0.764     0.746     0.755      4406\n",
            "         tim      0.845     0.866     0.855      5275\n",
            "\n",
            "   micro avg      0.789     0.815     0.802     29210\n",
            "   macro avg      0.638     0.623     0.627     29210\n",
            "weighted avg      0.790     0.815     0.802     29210\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F6DWpN_VP9A"
      },
      "source": [
        "class LayerNorm_LSTMCell(nn.Module):\n",
        "  def __init__(self, embedding_size, hidden_size, epsilon=1e-5):\n",
        "    super(LayerNorm_LSTMCell, self).__init__()\n",
        "    self.embedding_size=embedding_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.epsilon=1e-5\n",
        "\n",
        "    self.inp2hidden = nn.Linear(embedding_size, 4*hidden_size) #since there are 4 linear transformations : i,f,g,o\n",
        "    self.hidden2hidden = nn.Linear(hidden_size, 4*hidden_size) #this takes input h_t_minus_1\n",
        "\n",
        "    # define layernorm layers : we are normalising input to input,forget,output,cell gate in \"cummulative fashion\"\n",
        "    self.layernorm_inp2hidden = nn.LayerNorm(4*hidden_size)\n",
        "    self.layernorm_hidden2hidden = nn.LayerNorm(4*hidden_size)\n",
        "    self.layernorm_over_c = nn.LayerNorm(hidden_size)\n",
        "   \n",
        "  def forward(self, inp, h_c_prev=None): # x (batch,embedding_size), h_c (h and c at t-1) : [(batch,hidden_size)]*2\n",
        "    h_prev, c_prev = h_c_prev if h_c_prev!=None else (torch.zeros((inp.shape[0],self.hidden_size)).to(device) , torch.zeros((inp.shape[0],self.hidden_size)).to(device))\n",
        "    # first do the linear transformations with layernorms\n",
        "    linear_transform_inp = self.layernorm_inp2hidden(self.inp2hidden(inp)) + self.layernorm_hidden2hidden(self.hidden2hidden(h_prev))\n",
        "\n",
        "    #find the gates\n",
        "    split=self.hidden_size\n",
        "    i=torch.sigmoid(linear_transform_inp[:,0:split])\n",
        "    f=torch.sigmoid(linear_transform_inp[:,split:2*split])\n",
        "    o=torch.sigmoid(linear_transform_inp[:,2*split:3*split])\n",
        "    g=torch.tanh(linear_transform_inp[:,3*split:])\n",
        "    c=f*c_prev+i*g\n",
        "\n",
        "    #apply final layer norm\n",
        "    c=self.layernorm_over_c(c)\n",
        "    h=o*torch.tanh(c)\n",
        "    return (h,c)\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, embedding_size, hidden_size, bidirectional=True, batch_first=True):\n",
        "    super(LSTM, self).__init__()\n",
        "    # bidirectional=True, batch_first=True : always (assumed)\n",
        "    self.embedding_size=embedding_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.lstm_cell_fwd=LayerNorm_LSTMCell(embedding_size, hidden_size)\n",
        "    self.lstm_cell_bkwd=LayerNorm_LSTMCell(embedding_size, hidden_size)\n",
        "\n",
        "  def forward(self, inp): #inp (batch,seq_len,embedding_size)\n",
        "    # iterate over seq_len in forward and backward direction (using their respective lstm cells)\n",
        "\n",
        "    ht_fwd, ht_bkwd = [],[]\n",
        "    ct_fwd, ct_bkwd = [],[]\n",
        "    \n",
        "    for t in range(inp.shape[1]):\n",
        "      #forward lstm\n",
        "      h_c_prev=(ht_fwd[t-1],ct_fwd[t-1]) if t!=0 else None\n",
        "      ht,ct=self.lstm_cell_fwd(inp[:,t,:],h_c_prev)\n",
        "      ht_fwd.append(ht)\n",
        "      ct_fwd.append(ct)\n",
        "\n",
        "      #backward lstm\n",
        "      t_ = inp.shape[1]-t-1\n",
        "      h_c_prev_ = (ht_bkwd[0],ct_bkwd[0]) if t_!=inp.shape[1]-1 else None\n",
        "      ht_,ct_=self.lstm_cell_bkwd(inp[:,t_,:],h_c_prev_)\n",
        "      ht_bkwd.insert(0,ht_)\n",
        "      ct_bkwd.insert(0,ct_)\n",
        "    \n",
        "    #now stack ht and give it as out\n",
        "    #also take last ht,ct of fwd lstm and first ht,ct of bkwd lstm\n",
        "    #and give it as hn,cn after stacking\n",
        "\n",
        "    ht_fwd=torch.stack(ht_fwd) #seq_len,batch,hidden_dim\n",
        "    ct_fwd=torch.stack(ct_fwd) #seq_len,batch,hidden_dim\n",
        "    ht_bkwd=torch.stack(ht_bkwd) #seq_len,batch,hidden_dim\n",
        "    ct_bkwd=torch.stack(ct_bkwd) #seq_len,batch,hidden_dim\n",
        "    out=torch.cat((ht_fwd,ht_bkwd),dim=2).permute(1,0,2) #batch,seq_len,2*hidden_dim\n",
        "    \n",
        "    hn=torch.stack((ht_fwd[-1],ht_bkwd[0])) #batch,hidden_dim\n",
        "    cn=torch.stack((ct_fwd[-1],ct_bkwd[0])) #batch,hidden_dim\n",
        "    return out,(hn,cn)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g6OXupLWpMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
