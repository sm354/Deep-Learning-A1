{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "2.2_bILSTM_CRF_glove_CHARLEVEL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sm354/COL870-Assignment-1/blob/main/2_2_COMPLETE_bILSTM_CRF_glove_CHARLEVEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsTk933f2NFE",
        "outputId": "e7c1d418-9ce9-4899-f2c2-4f1b65c8175c"
      },
      "source": [
        "Expname = \"BiLSTM_crf_char_glove\"\n",
        "pre_embeddings= \"glove\" # glove or random\n",
        "rootpath = \"/content/drive/MyDrive/Q2_DL/Experiments/\"\n",
        "\n",
        "!pip install seqeval\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import io\n",
        "import sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seqeval\n",
        "from seqeval.metrics import accuracy_score as seq_accuracy_score\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "from seqeval.metrics import f1_score as seq_f1_score\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  device = \"cuda:0\" \n",
        "else:  \n",
        "  device = \"cpu\"  \n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "'''Helper Functions'''\n",
        "# reading text file in python and making list of sentences (list of lists) and list of tags(list of lists)\n",
        "def load_data(datapath, buildvocab_tags= True, vocab = None, nertags = None):\n",
        "    if(buildvocab_tags == True):\n",
        "        all_words = []\n",
        "        all_tags = []\n",
        "        with open(datapath) as f:\n",
        "            lines = f.readlines()\n",
        "            sent_num = 0\n",
        "            for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "                if(line == \"\\n\"):\n",
        "                    sent_num+=1\n",
        "                else:\n",
        "                    line_sep = line.split(sep = \" \")\n",
        "                    all_words.append(line_sep[0])\n",
        "                    all_tags.append(line_sep[3][:-1])\n",
        "                    \n",
        "        words = list(set(all_words))\n",
        "        tags = list(set(all_tags))\n",
        "\n",
        "        vocab = {}\n",
        "        vocab['<pad>'] = 0 # for padding input sequences\n",
        "        vocab['<oov>'] = 1\n",
        "        for i, word in enumerate(words):\n",
        "            vocab[word] = i+2\n",
        "            \n",
        "        nertags = {}\n",
        "        nertags['padtag'] = 0\n",
        "        for i,nertag in enumerate(tags):\n",
        "            nertags[nertag] = i+1\n",
        "\n",
        "    train_sent = []\n",
        "    train_tags = []\n",
        "    with open(datapath) as f:\n",
        "        lines = f.readlines()\n",
        "        sent_num = 0\n",
        "        sentence = []\n",
        "        tag = []\n",
        "        for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "            if(line == \"\\n\"):\n",
        "                sent_num+=1\n",
        "                train_sent.append(sentence)\n",
        "                train_tags.append(tag)\n",
        "                sentence = []\n",
        "                tag = []\n",
        "            else:\n",
        "                line_sep = line.split(sep = \" \")\n",
        "                if(line_sep[0] in vocab.keys()):\n",
        "                    sentence.append(vocab[line_sep[0]])\n",
        "                else:\n",
        "                    sentence.append(vocab['<oov>'])\n",
        "                    \n",
        "                tag.append(nertags[line_sep[3][:-1]])\n",
        "\n",
        "    # padding the sentences at the end\n",
        "    seq_maxlen = max(len(x) for x in train_sent)\n",
        "    x_lengths = [len(x) for x in train_sent]\n",
        "    Xtrain = []\n",
        "    Ytrain = []\n",
        "    for sent, tags in zip(train_sent, train_tags):\n",
        "        length_toappend = seq_maxlen - len(sent)\n",
        "        Xtrain.append(sent+[0]*length_toappend)\n",
        "        Ytrain.append(tags+[0]*length_toappend)\n",
        "\n",
        "\n",
        "    Xtrain = torch.Tensor(Xtrain)\n",
        "    Ytrain = torch.Tensor(Ytrain)\n",
        "    x_lengths = torch.Tensor(x_lengths)\n",
        "    # print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
        "    \n",
        "    return Xtrain, Ytrain, x_lengths, vocab, nertags\n",
        "\n",
        "def get_mask(x, xlengths):\n",
        "    bin_mask = []\n",
        "    for i in range(xlengths.shape[0]):\n",
        "        bin_mask.append([1]*int(xlengths[i].item())+[0]*int((x.shape[1] - xlengths[i].item())))\n",
        "    return torch.tensor(bin_mask)\n",
        "\n",
        "def load_char_data(words, charvocab):\n",
        "    train_char_sent = []\n",
        "    train_char_label = []\n",
        "    for word in words:\n",
        "        chars = []\n",
        "        char_labels = []\n",
        "\n",
        "        word_sep = list(word)\n",
        "        for c in word_sep[:-1]:\n",
        "            if (c in charvocab.keys()):\n",
        "                chars.append(charvocab[c])\n",
        "            else:\n",
        "                chars.append(charvocab['<oovchar>'])\n",
        "        for c in word_sep[1:]:\n",
        "            if (c in charvocab.keys()):\n",
        "                char_labels.append(charvocab[c])\n",
        "            else:\n",
        "                char_labels.append(charvocab['<oovchar>'])\n",
        "        \n",
        "        train_char_sent.append(chars)\n",
        "        train_char_label.append(char_labels)\n",
        "\n",
        "    # padding the char_sents at the end\n",
        "    seq_maxlen = max(len(x) for x in train_char_sent)\n",
        "    x_lengths_char = [len(x) for x in train_char_sent]\n",
        "    Xtrain_char = []\n",
        "    Ytrain_char = []\n",
        "    for char_sent, char_label in zip(train_char_sent, train_char_label):\n",
        "        length_toappend = seq_maxlen - len(char_sent)\n",
        "        Xtrain_char.append(char_sent+[0]*length_toappend)\n",
        "        Ytrain_char.append(char_label+[0]*length_toappend) # 0 is padchar\n",
        "\n",
        "\n",
        "    Xtrain_char = torch.Tensor(Xtrain_char)\n",
        "    Ytrain_char = torch.Tensor(Ytrain_char)\n",
        "    x_lengths_char = torch.Tensor(x_lengths_char)\n",
        "    # print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
        "    \n",
        "    return Xtrain_char, Ytrain_char, x_lengths_char\n",
        "\n",
        "def pad_chars(topadlist, maxlen):\n",
        "    topadlist = topadlist + [0]*(maxlen-len(topadlist))\n",
        "\n",
        "    return topadlist\n",
        "\n",
        "def make_id2word_charvocab(vocab, charvocab):\n",
        "    max_charlen = max(len(word) for word in vocab.keys())\n",
        "    word_charlevel_vocab = {}\n",
        "    wordid2wordlen = {}\n",
        "    for word in vocab.keys():\n",
        "        word_charlevel_vocab[vocab[word]] = [charvocab[w] if w in charvocab.keys() else charvocab['<oovchar>'] for w in word]\n",
        "        word_charlevel_vocab[vocab[word]] = pad_chars(word_charlevel_vocab[vocab[word]], max_charlen)\n",
        "\n",
        "        wordid2wordlen[vocab[word]] = len(word)\n",
        "        # word_charlevel_vocab[vocab[word]] = word_charlevel_vocab[vocab[word]].extend([charvocab['<padchar>']]*(max_charlen-len(word_charlevel_vocab[vocab[word]])))\n",
        "    return word_charlevel_vocab, wordid2wordlen\n",
        "\n",
        "\n",
        "def load_char_level(X, wordid2word_charlevel_vocab, wordid2wordlen):\n",
        "    #X is of shape (no.of.sentences, 104)\n",
        "    Xcharlevel = [] # will finally be fo shape (total.sentences, max_sent.len, )\n",
        "    Xcharlevel_lengths = []\n",
        "    for i in range(X.shape[0]):\n",
        "        sentence = []\n",
        "        wordlengths = []\n",
        "        for j in range(X.shape[1]):\n",
        "            sentence.append(torch.tensor([wordid2word_charlevel_vocab[int(X[i, j].item())]]))\n",
        "            wordlengths.append(wordid2wordlen[int(X[i, j].item())])\n",
        "            # sentences = pad_sequence(sentences)\n",
        "        # print(i)\n",
        "        Xcharlevel_lengths.append(wordlengths)\n",
        "        Xcharlevel.append(torch.stack(sentence))\n",
        "    \n",
        "    return torch.squeeze(torch.stack(Xcharlevel)), torch.tensor(Xcharlevel_lengths)\n",
        "\n",
        "def get_charvocab(vocab):\n",
        "    # using vocab make charvocab\n",
        "    words = list(vocab.keys())\n",
        "    characters = [char for word in words for char in word]\n",
        "    characters = list(set(characters))\n",
        "    char_vocab = {}\n",
        "    char_vocab[\"<padchar>\"] = 0\n",
        "    char_vocab[\"<oovchar>\"] = 1\n",
        "    for i, char in enumerate(characters):\n",
        "        char_vocab[char] = i+2\n",
        "\n",
        "    return char_vocab\n",
        "\n",
        "\n",
        "\"\"\"### Training Data\n",
        "### using dataloader to make data batches\"\"\"\n",
        "\n",
        "traindatapath = \"/content/drive/MyDrive/Q2_DL/train.txt\"\n",
        "devdatapath = \"/content/drive/MyDrive/Q2_DL/dev.txt\"\n",
        "\n",
        "Xtrain, Ytrain, x_trainlengths, vocab, nertags = load_data(traindatapath, buildvocab_tags=True)\n",
        "Xdev, Ydev, x_devlengths, _, _ = load_data(devdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
        "\n",
        "bin_mask_train, bin_mask_dev = get_mask(Xtrain, x_trainlengths), get_mask(Xdev, x_devlengths)\n",
        "\n",
        "# Character Level training data making\n",
        "# make vocabulary of characters from train vocabulary\n",
        "char_vocab = get_charvocab(vocab)\n",
        "wordid2word_charlevel_vocab, wordid2wordlen = make_id2word_charvocab(vocab, char_vocab) # of the form {word:[1,2,3,4]}, {wordnum:wordlen}\n",
        "#make char level train data for the char embeddings \n",
        "Xtrain_char, xlength_char = load_char_level(Xtrain, wordid2word_charlevel_vocab, wordid2wordlen)\n",
        "#finally make the dataloader for train\n",
        "traindataset = TensorDataset(Xtrain, Xtrain_char, Ytrain, x_trainlengths, xlength_char, bin_mask_train)\n",
        "Trainloader = DataLoader(traindataset, batch_size= 128, shuffle=True)\n",
        "\n",
        "\n",
        "# Character Level validation data making\n",
        "Xdev_temp, Ydev_temp, x_devlengths_temp, devvocab, devnertags = load_data(devdatapath, buildvocab_tags=True)\n",
        "wordid2word_charlevel_vocab_dev, wordid2wordlen_dev = make_id2word_charvocab(devvocab, char_vocab) # of the form {word:[1,2,3,4]}, {wordnum:wordlen}\n",
        "#make char level train data for the char embeddings \n",
        "Xdev_char, xdevlength_char = load_char_level(Xdev_temp, wordid2word_charlevel_vocab_dev, wordid2wordlen_dev)\n",
        "#finally make the dataloader for train\n",
        "devdataset = TensorDataset(Xdev, Xdev_char, Ydev, x_devlengths, xdevlength_char, bin_mask_dev)\n",
        "Devloader = DataLoader(devdataset, batch_size= 128, shuffle=True)\n",
        "\n",
        "# LOAD EMBEDDINGS\n",
        "embedding_size = 100\n",
        "if(pre_embeddings == \"glove\"):\n",
        "    gloveembeddings_index = {}\n",
        "    with io.open(\"/content/drive/MyDrive/Q2_DL/glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:],dtype='float32')\n",
        "            gloveembeddings_index[word] = coefs\n",
        "\n",
        "    #using vocab and Xtrain, Xvalid, get pretrained glove word embeddings\n",
        "    glove_embeds = np.zeros((len(vocab), embedding_size))\n",
        "    for word in vocab.keys():\n",
        "        if(word in gloveembeddings_index.keys()):\n",
        "            # for the pad word let theembedding be all zeros\n",
        "            glove_embeds[vocab[word]] = gloveembeddings_index[word]\n",
        "        else:\n",
        "            glove_embeds[vocab[word]] = np.random.randn(embedding_size)\n",
        "    word_embeds = torch.Tensor(glove_embeds)\n",
        "    # print(glove_embeds.shape) # shape (vocablength , embedding dim)\n",
        "\n",
        "if(pre_embeddings == \"random\"):\n",
        "    num_words = len(vocab)\n",
        "    word_embeds = torch.rand(num_words, embedding_size)\n",
        "\n",
        "# hence we get word_embeds which we could use afterwards\n",
        "\n",
        "\n",
        "# character level onehot embeddings and important classes for performance metrics\n",
        "char_onehot = torch.eye(len(char_vocab))\n",
        "imp_classes = [nertags[tag] for tag in nertags.keys()]\n",
        "imp_classes.remove(nertags['padtag'])\n",
        "imp_classes.remove(nertags['O'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 25.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 21.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 19.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=4d9607d49ab8014d4a435bf41eeb53602c0dcdc3ccb1d066c009e112c7926ccd\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9M1uW9_xHfE"
      },
      "source": [
        "\"\"\"### CRF MODULE\"\"\"\n",
        "\n",
        "class CRFmodule(nn.Module):\n",
        "    def __init__(self, numclass):\n",
        "        super(CRFmodule, self).__init__()\n",
        "        # numtags is representing the start position and numtags+1 the end position/id of the tags\n",
        "        random_transition = torch.zeros(numclass+2, numclass+2)\n",
        "        random_transition[numclass, :], random_transition[:, numclass+1] = -10000., -10000.\n",
        "        self.transmat = nn.Parameter(random_transition) # learnable matrix shape (num_classes, numclasses) including start and stop tag\n",
        "        self.startid = numclass\n",
        "        self.endid = numclass+1\n",
        "    \n",
        "    def forward(self, Ylstm, Ymask):\n",
        "        # y of shape (batchsize, seq_len, num_classes) num_classes = 18 when start and stop are not included but pad is included\n",
        "\n",
        "        # use viterbi algorithm to decode the correct sequence, given \"y\" sequence of tags \n",
        "        # from the bilstm and given the transition matrix that we have\n",
        "\n",
        "        # VITERBI ALGORITHM - output = decoded_tag_sequence of shape (batchsize, seqlen)\n",
        "        forward_scores = self.init_for_scores(Ylstm)\n",
        "        backtrack = []\n",
        "        for i in range(Ylstm.shape[1]):\n",
        "            for_scr_temp = forward_scores.view((Ylstm.shape[0], 1, Ylstm.shape[2])) \n",
        "            forward_transition_score_word = self.transmat + for_scr_temp \n",
        "\n",
        "            max_indices = torch.argmax(forward_transition_score_word, dim = 2)\n",
        "            forward_transition_score_word , _ = torch.max(forward_transition_score_word, dim = 2) # max_indices of shape (batches, C)\n",
        "            backtrack.append(max_indices)\n",
        "            unaryscore_word = Ylstm[:, i]#.view(Ylstm.shape[0], 1, Ylstm.shape[2]) # unary_score_word  of shape (batchsize, 1, num_classes)\n",
        "            forward_transition_score_word = forward_transition_score_word + unaryscore_word\n",
        "            \n",
        "            forward_scores = forward_transition_score_word * Ymask[:, i].view(Ylstm.shape[0], 1) + (1 - Ymask[:, i].view(Ylstm.shape[0], 1)) * forward_scores\n",
        "\n",
        "        end_score = forward_scores + self.transmat[self.endid] #shape will be (batches, num_classes)\n",
        "        max_index = torch.argmax(end_score, dim = 1).view(Ylstm.shape[0], 1) # shape is (Batch, 1)\n",
        "        # print(max_index.shape)\n",
        "        decoded_path = [max_index] \n",
        "\n",
        "        for index in backtrack[::-1]: #index is of shape (batches, numclasses)\n",
        "            # print(max_index)\n",
        "            max_index = torch.gather(index, 1, max_index).view(Ylstm.shape[0], 1)\n",
        "            decoded_path.append(max_index)\n",
        "        decoded_path = decoded_path[::-1][1:] #remove the start word\n",
        "        # print(decoded_path)\n",
        "        decoded_path = torch.cat(decoded_path, dim = 1)\n",
        "        return decoded_path\n",
        "\n",
        "    def crfloss(self, Ylstm, Ytrue, Ymask):\n",
        "        # loss is the negative los likelyhood = partition function - numerator\n",
        "        partition, numerator  = self.get_partition_numerator(Ylstm, Ytrue, Ymask) #numerator means in log space here\n",
        "        loss = partition - numerator\n",
        "        # print(numerator.mean(), partition.mean())\n",
        "        return loss.mean()\n",
        "    \n",
        "    def get_partition_numerator(self, Ylstm, Ytrue, Ymask):\n",
        "        # calculate the partition function\n",
        "        forward_scores = self.init_for_scores(Ylstm)\n",
        "        for i in range(Ylstm.shape[1]):\n",
        "            unaryscore_word = Ylstm[:, i].view(Ylstm.shape[0], Ylstm.shape[2], 1) # shape is now (batchsize, num_classes, 1)\n",
        "            unary_transition_score_word = unaryscore_word + self.transmat.view(1, Ylstm.shape[2], Ylstm.shape[2])\n",
        "            temp_score = torch.logsumexp(unary_transition_score_word + forward_scores.view(Ylstm.shape[0], 1, Ylstm.shape[2]), dim = 2)\n",
        "            forward_scores = temp_score * (Ymask[:, i].view(Ylstm.shape[0], 1)) + (1- Ymask[:, i].view(Ylstm.shape[0], 1)) * forward_scores\n",
        "\n",
        "        end_score_ = forward_scores + self.transmat[self.endid].view(1, Ylstm.shape[2])\n",
        "        forward_scores = torch.logsumexp(end_score_, dim = 1)\n",
        "\n",
        "        # calculate the score using Ylstm, Ytrue - shapes (batch, seqlen, numclass), (batch, seqlen)\n",
        "        # Ytrue is the tags of shape (Batch, seqlen), we concatenate start tag with this\n",
        "        Ytrue_mod = self.concat_start_tag_begin(Ytrue)\n",
        "        unary_scores = self.get_emission_score(Ylstm, Ytrue)\n",
        "        transition_scores = self.get_transition_score(Ytrue_mod)\n",
        "        total_score = ((unary_scores+transition_scores)*Ymask).sum(1) # sum alon the length dimension, finally get a (batch, 1) dimesnion vector\n",
        "        end_score = self.get_stop_score(Ytrue_mod)\n",
        "        numerator = total_score + end_score # shape is (batchsize)\n",
        "        # we have the numerator in log space\n",
        "        return forward_scores, numerator\n",
        "        \n",
        "    def init_for_scores(self, Ylstm):\n",
        "        forward_scores = torch.ones((Ylstm.shape[0], Ylstm.shape[2]))*-10000.\n",
        "        forward_scores = forward_scores.long().to(Ylstm.device)\n",
        "        forward_scores[:, self.startid] = 0.\n",
        "        return forward_scores\n",
        "\n",
        "    def get_stop_score(self, Ytrue):\n",
        "        from_ = Ytrue[:, -1].long()\n",
        "        to_ = self.endid\n",
        "        stop_scores = self.transmat[to_, from_]\n",
        "        return stop_scores\n",
        "\n",
        "    def concat_start_tag_begin(self, Ytrue):\n",
        "        starttags_batch = torch.full((Ytrue.shape[0], 1), fill_value = self.startid).to(Ytrue.device)\n",
        "        Ytrue = torch.cat((starttags_batch, Ytrue), dim = 1)\n",
        "        return Ytrue\n",
        "\n",
        "    def get_emission_score(self, Ylstm, Ytrue):\n",
        "        shape = Ytrue.shape\n",
        "        truetags = Ytrue.view(shape[0], shape[1], 1)\n",
        "        emission_scores = Ylstm.gather(dim=2, index=truetags.type(torch.int64).to(Ylstm.device)).view(shape[0], shape[1])\n",
        "        return emission_scores\n",
        "    \n",
        "    def get_transition_score(self, Ytrue):\n",
        "        from_ = Ytrue[:, :-1].long()\n",
        "        to_ = Ytrue[:, 1:].long()\n",
        "        transition_scores = self.transmat[to_, from_]\n",
        "        return transition_scores # of shape (batch, seqlen)\n",
        "\n",
        "\"\"\"# LSTM model for character **level**\n",
        "\"\"\"\n",
        "class forLSTM(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, pretr_char_embed):\n",
        "        super(forLSTM, self).__init__()\n",
        "        self.charembed = nn.Embedding.from_pretrained(pretr_char_embed, freeze = False) #size of pretrained = (totalchars,embedding size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, bidirectional = True, batch_first = True)\n",
        "\n",
        "    def forward(self, xchar, xlength_char):\n",
        "        #xchar is of shape(batchsize, seqlen_maxinbatch, maxwordlen-ie max char = 6)\n",
        "\n",
        "        shape = xchar.shape\n",
        "        xchar = xchar.view(-1, shape[2])\n",
        "        xlength_char = xlength_char.view(-1)\n",
        "        input = pack_padded_sequence(xchar, xlength_char.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        input, _ = pad_packed_sequence(input, batch_first=True)\n",
        "        embed = self.charembed(input)\n",
        "        _, (h,_) = self.lstm(embed) #h is of size (2, 128*maxno. of words in a sentence in the batch, 25)\n",
        "        h = h.view(h.shape[1], 50)\n",
        "        h = h.view(shape[0], shape[1], 50)\n",
        "        return h\n",
        "\n",
        "\"\"\"# BiLSTM Model\"\"\"\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, total_words, num_class, pretrained = False, pretrained_embed = None, char_embed_size = 0, pretr_char_embed = None):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.wordembed = nn.Embedding.from_pretrained(pretrained_embed, freeze = False)\n",
        "        self.for_charembed = forLSTM(embedding_size = char_embed_size, hidden_size = 25, pretr_char_embed = pretr_char_embed)\n",
        "        self.dropout = nn.Dropout(p = 0.5)\n",
        "        self.bilstm = nn.LSTM(embedding_size + 50,hidden_size, bidirectional = True, batch_first = True)\n",
        "        self.linear = nn.Linear(2*hidden_size, num_class+2) # 2 because forward and backward concatenate, +2 for feeding it into the crf layer, ie for start stop tags\n",
        "        self.crfmodule = CRFmodule(num_class)\n",
        "\n",
        "    # def forward(self, x, xchar, xlengths, xlength_char):\n",
        "    #     x = pack_padded_sequence(x, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    #     x, _ = pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "    #     xlength_char = pack_padded_sequence(xlength_char, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    #     xlength_char, _ = pad_packed_sequence(xlength_char, batch_first=True, padding_value = len(\"<pad>\")) \n",
        "    #     # above this line padding value is taken as len of pad word becasue that is what we pad sentences \n",
        "    #     # with hance at a character level it should be the length\n",
        "\n",
        "    #     xchar = pack_padded_sequence(xchar, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    #     xchar, _ = pad_packed_sequence(xchar, batch_first=True)\n",
        "\n",
        "    #     word_embedding = self.wordembed(x) # x is of size(batchsize, seq_len), wordembed is of size (batchsize, seq_len, embedding_size = 100)\n",
        "    #     forwardchar= self.for_charembed(xchar, xlength_char) #forwardchar and backwardchar would be of size (batchsize, seqlen. embedding_size = 25each) \n",
        "    #     word_embedding = torch.cat((word_embedding, forwardchar), dim = 2)\n",
        "\n",
        "    #     word_embedding = self.dropout(word_embedding) #dropout\n",
        "    #     out, (h,c) = self.bilstm(word_embedding) #'out' has dimension(batchsize, seq_len, 2*hidden_size)\n",
        "\n",
        "    #     out = self.linear(out) #now 'out' has dimension(batchsize, seq_len, num_class)\n",
        "    #     out = out.view(-1, out.shape[2]) # shape (128*seqlen, 18)\n",
        "    #     out = F.log_softmax(out, dim=1) # take the softmax across the dimension num_class, 'out' has dimension(batchsize, seq_len, num_class)\n",
        "    #     return out\n",
        "        \n",
        "    def forward(self, x, xchar, xlengths, xlength_char, xmask): \n",
        "        xmask = xmask.to(x.device)\n",
        "        ylstm, xmask = self.lstmoutput(x, xchar, xlengths, xlength_char, xmask)\n",
        "        out = self.crfmodule(ylstm, xmask) #out of shape (batch, seqlen)\n",
        "        return out\n",
        "\n",
        "    def loss(self, x, xchar, xlengths, xlength_char, ytrue, xmask):\n",
        "        xmask = xmask.to(x.device)\n",
        "\n",
        "        '''calls the loss function of the crf for getting the negative log likelyhood loss'''\n",
        "        ylstm, xmask = self.lstmoutput(x, xchar, xlengths, xlength_char, xmask)\n",
        "        loss = self.crfmodule.crfloss(ylstm, ytrue, xmask)\n",
        "        return loss\n",
        "\n",
        "    def lstmoutput(self, x, xchar, xlengths, xlength_char, xmask):\n",
        "        x = pack_padded_sequence(x, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        x, _ = pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "        xlength_char = pack_padded_sequence(xlength_char, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        xlength_char, _ = pad_packed_sequence(xlength_char, batch_first=True, padding_value = len(\"<pad>\")) \n",
        "        # above this line padding value is taken as len of pad word becasue that is what we pad sentences \n",
        "        # with hance at a character level it should be the length\n",
        "\n",
        "        xchar = pack_padded_sequence(xchar, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        xchar, _ = pad_packed_sequence(xchar, batch_first=True)\n",
        "\n",
        "        xmask = pack_padded_sequence(xmask, xlengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        xmask, _ = pad_packed_sequence(xmask, batch_first=True)\n",
        "\n",
        "        word_embedding = self.wordembed(x) # x is of size(batchsize, seq_len), wordembed is of size (batchsize, seq_len, embedding_size = 100)\n",
        "        forwardchar= self.for_charembed(xchar, xlength_char) #forwardchar and backwardchar would be of size (batchsize, seqlen. embedding_size = 25each) \n",
        "        word_embedding = torch.cat((word_embedding, forwardchar), dim = 2)\n",
        "\n",
        "        word_embedding = self.dropout(word_embedding) # dropout\n",
        "        out, (h,c) = self.bilstm(word_embedding) # 'out' has dimension(batchsize, seq_len, 2*hidden_size)\n",
        "        out = self.linear(out) # now 'out' has dimension(batchsize, seq_len, num_class+2)\n",
        "\n",
        "        return out, xmask\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmbNAAid2kRA"
      },
      "source": [
        "model = BiLSTM(embedding_size = 100, hidden_size = 100, total_words = len(vocab), num_class = 18, pretrained = True, pretrained_embed = word_embeds, char_embed_size = len(char_vocab), pretr_char_embed = char_onehot).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3) \n",
        "lossfunction = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# print(model)\n",
        "def performance(y, ypred, nertags):\n",
        "    y = y.numpy()\n",
        "    ypred = ypred.numpy()\n",
        "    mask = (y != nertags['padtag']) * (y != nertags['O'])\n",
        "    y = y*mask\n",
        "    ypred = ypred*mask\n",
        "    acc = ((y==ypred)*mask).sum()/mask.sum()\n",
        "    microf1 = f1_score(y, ypred, labels = imp_classes, average='micro')\n",
        "    macrof1 = f1_score(y, ypred, labels = imp_classes, average='macro')\n",
        "    return acc, microf1, macrof1\n",
        "\n",
        "def validate(model, loader):\n",
        "    with torch.no_grad():\n",
        "        validloss = 0\n",
        "        acc = 0\n",
        "        microf1 = 0\n",
        "        macrof1 = 0\n",
        "        i = 0\n",
        "        for step, (X, Xchar, Y, xlen, xlen_char, Xmask) in enumerate(loader):\n",
        "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
        "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
        "            ypred = model(X.long().to(device), Xchar.to(device), xlen.to(device), xlen_char.to(device), Xmask)#.permute(0, 2, 1)\n",
        "            vloss = model.loss(X.long().to(device), Xchar.to(device), xlen.to(device), xlen_char.to(device), Y, Xmask)\n",
        "            validloss+=vloss.item()\n",
        "            acc_, microf1_, macrof1_ = performance(Y.view(-1), ypred.to('cpu').view(-1), nertags)\n",
        "            acc+=acc_\n",
        "            microf1 += microf1_\n",
        "            macrof1 += macrof1_\n",
        "            i+=1\n",
        "\n",
        "    return validloss/i, acc/i, microf1/i, macrof1/i\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLyMWbwL2-kr",
        "outputId": "a63f94a6-748d-4e9c-d8c6-e0f211c24ce2"
      },
      "source": [
        "trainlosslist = []\n",
        "trainacclist = [] #accuracy except pad, O\n",
        "trainmicrof1list = []\n",
        "trainmacrof1list = []\n",
        "\n",
        "\n",
        "validlosslist = []\n",
        "valacclist = []\n",
        "valmicrof1list = []\n",
        "valmacrof1list = []\n",
        "\n",
        "\n",
        "# Model is ready now we have to train using cross entropy loss\n",
        "num_epochs = 50\n",
        "# validloss = []\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    if(epoch == 35):\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "    \n",
        "    totalloss, acc, microf1, macrof1 = 0, 0, 0, 0\n",
        "    for step, (Xbatch , Xchar ,Ybatch, xbatch_len, xlength_char, xbatch_mask) in enumerate(Trainloader):\n",
        "        #make gradients 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        Ybatch = pack_padded_sequence(Ybatch, xbatch_len, batch_first=True, enforce_sorted=False)\n",
        "        Ybatch, y_lengths = pad_packed_sequence(Ybatch, batch_first=True)\n",
        "\n",
        "        #get output from model and claculate loss\n",
        "        ypred = model(Xbatch.long().to(device), Xchar.to(device), xbatch_len.to(device), xlength_char.to(device), xbatch_mask)#.permute(0, 2, 1)\n",
        "        loss = model.loss(Xbatch.long().to(device), Xchar.to(device), xbatch_len.to(device), xlength_char.to(device), Ybatch, xbatch_mask)\n",
        "        \n",
        "        acc_, microf1_, macrof1_ = performance(Ybatch.view(-1), ypred.to('cpu').view(-1), nertags)\n",
        "        acc+= acc_\n",
        "        microf1+=microf1_\n",
        "        macrof1+=macrof1_\n",
        "        if(step%20 == 0 and step !=0):\n",
        "            print(\"training accuracy = {}, microF1 = {}, macroF1 = {}\".format(acc/(step+1), microf1/(step+1), macrof1/(step+1)))\n",
        "        \n",
        "        totalloss += loss.item()\n",
        "\n",
        "        #backward and step\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
        "        optimizer.step()\n",
        "    \n",
        "    trainlosslist.append(totalloss/(step+1))\n",
        "    trainacclist.append(acc/(step+1))\n",
        "    trainmicrof1list.append(microf1/(step+1))\n",
        "    trainmacrof1list.append(macrof1/(step+1))\n",
        "\n",
        "    # model validation loss and scheduler step for learning rate change if required\n",
        "    val_loss, val_acc, val_microf1, val_macrof1  = validate(model, Devloader)\n",
        "    validlosslist.append(val_loss)\n",
        "    valacclist.append(val_acc)\n",
        "    valmicrof1list.append(val_microf1)\n",
        "    valmacrof1list.append(val_macrof1)\n",
        "    \n",
        "    # scheduler.step(val_loss)\n",
        "    print('\\nepoch = {}, training_loss = {}, validation_loss ={}, training_acc = {}, validation_acc ={}'.format(epoch, trainlosslist[-1], validlosslist[-1], trainacclist[-1], valacclist[-1]))        \n",
        "        \n",
        "\n",
        "model.eval()\n",
        "\n",
        "import os\n",
        "if not os.path.exists(rootpath):\n",
        "    os.mkdir(rootpath)\n",
        "\n",
        "if not os.path.exists(rootpath+Expname):\n",
        "    os.mkdir(rootpath+Expname)\n",
        "\n",
        "\n",
        "def SavePlots(y1, y2, metric, rootpath, Expname):\n",
        "    try:\n",
        "        plt.clf()\n",
        "    except Exception as e:\n",
        "        pass\n",
        "    \"\"\"y2 should be validation\"\"\"\n",
        "    epochs=np.arange(1,len(y1)+1,1)\n",
        "    plt.title(Expname + \" \" + metric + \" plot\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(metric)\n",
        "    plt.plot(epochs,y1,label='Training %s'%metric, linewidth = 2)\n",
        "    plt.plot(epochs,y2,label='Validation %s'%metric, linewidth = 2)\n",
        "    if(metric == \"Loss\"):\n",
        "        ep=np.argmin(y2)\n",
        "    elif(metric != \"Loss\"):\n",
        "        ep =np.argmax(y2)\n",
        "    plt.plot(ep+1,y2[ep],'r*',label='bestvalue@(%.i,%.2f)'%(ep+1,y2[ep]))\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.savefig(rootpath+Expname+\"/{}\".format(metric), dpi=300)\n",
        "\n",
        "SavePlots(trainlosslist, validlosslist, \"Loss\", rootpath, Expname)\n",
        "SavePlots(trainacclist, valacclist, \"Accuracy\", rootpath, Expname)\n",
        "SavePlots(trainmicrof1list, valmicrof1list, \"Micro F1\", rootpath, Expname)\n",
        "SavePlots(trainmacrof1list, valmacrof1list, \"Macro F1\", rootpath, Expname)\n",
        "\n",
        "#make id2tag\n",
        "id2tag = {}\n",
        "for tag in nertags.keys():\n",
        "    if(tag == 'padtag'):\n",
        "        id2tag[nertags[tag]] = 'O' # because we dont want the model to predict 'padtag' tags\n",
        "    else:\n",
        "        id2tag[nertags[tag]] = tag\n",
        "\n",
        "\n",
        "def final_metrics(model, loader):\n",
        "    y_predicted = []\n",
        "    y_true = []\n",
        "    with torch.no_grad():\n",
        "        for step, (X, Xchar, Y, xlen, xlen_char, xmask) in enumerate(loader):\n",
        "            Y = pack_padded_sequence(Y, xlen, batch_first=True, enforce_sorted=False)\n",
        "            Y, _ = pad_packed_sequence(Y, batch_first=True)\n",
        "            ypred = model(X.long().to(device), Xchar.to(device), xlen.to(device), xlen_char.to(device), xmask)#.permute(0, 2, 1)\n",
        "            # ypred = torch.argmax(ypred.to('cpu'), dim = 1)\n",
        "            ypred = ypred.view(Y.shape[0], -1)\n",
        "            # print(ypred.shape)\n",
        "\n",
        "            y_predicted.append(ypred)\n",
        "            y_true.append(Y)\n",
        "\n",
        "    y_predicted_list = []\n",
        "    y_true_list = []\n",
        "    for i in range(len(y_predicted)):\n",
        "        for j in range(y_predicted[i].shape[0]):\n",
        "            sent_pred = []\n",
        "            sent_true = []\n",
        "            for x in range(y_predicted[i].shape[1]):\n",
        "                sent_pred.append(id2tag[int(y_predicted[i][j, x])])\n",
        "                sent_true.append(id2tag[int(y_true[i][j, x])])\n",
        "            y_predicted_list.append(sent_pred)\n",
        "            y_true_list.append(sent_true)\n",
        "    # print(y_predicted_list[0:5])\n",
        "    # print(y_true_list[0:5])\n",
        "    return seq_f1_score(y_true_list, y_predicted_list), seq_accuracy_score(y_true_list, y_predicted_list), seq_classification_report(y_true_list, y_predicted_list, digits = 3)\n",
        "    #CONVERTING y_predicted and y_true lists into tag list\n",
        "    # return y_predicted, y_true\n",
        "\n",
        "\n",
        "# calculate the final metrics usign seq eval\n",
        "# TRAINING DATA\n",
        "loader_train = DataLoader(traindataset, batch_size= 1, shuffle=False)\n",
        "train_f1_conll, train_acc_conll, train_classif_report = final_metrics(model, loader_train)\n",
        "\n",
        "# VALIDATION DATA\n",
        "loader_valid = DataLoader(devdataset, batch_size= 1, shuffle=False)\n",
        "valid_f1_conll, valid_acc_conll, valid_classif_report = final_metrics(model, loader_valid)\n",
        "\n",
        "print(\"PERFORMANCE ON Train DATA\")\n",
        "print('MicroF1 = {} '.format(train_f1_conll))\n",
        "print('Accuracy = {}'.format(train_acc_conll))\n",
        "print('------------Classification Report-------------')\n",
        "print(train_classif_report)\n",
        "\n",
        "print(\"PERFORMANCE ON Validation DATA\")\n",
        "print('MicroF1 = {} '.format(valid_f1_conll))\n",
        "print('Accuracy = {}'.format(valid_acc_conll))\n",
        "print('------------Classification Report-------------')\n",
        "print(valid_classif_report)\n",
        "\n",
        "\n",
        "\n",
        "#Test DATASET\n",
        "testdatapath = \"/content/drive/MyDrive/Q2_DL/test.txt\"\n",
        "char_vocab = get_charvocab(vocab)\n",
        "Xtest, Ytest, x_testlengths, _, _ = load_data(testdatapath, buildvocab_tags=False, vocab = vocab, nertags = nertags)\n",
        "bin_mask_test =  get_mask(Xtest, x_testlengths)\n",
        "\n",
        "Xtest_temp, Ytest_temp, x_testlengths_temp, testvocab, testnertags = load_data(testdatapath, buildvocab_tags=True)\n",
        "wordid2word_charlevel_vocab_test, wordid2wordlen_test = make_id2word_charvocab(testvocab, char_vocab) # of the form {word:[1,2,3,4]}, {wordnum:wordlen}\n",
        "#make char level train data for the char embeddings \n",
        "Xtest_char, xtestlength_char = load_char_level(Xtest_temp, wordid2word_charlevel_vocab_test, wordid2wordlen_test)\n",
        "#finally make the dataloader for train\n",
        "testdataset = TensorDataset(Xtest, Xtest_char, Ytest, x_testlengths, xtestlength_char, bin_mask_test)\n",
        "loader_test = DataLoader(testdataset, batch_size= 1, shuffle=False)\n",
        "test_f1_conll, test_acc_conll, test_classif_report = final_metrics(model, loader_test)\n",
        "\n",
        "\n",
        "\n",
        "print(\"PERFORMANCE ON Test DATA\")\n",
        "print('MicroF1 = {}'.format(test_f1_conll))\n",
        "print('Accuracy = {}'.format(test_acc_conll))\n",
        "print('------------Classification Report-------------')\n",
        "print(test_classif_report)\n",
        "\n",
        "\n",
        "\"\"\"SAVING DATA\"\"\"\n",
        "\n",
        "# save performance metrics dictionaries\n",
        "# save train loss, acc, micro, macro\n",
        "# save val loss, acc, micro, macro\n",
        "# save model\n",
        "import pickle\n",
        "#train\n",
        "pickle.dump(train_classif_report, open(rootpath+Expname+\"/train_classif_report.dict.pickle\", \"wb\" ))\n",
        "np.save(rootpath+Expname+\"/train_losslist.npy\", np.asarray(trainlosslist))\n",
        "np.save(rootpath+Expname+\"/train_acclist.npy\", np.asarray(trainacclist))\n",
        "np.save(rootpath+Expname+\"/train_microf1list.npy\", np.asarray(trainmicrof1list))\n",
        "np.save(rootpath+Expname+\"/train_macrof1list.npy\", np.asarray(trainmacrof1list))\n",
        "\n",
        "#valid\n",
        "pickle.dump(valid_classif_report, open(rootpath+Expname+\"/valid_classif_report.dict.pickle\", \"wb\" ))\n",
        "np.save(rootpath+Expname+\"/val_losslist.npy\", np.asarray(validlosslist))\n",
        "np.save(rootpath+Expname+\"/val_acclist.npy\", np.asarray(valacclist))\n",
        "np.save(rootpath+Expname+\"/val_microf1list.npy\", np.asarray(valmicrof1list))\n",
        "np.save(rootpath+Expname+\"/val_macrof1list.npy\", np.asarray(valmacrof1list))\n",
        "\n",
        "#test\n",
        "pickle.dump(test_classif_report, open(rootpath+Expname+\"/test_classif_report.dict.pickle\", \"wb\" ))\n",
        "\n",
        "\n",
        "#Save Model\n",
        "torch.save(model, rootpath+Expname+\"/{}_model.pth\".format(Expname))    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training accuracy = 0.005125184094256259, microF1 = 0.005627064307450875, macroF1 = 0.00275946515734424\n",
            "training accuracy = 0.002625094292180035, microF1 = 0.0028821548891821555, macroF1 = 0.0014133845927860743\n",
            "training accuracy = 0.006021775482769899, microF1 = 0.009873425267867235, macroF1 = 0.004312784341986381\n",
            "training accuracy = 0.054227617627644824, microF1 = 0.08081208664970312, macroF1 = 0.029822521595619877\n",
            "training accuracy = 0.11378133318863705, microF1 = 0.1562706871081767, macroF1 = 0.05945195439788867\n",
            "training accuracy = 0.16590090939295105, microF1 = 0.2175493973851233, macroF1 = 0.08690591012509655\n",
            "training accuracy = 0.21116620411591047, microF1 = 0.26883988337954967, macroF1 = 0.1145962565212885\n",
            "training accuracy = 0.2500720623226848, microF1 = 0.31150870454408797, macroF1 = 0.13889609542995313\n",
            "training accuracy = 0.2820606835864971, microF1 = 0.34632058832937357, macroF1 = 0.16030063455971963\n",
            "training accuracy = 0.3111575594089963, microF1 = 0.37682461026665215, macroF1 = 0.17843250480920622\n",
            "training accuracy = 0.33694513519767655, microF1 = 0.40416116367800337, macroF1 = 0.19490934197669654\n",
            "training accuracy = 0.36018962167822344, microF1 = 0.4283174252154756, macroF1 = 0.20911866762468578\n",
            "training accuracy = 0.3804776157227996, microF1 = 0.44921735135749996, macroF1 = 0.22183234688831915\n",
            "training accuracy = 0.39744103583172996, microF1 = 0.4666302769349968, macroF1 = 0.2328538854923955\n",
            "\n",
            "epoch = 0, training_loss = 8.83555899944502, validation_loss =4.11212863381376, training_acc = 0.4058015357387855, validation_acc =0.6472538507675877\n",
            "training accuracy = 0.6472918479914779, microF1 = 0.722945017742242, macroF1 = 0.3927890419861268\n",
            "training accuracy = 0.6534856553293891, microF1 = 0.7268491555475267, macroF1 = 0.39436188398692246\n",
            "training accuracy = 0.6572894052297609, microF1 = 0.7287607676652403, macroF1 = 0.39400343033119933\n",
            "training accuracy = 0.6609178752804862, microF1 = 0.7311108617015263, macroF1 = 0.3945703136479185\n",
            "training accuracy = 0.6627246156900322, microF1 = 0.7324232201184475, macroF1 = 0.3955241087354158\n",
            "training accuracy = 0.6660336308402389, microF1 = 0.7353800005495266, macroF1 = 0.3973934180326934\n",
            "training accuracy = 0.6683139092916767, microF1 = 0.7374693291073774, macroF1 = 0.39901866085124854\n",
            "training accuracy = 0.6709410080939385, microF1 = 0.7398421207166164, macroF1 = 0.400698934195247\n",
            "training accuracy = 0.6736497429189995, microF1 = 0.7417839946033011, macroF1 = 0.40242143177106704\n",
            "training accuracy = 0.6766057734137735, microF1 = 0.7442313967698593, macroF1 = 0.40387390807778206\n",
            "training accuracy = 0.6794896756690242, microF1 = 0.7465639707636531, macroF1 = 0.405148595550153\n",
            "training accuracy = 0.6816089628788785, microF1 = 0.7482631219073338, macroF1 = 0.4063426431323747\n",
            "training accuracy = 0.6836733710251502, microF1 = 0.7497527658117193, macroF1 = 0.4074854257976027\n",
            "training accuracy = 0.6855221423234348, microF1 = 0.7510814881425404, macroF1 = 0.40855638511162123\n",
            "\n",
            "epoch = 1, training_loss = 2.9869101207280897, validation_loss =2.4433892178781256, training_acc = 0.6870076138137597, validation_acc =0.705641854939769\n",
            "training accuracy = 0.7135975108377443, microF1 = 0.7732533702981054, macroF1 = 0.4193526262645143\n",
            "training accuracy = 0.7179822521183052, microF1 = 0.7766505023999566, macroF1 = 0.42331061409367354\n",
            "training accuracy = 0.7184680309573541, microF1 = 0.7772388256614615, macroF1 = 0.42524880346159893\n",
            "training accuracy = 0.7216707729388105, microF1 = 0.780070738404332, macroF1 = 0.4272358534683323\n",
            "training accuracy = 0.7224995579298145, microF1 = 0.7804557852003419, macroF1 = 0.4275683051575116\n",
            "training accuracy = 0.7236449922300959, microF1 = 0.7808846958134725, macroF1 = 0.42900664345289724\n",
            "training accuracy = 0.724227000136168, microF1 = 0.781040979841728, macroF1 = 0.4290205671022737\n",
            "training accuracy = 0.7256511495329948, microF1 = 0.7820491401717549, macroF1 = 0.43093768398213156\n",
            "training accuracy = 0.7275358508242167, microF1 = 0.7833808303295909, macroF1 = 0.4327332364419912\n",
            "training accuracy = 0.7289608989554236, microF1 = 0.7846947497806289, macroF1 = 0.4334044342263852\n",
            "training accuracy = 0.7312969983665103, microF1 = 0.7864941459221647, macroF1 = 0.43479034117426435\n",
            "training accuracy = 0.7313384958479255, microF1 = 0.7864533298694282, macroF1 = 0.43489782917366787\n",
            "training accuracy = 0.7323350345477997, microF1 = 0.7872425797777862, macroF1 = 0.43512073959448283\n",
            "training accuracy = 0.7328383029659524, microF1 = 0.7876512981081601, macroF1 = 0.4353015989220635\n",
            "\n",
            "epoch = 2, training_loss = 1.6411685699859435, validation_loss =1.3807917483074148, training_acc = 0.7336267125203005, validation_acc =0.724616138460851\n",
            "training accuracy = 0.7455393705553817, microF1 = 0.7979259475480857, macroF1 = 0.4435513123710767\n",
            "training accuracy = 0.7528939214854683, microF1 = 0.8031352647961105, macroF1 = 0.4532000708857205\n",
            "training accuracy = 0.753855292013622, microF1 = 0.803882761265247, macroF1 = 0.45385002162374327\n",
            "training accuracy = 0.7531837200368093, microF1 = 0.8031885257396135, macroF1 = 0.4551583311392311\n",
            "training accuracy = 0.752458964590562, microF1 = 0.802751949807661, macroF1 = 0.4532605256594865\n",
            "training accuracy = 0.7535806327554313, microF1 = 0.803755430946506, macroF1 = 0.45553079355713993\n",
            "training accuracy = 0.7553430228980551, microF1 = 0.8054652746127395, macroF1 = 0.45518183986460115\n",
            "training accuracy = 0.7561525651049463, microF1 = 0.8060233794097864, macroF1 = 0.4545896808592567\n",
            "training accuracy = 0.7558245881225047, microF1 = 0.80568673253173, macroF1 = 0.4541723589086149\n",
            "training accuracy = 0.7567617507026658, microF1 = 0.8063578031723869, macroF1 = 0.45431109911005585\n",
            "training accuracy = 0.7568886416597524, microF1 = 0.8060744155079773, macroF1 = 0.4547719878987883\n",
            "training accuracy = 0.7571139489599924, microF1 = 0.8061886998931576, macroF1 = 0.45577862906534833\n",
            "training accuracy = 0.7580219625507719, microF1 = 0.8069062576299896, macroF1 = 0.4562485200699257\n",
            "training accuracy = 0.7585409967172163, microF1 = 0.8072582207679253, macroF1 = 0.4565484993133875\n",
            "\n",
            "epoch = 3, training_loss = 0.638452373163397, validation_loss =0.5332325160810628, training_acc = 0.7579591916240858, validation_acc =0.7584848765673347\n",
            "training accuracy = 0.7719623812045585, microF1 = 0.8169777630223216, macroF1 = 0.47452262475799956\n",
            "training accuracy = 0.7722946482988697, microF1 = 0.8169820329870159, macroF1 = 0.47132588143177384\n",
            "training accuracy = 0.7706131885874614, microF1 = 0.8153575390914295, macroF1 = 0.4661633249246982\n",
            "training accuracy = 0.7709763349521632, microF1 = 0.8159823857204929, macroF1 = 0.46524621428463014\n",
            "training accuracy = 0.7721819143918314, microF1 = 0.8168930088264261, macroF1 = 0.4679176830686715\n",
            "training accuracy = 0.7721458332905884, microF1 = 0.8171173631694232, macroF1 = 0.46870284376439336\n",
            "training accuracy = 0.7716319586499054, microF1 = 0.816562215970706, macroF1 = 0.4686760616913337\n",
            "training accuracy = 0.7722359298683737, microF1 = 0.8172257064579062, macroF1 = 0.47089841665264115\n",
            "training accuracy = 0.7716164564269882, microF1 = 0.8166306782774705, macroF1 = 0.47093189506458094\n",
            "training accuracy = 0.7718902185756399, microF1 = 0.8167409017770587, macroF1 = 0.47047527677460366\n",
            "training accuracy = 0.7720334621481851, microF1 = 0.8167249973389842, macroF1 = 0.4712340473600931\n",
            "training accuracy = 0.7725880903035504, microF1 = 0.8173201921008472, macroF1 = 0.4708971989754298\n",
            "training accuracy = 0.7731166700065876, microF1 = 0.8178927323558522, macroF1 = 0.4724096178413597\n",
            "training accuracy = 0.7733124925259582, microF1 = 0.8181335892118341, macroF1 = 0.4718133356759148\n",
            "\n",
            "epoch = 4, training_loss = -0.23113532113455415, validation_loss =-0.252619064192182, training_acc = 0.7732644811145758, validation_acc =0.7506789151058572\n",
            "training accuracy = 0.7869689921457272, microF1 = 0.828669457098346, macroF1 = 0.4846310585792484\n",
            "training accuracy = 0.7848378873851534, microF1 = 0.827111741125298, macroF1 = 0.4807950628360307\n",
            "training accuracy = 0.783739121127755, microF1 = 0.8256459929250349, macroF1 = 0.47666892342553313\n",
            "training accuracy = 0.7835137379002844, microF1 = 0.8257362760459704, macroF1 = 0.47460408541764976\n",
            "training accuracy = 0.7837287752922373, microF1 = 0.8263235519617473, macroF1 = 0.4763255458877205\n",
            "training accuracy = 0.7834163715489492, microF1 = 0.8262256943412598, macroF1 = 0.4782856322362361\n",
            "training accuracy = 0.7830489203265023, microF1 = 0.8260263022022479, macroF1 = 0.4780838763616261\n",
            "training accuracy = 0.7836477030123458, microF1 = 0.8265725241224602, macroF1 = 0.48005581142951204\n",
            "training accuracy = 0.7833315268916218, microF1 = 0.8262717698776157, macroF1 = 0.47956647291271665\n",
            "training accuracy = 0.7829130306253154, microF1 = 0.8257853644149133, macroF1 = 0.4805645046071522\n",
            "training accuracy = 0.7828364276151272, microF1 = 0.8255317961968711, macroF1 = 0.4798448293432008\n",
            "training accuracy = 0.7836098595004045, microF1 = 0.8262408987261696, macroF1 = 0.4809466097028556\n",
            "training accuracy = 0.7838008221481092, microF1 = 0.8263775056546611, macroF1 = 0.48073636268571207\n",
            "training accuracy = 0.7843907010123524, microF1 = 0.8269288733013431, macroF1 = 0.48184650764048254\n",
            "\n",
            "epoch = 5, training_loss = -1.0152751300035883, validation_loss =-0.9762258170191774, training_acc = 0.7845192988751897, validation_acc =0.7658005516251897\n",
            "training accuracy = 0.782975421246591, microF1 = 0.823217311449268, macroF1 = 0.4688225409786562\n",
            "training accuracy = 0.795913203400581, microF1 = 0.835955148034532, macroF1 = 0.47833964732448164\n",
            "training accuracy = 0.7935236892582092, microF1 = 0.8351790791185734, macroF1 = 0.4843337372793466\n",
            "training accuracy = 0.7944751262119264, microF1 = 0.8353305818481919, macroF1 = 0.48569178764624354\n",
            "training accuracy = 0.7913665210293853, microF1 = 0.8324617810333299, macroF1 = 0.48232756464108645\n",
            "training accuracy = 0.7912927120303339, microF1 = 0.8322017494505036, macroF1 = 0.48310531633576975\n",
            "training accuracy = 0.7920955817154264, microF1 = 0.8327043823866045, macroF1 = 0.48464888192910144\n",
            "training accuracy = 0.7919953850856164, microF1 = 0.8324066621766801, macroF1 = 0.4826974507291715\n",
            "training accuracy = 0.7926610019691942, microF1 = 0.8329205958560962, macroF1 = 0.4830443198847524\n",
            "training accuracy = 0.7933941204919295, microF1 = 0.8334639298514889, macroF1 = 0.4846323561363611\n",
            "training accuracy = 0.7936516722098678, microF1 = 0.8335914709184553, macroF1 = 0.48536654833117854\n",
            "training accuracy = 0.7939081480080137, microF1 = 0.8339047272962237, macroF1 = 0.48602855240027265\n",
            "training accuracy = 0.7939313665392751, microF1 = 0.8341024004477751, macroF1 = 0.48639312654070893\n",
            "training accuracy = 0.7934922776454617, microF1 = 0.8337033356546601, macroF1 = 0.4881905240501285\n",
            "\n",
            "epoch = 6, training_loss = -1.7534328703208477, validation_loss =-1.6731062648222619, training_acc = 0.7934360257445731, validation_acc =0.7624436488965736\n",
            "training accuracy = 0.8075488788911427, microF1 = 0.8448168120416591, macroF1 = 0.5010966263028762\n",
            "training accuracy = 0.8056552112467517, microF1 = 0.8429671678642471, macroF1 = 0.49895618498094796\n",
            "training accuracy = 0.8044071533599066, microF1 = 0.8429767099290182, macroF1 = 0.4964863025336364\n",
            "training accuracy = 0.8025337579294866, microF1 = 0.8413484380885193, macroF1 = 0.49368069724912345\n",
            "training accuracy = 0.8037784991409005, microF1 = 0.8422966594617514, macroF1 = 0.4961716556166726\n",
            "training accuracy = 0.8040179465048076, microF1 = 0.842461086348784, macroF1 = 0.4930607782460707\n",
            "training accuracy = 0.8051501226607476, microF1 = 0.8432345320222595, macroF1 = 0.4921555953262714\n",
            "training accuracy = 0.8057073494493034, microF1 = 0.8433191068147673, macroF1 = 0.4945065249801669\n",
            "training accuracy = 0.8053756506625022, microF1 = 0.8430752041613877, macroF1 = 0.49528607012574677\n",
            "training accuracy = 0.8045480922256141, microF1 = 0.842421367716869, macroF1 = 0.4962736145437429\n",
            "training accuracy = 0.803985175059567, microF1 = 0.8419739778540133, macroF1 = 0.4972131647281734\n",
            "training accuracy = 0.8038348252272788, microF1 = 0.8417250172462409, macroF1 = 0.49797081274159605\n",
            "training accuracy = 0.8044591981792137, microF1 = 0.8421661370228792, macroF1 = 0.4988204846325101\n",
            "training accuracy = 0.8044515958490593, microF1 = 0.842146203680666, macroF1 = 0.4990882396391015\n",
            "\n",
            "epoch = 7, training_loss = -2.4643777240182936, validation_loss =-2.2914059739751913, training_acc = 0.804280027577609, validation_acc =0.7736378033061367\n",
            "training accuracy = 0.808033566325867, microF1 = 0.8430470224788625, macroF1 = 0.488090468006643\n",
            "training accuracy = 0.8071802488113805, microF1 = 0.8429715354126595, macroF1 = 0.4970091360616709\n",
            "training accuracy = 0.8077109427842921, microF1 = 0.8439322651794383, macroF1 = 0.49088752739280234\n",
            "training accuracy = 0.8101618318126559, microF1 = 0.8459683022774626, macroF1 = 0.49168609424915843\n",
            "training accuracy = 0.810707834711836, microF1 = 0.8465399942960847, macroF1 = 0.4927968175008086\n",
            "training accuracy = 0.8092488085999967, microF1 = 0.8455861432486645, macroF1 = 0.4963010523252815\n",
            "training accuracy = 0.8082680357765306, microF1 = 0.8447142023948294, macroF1 = 0.4946152216327559\n",
            "training accuracy = 0.8075693487210193, microF1 = 0.8442283771819925, macroF1 = 0.49612982866074384\n",
            "training accuracy = 0.8075984377484944, microF1 = 0.8442836397578265, macroF1 = 0.4969982612539443\n",
            "training accuracy = 0.8077562070280774, microF1 = 0.8442057306493815, macroF1 = 0.4984548338845034\n",
            "training accuracy = 0.8080070671509336, microF1 = 0.8445450010452592, macroF1 = 0.49838239833559816\n",
            "training accuracy = 0.8086812878920159, microF1 = 0.8451026562728349, macroF1 = 0.5003229440886123\n",
            "training accuracy = 0.8089836052132698, microF1 = 0.8453381438551704, macroF1 = 0.5019223195890659\n",
            "training accuracy = 0.8093399246536424, microF1 = 0.8457408332600992, macroF1 = 0.5016024092531804\n",
            "\n",
            "epoch = 8, training_loss = -3.1438419515734277, validation_loss =-2.9674782408881435, training_acc = 0.809135185192639, validation_acc =0.7758037407555903\n",
            "training accuracy = 0.8137083922107503, microF1 = 0.8482621766388537, macroF1 = 0.4850887508232757\n",
            "training accuracy = 0.8156635886236792, microF1 = 0.8508796944402155, macroF1 = 0.49207029481920345\n",
            "training accuracy = 0.8162703541309397, microF1 = 0.8509927295808246, macroF1 = 0.49798336960043676\n",
            "training accuracy = 0.8152306047140433, microF1 = 0.8500070276504355, macroF1 = 0.49754048604274054\n",
            "training accuracy = 0.8152526369885137, microF1 = 0.8503888441107639, macroF1 = 0.5023025854843188\n",
            "training accuracy = 0.8159290380719318, microF1 = 0.8508840912899014, macroF1 = 0.5029835411864898\n",
            "training accuracy = 0.8153393023337231, microF1 = 0.8507486422911285, macroF1 = 0.5032530749869016\n",
            "training accuracy = 0.8162577173379711, microF1 = 0.8516019490831609, macroF1 = 0.5048798342745159\n",
            "training accuracy = 0.8170531556649181, microF1 = 0.8524384558858173, macroF1 = 0.5054087437330057\n",
            "training accuracy = 0.8164479883848955, microF1 = 0.8519433401710393, macroF1 = 0.505435417071166\n",
            "training accuracy = 0.8169711923581189, microF1 = 0.852240965844609, macroF1 = 0.5066746305545675\n",
            "training accuracy = 0.8166991588928895, microF1 = 0.8519196582216751, macroF1 = 0.5062854544748906\n",
            "training accuracy = 0.816155988991477, microF1 = 0.851391145435217, macroF1 = 0.5069582467564876\n",
            "training accuracy = 0.8165407919150863, microF1 = 0.851735578442788, macroF1 = 0.5075924119930104\n",
            "\n",
            "epoch = 9, training_loss = -3.8217257994556753, validation_loss =-3.5832132187086283, training_acc = 0.8164793425879425, validation_acc =0.7812962481375992\n",
            "training accuracy = 0.8182490391777496, microF1 = 0.8500243369855472, macroF1 = 0.4952260507914247\n",
            "training accuracy = 0.8206407028882522, microF1 = 0.853955034426651, macroF1 = 0.5134761210903007\n",
            "training accuracy = 0.8191837770264341, microF1 = 0.8537688765844557, macroF1 = 0.5124273995948972\n",
            "training accuracy = 0.82013357199844, microF1 = 0.8543928754904498, macroF1 = 0.5130783722247656\n",
            "training accuracy = 0.8216437984633517, microF1 = 0.8558029210612187, macroF1 = 0.5105950606842737\n",
            "training accuracy = 0.8225118436873148, microF1 = 0.8565664809410097, macroF1 = 0.5131804751119057\n",
            "training accuracy = 0.8220790850470476, microF1 = 0.8563459607217061, macroF1 = 0.5126209138037783\n",
            "training accuracy = 0.8219806792255955, microF1 = 0.8562900330733741, macroF1 = 0.5139015058685169\n",
            "training accuracy = 0.8215299610802049, microF1 = 0.855861778219541, macroF1 = 0.5144906687696221\n",
            "training accuracy = 0.8210039461836404, microF1 = 0.8554044895042064, macroF1 = 0.5163621457745027\n",
            "training accuracy = 0.8211920214508635, microF1 = 0.8556084085766925, macroF1 = 0.5162308756233627\n",
            "training accuracy = 0.8212637823928168, microF1 = 0.8555133530356208, macroF1 = 0.5160629828464963\n",
            "training accuracy = 0.8213963767142997, microF1 = 0.8554970378042126, macroF1 = 0.5169436417461825\n",
            "training accuracy = 0.8212908331482203, microF1 = 0.8554197531174418, macroF1 = 0.5170910209541109\n",
            "\n",
            "epoch = 10, training_loss = -4.479782863990548, validation_loss =-4.210671778806706, training_acc = 0.8215407170575502, validation_acc =0.7770623822839555\n",
            "training accuracy = 0.8292135890127975, microF1 = 0.8616671657234272, macroF1 = 0.5125146186861047\n",
            "training accuracy = 0.8260541740449932, microF1 = 0.8594025901310034, macroF1 = 0.5160475414856805\n",
            "training accuracy = 0.8253068261033701, microF1 = 0.8590245020909775, macroF1 = 0.52425872752194\n",
            "training accuracy = 0.8290499246313847, microF1 = 0.8618411913522517, macroF1 = 0.5242377658597651\n",
            "training accuracy = 0.8284070325531196, microF1 = 0.8614455190651635, macroF1 = 0.5242780479238791\n",
            "training accuracy = 0.8288700983603284, microF1 = 0.8615762211888194, macroF1 = 0.5246748284630842\n",
            "training accuracy = 0.829002202529775, microF1 = 0.8618511306333465, macroF1 = 0.5252938407906518\n",
            "training accuracy = 0.828033070805457, microF1 = 0.8607891090035792, macroF1 = 0.5246169418091027\n",
            "training accuracy = 0.828147505795376, microF1 = 0.8607879235932672, macroF1 = 0.5246100653806988\n",
            "training accuracy = 0.8272892330966547, microF1 = 0.8601129554268135, macroF1 = 0.5229480731946944\n",
            "training accuracy = 0.8275574726918765, microF1 = 0.8603461454750738, macroF1 = 0.524766196758075\n",
            "training accuracy = 0.8275901576976605, microF1 = 0.8602048064201073, macroF1 = 0.5229940704815018\n",
            "training accuracy = 0.8278772355801326, microF1 = 0.8605224154311024, macroF1 = 0.523442942328775\n",
            "training accuracy = 0.8276373452915136, microF1 = 0.8603801657507453, macroF1 = 0.5232272454324135\n",
            "\n",
            "epoch = 11, training_loss = -5.126782038777145, validation_loss =-4.8281532317092735, training_acc = 0.8278542190698338, validation_acc =0.7785817767630223\n",
            "training accuracy = 0.8305906080090715, microF1 = 0.8641052909961353, macroF1 = 0.5114727801013459\n",
            "training accuracy = 0.8357667425326082, microF1 = 0.8667624119916455, macroF1 = 0.5152717113844428\n",
            "training accuracy = 0.833100785436159, microF1 = 0.8644329622283037, macroF1 = 0.5155764374857172\n",
            "training accuracy = 0.8320743272697653, microF1 = 0.8639338156810205, macroF1 = 0.5191348233054206\n",
            "training accuracy = 0.8338789616791603, microF1 = 0.8647616868217252, macroF1 = 0.523663980529314\n",
            "training accuracy = 0.8332483307063091, microF1 = 0.8641718000812167, macroF1 = 0.5204057043423909\n",
            "training accuracy = 0.8325085974767583, microF1 = 0.8635513782528843, macroF1 = 0.5222886526677656\n",
            "training accuracy = 0.8330680882276142, microF1 = 0.8640378265347037, macroF1 = 0.5247473476386308\n",
            "training accuracy = 0.8330223716868329, microF1 = 0.8640643682878802, macroF1 = 0.5253802586095319\n",
            "training accuracy = 0.8336455211595676, microF1 = 0.8646215803788856, macroF1 = 0.5250933579052296\n",
            "training accuracy = 0.8331575764910994, microF1 = 0.8644003063773313, macroF1 = 0.5236692054362607\n",
            "training accuracy = 0.8325185124866992, microF1 = 0.8640520534792456, macroF1 = 0.5226814653696347\n",
            "training accuracy = 0.8325594291341949, microF1 = 0.8641493682272756, macroF1 = 0.5241743833195797\n",
            "training accuracy = 0.8326689065729675, microF1 = 0.8642940555698644, macroF1 = 0.5234475911080667\n",
            "\n",
            "epoch = 12, training_loss = -5.7642501375519535, validation_loss =-5.447781990483864, training_acc = 0.832620701517777, validation_acc =0.7798408073635135\n",
            "training accuracy = 0.8344130401857005, microF1 = 0.8667228332184319, macroF1 = 0.5594195592045935\n",
            "training accuracy = 0.8402740617779478, microF1 = 0.8711994404824202, macroF1 = 0.5423271100913843\n",
            "training accuracy = 0.8389343039113033, microF1 = 0.8696087011247353, macroF1 = 0.5368780434916623\n",
            "training accuracy = 0.8392198059507848, microF1 = 0.8696036480620487, macroF1 = 0.5391255906980618\n",
            "training accuracy = 0.8387806777331568, microF1 = 0.8692850231915881, macroF1 = 0.5360590992875238\n",
            "training accuracy = 0.8379913482541502, microF1 = 0.8687096292145401, macroF1 = 0.538305389991736\n",
            "training accuracy = 0.8376249529756724, microF1 = 0.8683397951121211, macroF1 = 0.5343797012953222\n",
            "training accuracy = 0.8373021516783883, microF1 = 0.8681240840934358, macroF1 = 0.5341523076969781\n",
            "training accuracy = 0.8376913020862337, microF1 = 0.8683591141927446, macroF1 = 0.5375941404886163\n",
            "training accuracy = 0.8376019104345274, microF1 = 0.8681355343598889, macroF1 = 0.5371331847603708\n",
            "training accuracy = 0.8381991102743767, microF1 = 0.8684980919007084, macroF1 = 0.5364204851663719\n",
            "training accuracy = 0.8375240849684501, microF1 = 0.8680172823054105, macroF1 = 0.5365188568278614\n",
            "training accuracy = 0.8375141968535693, microF1 = 0.8680251432587113, macroF1 = 0.5369880703040817\n",
            "training accuracy = 0.8375246576698233, microF1 = 0.8681007710686107, macroF1 = 0.5363803842062292\n",
            "\n",
            "epoch = 13, training_loss = -6.3967091471878526, validation_loss =-6.011556428732331, training_acc = 0.8374138621356599, validation_acc =0.7863588638728443\n",
            "training accuracy = 0.8521906688791664, microF1 = 0.8813268591413874, macroF1 = 0.5658745881278897\n",
            "training accuracy = 0.847286161775708, microF1 = 0.877138405753083, macroF1 = 0.565452889453142\n",
            "training accuracy = 0.8431425820483668, microF1 = 0.8733597315779331, macroF1 = 0.5544484952889125\n",
            "training accuracy = 0.8447518088829575, microF1 = 0.8746553901089534, macroF1 = 0.5534913485915776\n",
            "training accuracy = 0.842641057542517, microF1 = 0.8731723910997214, macroF1 = 0.5519160360208805\n",
            "training accuracy = 0.8428317680223855, microF1 = 0.873178748278747, macroF1 = 0.5498154914600043\n",
            "training accuracy = 0.84311015981268, microF1 = 0.8735860939303716, macroF1 = 0.5493914131223535\n",
            "training accuracy = 0.8427232895616946, microF1 = 0.87322795933793, macroF1 = 0.5471019319369798\n",
            "training accuracy = 0.8423797052478407, microF1 = 0.872852992363404, macroF1 = 0.5436352831339282\n",
            "training accuracy = 0.8415173474819515, microF1 = 0.8720322013649553, macroF1 = 0.5425133940626543\n",
            "training accuracy = 0.8404716030551976, microF1 = 0.8709914804283455, macroF1 = 0.5422282178406045\n",
            "training accuracy = 0.8412619127232838, microF1 = 0.871487491587275, macroF1 = 0.540759316646157\n",
            "training accuracy = 0.8415021925186299, microF1 = 0.8716374976574947, macroF1 = 0.5398476453653104\n",
            "training accuracy = 0.8426964987555897, microF1 = 0.8725634535594557, macroF1 = 0.53977376831767\n",
            "\n",
            "epoch = 14, training_loss = -7.021046125602067, validation_loss =-6.619488961917838, training_acc = 0.84246990968926, validation_acc =0.7834446623425692\n",
            "training accuracy = 0.8377167864218242, microF1 = 0.8673725361079275, macroF1 = 0.5417953694998943\n",
            "training accuracy = 0.8430212415026769, microF1 = 0.8718222278636613, macroF1 = 0.5497989270340006\n",
            "training accuracy = 0.8416230959579992, microF1 = 0.8712271445132099, macroF1 = 0.5408757771265684\n",
            "training accuracy = 0.8414315741265431, microF1 = 0.8713055529728725, macroF1 = 0.5373021695455221\n",
            "training accuracy = 0.843751708982746, microF1 = 0.8734554666794798, macroF1 = 0.5437259155982184\n",
            "training accuracy = 0.8428087534619557, microF1 = 0.8722889920642213, macroF1 = 0.5452998805378705\n",
            "training accuracy = 0.843155982684331, microF1 = 0.8727820845322158, macroF1 = 0.5460059231917308\n",
            "training accuracy = 0.8436970815236605, microF1 = 0.8732429214158098, macroF1 = 0.5470940241261997\n",
            "training accuracy = 0.8435177749574377, microF1 = 0.8730564662268003, macroF1 = 0.5467991423485693\n",
            "training accuracy = 0.8436279710810255, microF1 = 0.8732292076069879, macroF1 = 0.5454060252665767\n",
            "training accuracy = 0.8438822746984902, microF1 = 0.8733224107914284, macroF1 = 0.54552632273255\n",
            "training accuracy = 0.8434584947740964, microF1 = 0.872999306589046, macroF1 = 0.5448146394612741\n",
            "training accuracy = 0.8432210037737667, microF1 = 0.8727348699737129, macroF1 = 0.5455730227174078\n",
            "training accuracy = 0.8429884571991291, microF1 = 0.8725098672387838, macroF1 = 0.5449729165485209\n",
            "\n",
            "epoch = 15, training_loss = -7.648094386988899, validation_loss =-7.222122698715053, training_acc = 0.8431132097329694, validation_acc =0.7809595396089246\n",
            "training accuracy = 0.849375881327745, microF1 = 0.8763099331523314, macroF1 = 0.5420927857445277\n",
            "training accuracy = 0.8473452871026003, microF1 = 0.8760614175784701, macroF1 = 0.5389705999056115\n",
            "training accuracy = 0.8474773708343147, microF1 = 0.8760985837410694, macroF1 = 0.5370013522656882\n",
            "training accuracy = 0.8465299666189956, microF1 = 0.8750924978418564, macroF1 = 0.5409798127400484\n",
            "training accuracy = 0.8468834644350668, microF1 = 0.8752924612755686, macroF1 = 0.5421145005290666\n",
            "training accuracy = 0.8470674755338302, microF1 = 0.8755015645713021, macroF1 = 0.542665205345429\n",
            "training accuracy = 0.847159013905776, microF1 = 0.8755397376816553, macroF1 = 0.5448024459013301\n",
            "training accuracy = 0.8479616955058191, microF1 = 0.8763676160101187, macroF1 = 0.546096853175976\n",
            "training accuracy = 0.8482287032068694, microF1 = 0.8764742187623696, macroF1 = 0.5478372483916681\n",
            "training accuracy = 0.8488221417409116, microF1 = 0.8770823820031739, macroF1 = 0.5495626511596913\n",
            "training accuracy = 0.8491151635995674, microF1 = 0.8772255116711707, macroF1 = 0.5475888730552537\n",
            "training accuracy = 0.8485871405076626, microF1 = 0.8769284391107358, macroF1 = 0.5469171873019635\n",
            "training accuracy = 0.8478389855272284, microF1 = 0.876324781394095, macroF1 = 0.5472089807018028\n",
            "training accuracy = 0.8479886202136014, microF1 = 0.8764422141548065, macroF1 = 0.5475134054214931\n",
            "\n",
            "epoch = 16, training_loss = -8.265160698251625, validation_loss =-7.817169936661868, training_acc = 0.8476017149713556, validation_acc =0.7898146893842122\n",
            "training accuracy = 0.8434085576357113, microF1 = 0.8716589452000902, macroF1 = 0.5300733019376577\n",
            "training accuracy = 0.8494568624882622, microF1 = 0.8764121863343286, macroF1 = 0.5562262778313117\n",
            "training accuracy = 0.8493378407463907, microF1 = 0.8765947640585157, macroF1 = 0.5567814474864153\n",
            "training accuracy = 0.8486348999236369, microF1 = 0.8760394022218072, macroF1 = 0.5513743984902408\n",
            "training accuracy = 0.8479035574394912, microF1 = 0.8757161126376997, macroF1 = 0.5504140899185306\n",
            "training accuracy = 0.8484622033303886, microF1 = 0.876627308004974, macroF1 = 0.5516330314494587\n",
            "training accuracy = 0.8500533108011041, microF1 = 0.8780753187237329, macroF1 = 0.5517480984667741\n",
            "training accuracy = 0.8492920625095154, microF1 = 0.8772300356650401, macroF1 = 0.5528610257934484\n",
            "training accuracy = 0.8490985186980067, microF1 = 0.8770448355678115, macroF1 = 0.5517678118228009\n",
            "training accuracy = 0.8487194436025162, microF1 = 0.8766610565981775, macroF1 = 0.5523977231294874\n",
            "training accuracy = 0.8485631846328437, microF1 = 0.876573278574738, macroF1 = 0.5500866486036201\n",
            "training accuracy = 0.8489170174128221, microF1 = 0.876923108314527, macroF1 = 0.549681483942167\n",
            "training accuracy = 0.8491600685104558, microF1 = 0.8769541479831542, macroF1 = 0.5496347586080816\n",
            "training accuracy = 0.8496159647844136, microF1 = 0.877396326455997, macroF1 = 0.5487407444812737\n",
            "\n",
            "epoch = 17, training_loss = -8.87792660362532, validation_loss =-8.363623540426039, training_acc = 0.8497778065072682, validation_acc =0.7900831512330401\n",
            "training accuracy = 0.8525172367524524, microF1 = 0.8810537394082893, macroF1 = 0.5679781726971387\n",
            "training accuracy = 0.8585426069192038, microF1 = 0.8848202131419978, macroF1 = 0.5593008871633677\n",
            "training accuracy = 0.8598763797282493, microF1 = 0.8854323439719454, macroF1 = 0.5601914204951297\n",
            "training accuracy = 0.8583031037819271, microF1 = 0.8835720549402856, macroF1 = 0.5652830167466182\n",
            "training accuracy = 0.8571953978589131, microF1 = 0.8827743543801535, macroF1 = 0.5621539763756592\n",
            "training accuracy = 0.8574273158530857, microF1 = 0.8828975303699662, macroF1 = 0.5553910551573945\n",
            "training accuracy = 0.8560842149214558, microF1 = 0.881895156601864, macroF1 = 0.5535388791996696\n",
            "training accuracy = 0.8564420421225623, microF1 = 0.8825522777983461, macroF1 = 0.5514138083575792\n",
            "training accuracy = 0.8554175007318451, microF1 = 0.8818909573244745, macroF1 = 0.5533489980385886\n",
            "training accuracy = 0.855145850471507, microF1 = 0.881705772773095, macroF1 = 0.5536458805362545\n",
            "training accuracy = 0.8551103666760743, microF1 = 0.8815265997636533, macroF1 = 0.5532057027122097\n",
            "training accuracy = 0.8556022765333822, microF1 = 0.8819908932252948, macroF1 = 0.5522603499673261\n",
            "training accuracy = 0.8555868591007756, microF1 = 0.8821136331728262, macroF1 = 0.5529650498229591\n",
            "training accuracy = 0.8558770994047988, microF1 = 0.8825178450701139, macroF1 = 0.5539016975439176\n",
            "\n",
            "epoch = 18, training_loss = -9.494114099089632, validation_loss =-8.957616835525355, training_acc = 0.8558209873377308, validation_acc =0.788462692559667\n",
            "training accuracy = 0.8602693985873124, microF1 = 0.8868889152998106, macroF1 = 0.5692849349482516\n",
            "training accuracy = 0.8575653758497814, microF1 = 0.8843093922863218, macroF1 = 0.5690827748230572\n",
            "training accuracy = 0.8583223257486826, microF1 = 0.8846007792994076, macroF1 = 0.5631274404769864\n",
            "training accuracy = 0.8590024606433806, microF1 = 0.8852965060524094, macroF1 = 0.5664411907879201\n",
            "training accuracy = 0.8598172442043837, microF1 = 0.8861319405101721, macroF1 = 0.5658842667644829\n",
            "training accuracy = 0.8597389625683418, microF1 = 0.8861631585309214, macroF1 = 0.5658901149877359\n",
            "training accuracy = 0.8603012093800619, microF1 = 0.886380090157407, macroF1 = 0.5706704546898945\n",
            "training accuracy = 0.8600817671521881, microF1 = 0.8862069847074334, macroF1 = 0.5682371291809942\n",
            "training accuracy = 0.8593843078499083, microF1 = 0.8854674213654674, macroF1 = 0.5688172459461135\n",
            "training accuracy = 0.8594188760779008, microF1 = 0.8853332265970928, macroF1 = 0.5702371597017011\n",
            "training accuracy = 0.8591423747610915, microF1 = 0.8852498148468014, macroF1 = 0.5683622625052672\n",
            "training accuracy = 0.8588204651607565, microF1 = 0.8850763132295285, macroF1 = 0.5660136420707719\n",
            "training accuracy = 0.8588566276428378, microF1 = 0.8853019939292818, macroF1 = 0.5673618226646472\n",
            "training accuracy = 0.858644433229501, microF1 = 0.8851046571999132, macroF1 = 0.5667124355599529\n",
            "\n",
            "epoch = 19, training_loss = -10.104629120056572, validation_loss =-9.548518869065747, training_acc = 0.8586542630655859, validation_acc =0.7927130869936112\n",
            "training accuracy = 0.8650613750273364, microF1 = 0.8891010916675809, macroF1 = 0.5824594037507058\n",
            "training accuracy = 0.8632923749790896, microF1 = 0.8876464045136471, macroF1 = 0.5643760054371949\n",
            "training accuracy = 0.8637603491760472, microF1 = 0.8883039843523778, macroF1 = 0.5625235873907733\n",
            "training accuracy = 0.8620369525976007, microF1 = 0.8870005926123625, macroF1 = 0.5648654062581637\n",
            "training accuracy = 0.8620438285346862, microF1 = 0.8868509108694604, macroF1 = 0.561517621729766\n",
            "training accuracy = 0.8615757260141971, microF1 = 0.8866067185634355, macroF1 = 0.5636603493567793\n",
            "training accuracy = 0.8614503025474498, microF1 = 0.8863922462869757, macroF1 = 0.5626478783386724\n",
            "training accuracy = 0.8609122529634217, microF1 = 0.8861496952052633, macroF1 = 0.5645310347687975\n",
            "training accuracy = 0.8609710504634381, microF1 = 0.8864634392747235, macroF1 = 0.5655268579478925\n",
            "training accuracy = 0.8608801890795725, microF1 = 0.8863371980504806, macroF1 = 0.567242462510371\n",
            "training accuracy = 0.8609667724014468, microF1 = 0.8863710193576183, macroF1 = 0.567438007754588\n",
            "training accuracy = 0.8611652297242436, microF1 = 0.8866751296374427, macroF1 = 0.56746067682485\n",
            "training accuracy = 0.861901391560866, microF1 = 0.88738379202852, macroF1 = 0.566552157256123\n",
            "training accuracy = 0.8618550494222847, microF1 = 0.8873285268268034, macroF1 = 0.56528592371044\n",
            "\n",
            "epoch = 20, training_loss = -10.707952171666516, validation_loss =-10.127345832352786, training_acc = 0.8617389872164137, validation_acc =0.7947846351882134\n",
            "training accuracy = 0.8755096389417748, microF1 = 0.8982070835673672, macroF1 = 0.5797554643336872\n",
            "training accuracy = 0.8710516956929855, microF1 = 0.8952885696470386, macroF1 = 0.5648903982313245\n",
            "training accuracy = 0.8683001133590376, microF1 = 0.8925590328666855, macroF1 = 0.5641634134189878\n",
            "training accuracy = 0.8657799010832767, microF1 = 0.8905206174064605, macroF1 = 0.5607621004137459\n",
            "training accuracy = 0.8675629257316639, microF1 = 0.8919372235916788, macroF1 = 0.5636664789714195\n",
            "training accuracy = 0.8666315785730505, microF1 = 0.8913333976510143, macroF1 = 0.564592512646906\n",
            "training accuracy = 0.8649078043671314, microF1 = 0.889881861213326, macroF1 = 0.5668339943704256\n",
            "training accuracy = 0.8641617524233628, microF1 = 0.8893772581788917, macroF1 = 0.5650897723882334\n",
            "training accuracy = 0.8645355154950218, microF1 = 0.8895146747493039, macroF1 = 0.5643725097481881\n",
            "training accuracy = 0.8646030288934046, microF1 = 0.8894755263782707, macroF1 = 0.564734957082164\n",
            "training accuracy = 0.8650335582877208, microF1 = 0.8898493524023818, macroF1 = 0.5677347770080085\n",
            "training accuracy = 0.865136615559787, microF1 = 0.8898377929466189, macroF1 = 0.5671063395812568\n",
            "training accuracy = 0.8646241066777781, microF1 = 0.8893696513138833, macroF1 = 0.565569501078937\n",
            "training accuracy = 0.8644767897019031, microF1 = 0.8893113244646084, macroF1 = 0.5646995393369406\n",
            "\n",
            "epoch = 21, training_loss = -11.318436645560249, validation_loss =-10.701383580866548, training_acc = 0.8644057901508481, validation_acc =0.7905428681570259\n",
            "training accuracy = 0.8636959399359224, microF1 = 0.8889372343584613, macroF1 = 0.5666981534343678\n",
            "training accuracy = 0.8646693227020992, microF1 = 0.8914518217289717, macroF1 = 0.5635980224576131\n",
            "training accuracy = 0.8648325060637243, microF1 = 0.8905031603758204, macroF1 = 0.5596896109583298\n",
            "training accuracy = 0.8651058297836016, microF1 = 0.8904524564707649, macroF1 = 0.562446018577648\n",
            "training accuracy = 0.8649326078469395, microF1 = 0.890415569253037, macroF1 = 0.5615881156700521\n",
            "training accuracy = 0.8638766057695824, microF1 = 0.8893604796537802, macroF1 = 0.5630184126492993\n",
            "training accuracy = 0.8640059795587709, microF1 = 0.8892738263326474, macroF1 = 0.5655905067278651\n",
            "training accuracy = 0.8648543581746917, microF1 = 0.8899466309938544, macroF1 = 0.5634516497604203\n",
            "training accuracy = 0.865437353354298, microF1 = 0.8904764532769585, macroF1 = 0.5666510617619662\n",
            "training accuracy = 0.8653061327788664, microF1 = 0.8902182649221159, macroF1 = 0.5665030261052121\n",
            "training accuracy = 0.8652277592260647, microF1 = 0.8901157529694786, macroF1 = 0.5680389957760917\n",
            "training accuracy = 0.8654085022505726, microF1 = 0.8903652797082113, macroF1 = 0.5671515241052392\n",
            "training accuracy = 0.8656801030078649, microF1 = 0.8905603879480568, macroF1 = 0.5681956514297509\n",
            "training accuracy = 0.8663952433740568, microF1 = 0.8912103459490709, macroF1 = 0.5689398101414936\n",
            "\n",
            "epoch = 22, training_loss = -11.921416256435958, validation_loss =-11.254247724395437, training_acc = 0.8666081231810009, validation_acc =0.7851494686149785\n",
            "training accuracy = 0.8712225099412353, microF1 = 0.8953807674206561, macroF1 = 0.5589720447481874\n",
            "training accuracy = 0.8704071129867419, microF1 = 0.8939979296750612, macroF1 = 0.561316600525498\n",
            "training accuracy = 0.870991851544541, microF1 = 0.8945127065552256, macroF1 = 0.5749999368074026\n",
            "training accuracy = 0.8720858740177042, microF1 = 0.8955443545896091, macroF1 = 0.5755124767384638\n",
            "training accuracy = 0.8725442375430296, microF1 = 0.8960460538803506, macroF1 = 0.5710229487687093\n",
            "training accuracy = 0.8721337911947828, microF1 = 0.895662751932502, macroF1 = 0.5732026136446976\n",
            "training accuracy = 0.8710993060105757, microF1 = 0.8949133949157309, macroF1 = 0.5704275043612043\n",
            "training accuracy = 0.8706879825530749, microF1 = 0.8944388970469644, macroF1 = 0.5716701217416107\n",
            "training accuracy = 0.8700103330303128, microF1 = 0.8938031089914399, macroF1 = 0.5678274585082398\n",
            "training accuracy = 0.8698278007785261, microF1 = 0.893665699924438, macroF1 = 0.5688415916599182\n",
            "training accuracy = 0.8702632440534859, microF1 = 0.8941742070921179, macroF1 = 0.567656462079887\n",
            "training accuracy = 0.8704756274494768, microF1 = 0.894432639399272, macroF1 = 0.5690831340057426\n",
            "training accuracy = 0.8712695910558818, microF1 = 0.8950846898078443, macroF1 = 0.5706616281804343\n",
            "training accuracy = 0.8709197974010834, microF1 = 0.8947837074148176, macroF1 = 0.5726513542189574\n",
            "\n",
            "epoch = 23, training_loss = -12.530202796778728, validation_loss =-11.839417447748872, training_acc = 0.8710450870092734, validation_acc =0.7941033453748054\n",
            "training accuracy = 0.8770425945691871, microF1 = 0.9009704104387294, macroF1 = 0.6042258135570785\n",
            "training accuracy = 0.8747385338357034, microF1 = 0.8980497049609604, macroF1 = 0.5908048500881103\n",
            "training accuracy = 0.8750585341111806, microF1 = 0.8980390672384192, macroF1 = 0.5822150226663437\n",
            "training accuracy = 0.8735894966638775, microF1 = 0.8967963733902388, macroF1 = 0.5820508507182978\n",
            "training accuracy = 0.8737657032877908, microF1 = 0.8969369383566481, macroF1 = 0.5804551959878683\n",
            "training accuracy = 0.8758297875989276, microF1 = 0.8986714328760081, macroF1 = 0.5831426769822134\n",
            "training accuracy = 0.8754330956217683, microF1 = 0.8982880827647863, macroF1 = 0.5852288920448493\n",
            "training accuracy = 0.875747405029745, microF1 = 0.8985748189876293, macroF1 = 0.5891485414526392\n",
            "training accuracy = 0.8756676199891366, microF1 = 0.8984961722046337, macroF1 = 0.5875263614130466\n",
            "training accuracy = 0.8754229361501736, microF1 = 0.8980933227062917, macroF1 = 0.5845382243345043\n",
            "training accuracy = 0.8741507393725046, microF1 = 0.8970250793561392, macroF1 = 0.5816520639370385\n",
            "training accuracy = 0.8738396546707827, microF1 = 0.896731305784129, macroF1 = 0.5806340399947633\n",
            "training accuracy = 0.8733779651988895, microF1 = 0.8963504337719326, macroF1 = 0.5803542232797924\n",
            "training accuracy = 0.8739231517416403, microF1 = 0.8969176949808368, macroF1 = 0.5790424337861579\n",
            "\n",
            "epoch = 24, training_loss = -13.137240963703169, validation_loss =-12.405824582601332, training_acc = 0.8741015393013571, validation_acc =0.7893538608970264\n",
            "training accuracy = 0.8739066075984571, microF1 = 0.8966717729540001, macroF1 = 0.5673195209712181\n",
            "training accuracy = 0.8759732000529217, microF1 = 0.8980501231560031, macroF1 = 0.5760141262815454\n",
            "training accuracy = 0.8762331404027259, microF1 = 0.8993875998519444, macroF1 = 0.5754529062728356\n",
            "training accuracy = 0.8761807709982551, microF1 = 0.8987423681149782, macroF1 = 0.569937925981909\n",
            "training accuracy = 0.8764407743313654, microF1 = 0.8994335555929099, macroF1 = 0.5716488186458901\n",
            "training accuracy = 0.8763809695861369, microF1 = 0.8995339656176408, macroF1 = 0.5754989845830442\n",
            "training accuracy = 0.8746951235620944, microF1 = 0.8979921474487507, macroF1 = 0.5723417955315157\n",
            "training accuracy = 0.8758605249950928, microF1 = 0.8989486847090067, macroF1 = 0.5782551777065286\n",
            "training accuracy = 0.8752117434560581, microF1 = 0.8981028240031833, macroF1 = 0.5780931529393813\n",
            "training accuracy = 0.8744096469342525, microF1 = 0.897517346625881, macroF1 = 0.5775778781966964\n",
            "training accuracy = 0.8743320052552315, microF1 = 0.8974540385496744, macroF1 = 0.5795843456745736\n",
            "training accuracy = 0.8749247775845992, microF1 = 0.897978732210831, macroF1 = 0.5805134291624221\n",
            "training accuracy = 0.8749014243870747, microF1 = 0.8979794269622733, macroF1 = 0.5796521997594951\n",
            "training accuracy = 0.8748146388073974, microF1 = 0.8978773973719044, macroF1 = 0.579642872480801\n",
            "\n",
            "epoch = 25, training_loss = -13.733504016784458, validation_loss =-12.98430066256179, training_acc = 0.8745525260301775, validation_acc =0.7919445172352984\n",
            "training accuracy = 0.8869343038863339, microF1 = 0.9055186476367508, macroF1 = 0.5924819537737496\n",
            "training accuracy = 0.8847553724736915, microF1 = 0.905027021604042, macroF1 = 0.5824576696383926\n",
            "training accuracy = 0.8847134921796503, microF1 = 0.9048940613335827, macroF1 = 0.5821434670770403\n",
            "training accuracy = 0.882868126225201, microF1 = 0.9034478975971383, macroF1 = 0.5754725344003693\n",
            "training accuracy = 0.882197460690279, microF1 = 0.9033537953268709, macroF1 = 0.5774751704481959\n",
            "training accuracy = 0.8806880320441635, microF1 = 0.9021446562155062, macroF1 = 0.5749313265622189\n",
            "training accuracy = 0.8796861489556272, microF1 = 0.9011906514427367, macroF1 = 0.5755106795121653\n",
            "training accuracy = 0.8792836956978922, microF1 = 0.9010986571165389, macroF1 = 0.5782404630574262\n",
            "training accuracy = 0.8784575310192891, microF1 = 0.9003506165691317, macroF1 = 0.5780561830614855\n",
            "training accuracy = 0.8789824207702674, microF1 = 0.900846493994382, macroF1 = 0.5835570609872937\n",
            "training accuracy = 0.8792235091812621, microF1 = 0.9010762666861948, macroF1 = 0.5834978819956437\n",
            "training accuracy = 0.8784832838421407, microF1 = 0.9004518936530753, macroF1 = 0.5830410741243132\n",
            "training accuracy = 0.878485311169771, microF1 = 0.9005634343427336, macroF1 = 0.583811462856018\n",
            "training accuracy = 0.8783664724681106, microF1 = 0.9004179233740551, macroF1 = 0.5848393124314507\n",
            "\n",
            "epoch = 26, training_loss = -14.337854254286723, validation_loss =-13.557140252024857, training_acc = 0.8784422119051412, validation_acc =0.7866109290211121\n",
            "training accuracy = 0.8838217474299613, microF1 = 0.9036239929785527, macroF1 = 0.5837175434575296\n",
            "training accuracy = 0.8870938475402982, microF1 = 0.9069070008222224, macroF1 = 0.5891746206761465\n",
            "training accuracy = 0.8826819672144411, microF1 = 0.903308306514839, macroF1 = 0.5913936130243961\n",
            "training accuracy = 0.8820131549354171, microF1 = 0.9030772896962472, macroF1 = 0.5859080739882543\n",
            "training accuracy = 0.8819888160249838, microF1 = 0.9031336489693638, macroF1 = 0.5934892457428159\n",
            "training accuracy = 0.8809192720336856, microF1 = 0.9023269152207222, macroF1 = 0.5898675287677846\n",
            "training accuracy = 0.8814196928390446, microF1 = 0.9029298407832937, macroF1 = 0.5879233079236454\n",
            "training accuracy = 0.8813484473727516, microF1 = 0.9026966602947198, macroF1 = 0.5875102255269534\n",
            "training accuracy = 0.8813575284474137, microF1 = 0.9028270730972003, macroF1 = 0.5857807318133018\n",
            "training accuracy = 0.881551186666562, microF1 = 0.9029449194596179, macroF1 = 0.5853195021437225\n",
            "training accuracy = 0.881369643956367, microF1 = 0.9027984993344546, macroF1 = 0.5870304761579085\n",
            "training accuracy = 0.8809854936283487, microF1 = 0.9024340750999769, macroF1 = 0.5866882896590507\n",
            "training accuracy = 0.8810513643923656, microF1 = 0.9024491597572966, macroF1 = 0.5866753600328874\n",
            "training accuracy = 0.8803731101150423, microF1 = 0.9018195705387649, macroF1 = 0.5865508719005459\n",
            "\n",
            "epoch = 27, training_loss = -14.931909308810415, validation_loss =-14.128958407136583, training_acc = 0.8804246500147868, validation_acc =0.7923599845493903\n",
            "training accuracy = 0.8820095568843449, microF1 = 0.9042248068588896, macroF1 = 0.6001778541201284\n",
            "training accuracy = 0.8800759701846141, microF1 = 0.9014654383249732, macroF1 = 0.5990546047522713\n",
            "training accuracy = 0.8812316200372943, microF1 = 0.9025750699815549, macroF1 = 0.6028269128080523\n",
            "training accuracy = 0.8811833996311449, microF1 = 0.9023982959700295, macroF1 = 0.5999708286205769\n",
            "training accuracy = 0.8791604674958828, microF1 = 0.901073722194744, macroF1 = 0.5976021493217525\n",
            "training accuracy = 0.8788395573401726, microF1 = 0.900828664435563, macroF1 = 0.5967108716817345\n",
            "training accuracy = 0.879824587334341, microF1 = 0.9014908076630413, macroF1 = 0.5971988480199457\n",
            "training accuracy = 0.8789473771973744, microF1 = 0.9006688321855808, macroF1 = 0.5965629496656327\n",
            "training accuracy = 0.8799028117837213, microF1 = 0.9013275971479028, macroF1 = 0.5980029150992193\n",
            "training accuracy = 0.8802154464677343, microF1 = 0.9015951266635565, macroF1 = 0.5982301554601483\n",
            "training accuracy = 0.8805480914126187, microF1 = 0.9020264941741079, macroF1 = 0.5962210479496742\n",
            "training accuracy = 0.880538649781463, microF1 = 0.9019937442999458, macroF1 = 0.5931011995150676\n",
            "training accuracy = 0.8810414409712747, microF1 = 0.902398715271903, macroF1 = 0.5915057274782796\n",
            "training accuracy = 0.8810126676184423, microF1 = 0.9023084744524844, macroF1 = 0.5925202255724226\n",
            "\n",
            "epoch = 28, training_loss = -15.532811748203134, validation_loss =-14.687150394793639, training_acc = 0.8809203597211506, validation_acc =0.7968716246497173\n",
            "training accuracy = 0.8852779259707284, microF1 = 0.9068998900638703, macroF1 = 0.5782450957455025\n",
            "training accuracy = 0.8851677870272265, microF1 = 0.9070353701554218, macroF1 = 0.5868300228120188\n",
            "training accuracy = 0.88434953325991, microF1 = 0.9058579611236286, macroF1 = 0.5917058180319948\n",
            "training accuracy = 0.8851813290496141, microF1 = 0.9062973479170305, macroF1 = 0.5939961747002972\n",
            "training accuracy = 0.8845141699395543, microF1 = 0.9059344031101253, macroF1 = 0.5958358848746024\n",
            "training accuracy = 0.8843371087232013, microF1 = 0.9052745401691206, macroF1 = 0.5971083058213535\n",
            "training accuracy = 0.8843490181312412, microF1 = 0.9051180635273779, macroF1 = 0.5935871057613342\n",
            "training accuracy = 0.8844926092305396, microF1 = 0.9052592905666177, macroF1 = 0.5957626733953538\n",
            "training accuracy = 0.8849903328826408, microF1 = 0.9054949761877731, macroF1 = 0.5974137551107512\n",
            "training accuracy = 0.8843255040908817, microF1 = 0.9050765470762833, macroF1 = 0.5952334207501415\n",
            "training accuracy = 0.8853407278265224, microF1 = 0.9058722031903648, macroF1 = 0.594940141935611\n",
            "training accuracy = 0.8856780001860926, microF1 = 0.9062157037612312, macroF1 = 0.5959446629094646\n",
            "training accuracy = 0.8852181988736593, microF1 = 0.9059103363204609, macroF1 = 0.5958252137779155\n",
            "training accuracy = 0.8849659722644743, microF1 = 0.9056143695495212, macroF1 = 0.5977793330877356\n",
            "\n",
            "epoch = 29, training_loss = -16.119668799986954, validation_loss =-15.250364165945152, training_acc = 0.8844996842037143, validation_acc =0.7888539066446347\n",
            "training accuracy = 0.8857036091873257, microF1 = 0.9074547647865605, macroF1 = 0.5906736385083464\n",
            "training accuracy = 0.8850361100030951, microF1 = 0.9063170792101634, macroF1 = 0.5975873324147585\n",
            "training accuracy = 0.8845532477873038, microF1 = 0.9058509707678712, macroF1 = 0.6021022698341885\n",
            "training accuracy = 0.8870455250951376, microF1 = 0.9075658828553709, macroF1 = 0.6058910685279307\n",
            "training accuracy = 0.8872614535851113, microF1 = 0.9076997784731905, macroF1 = 0.6034307188675845\n",
            "training accuracy = 0.8873225447140438, microF1 = 0.9079450651948544, macroF1 = 0.6051556559676412\n",
            "training accuracy = 0.8869653678420529, microF1 = 0.9075203218415645, macroF1 = 0.5990598057657661\n",
            "training accuracy = 0.8863226677984468, microF1 = 0.9070205118920779, macroF1 = 0.5981893079337709\n",
            "training accuracy = 0.8868406259814995, microF1 = 0.9072252415565639, macroF1 = 0.5985005015713586\n",
            "training accuracy = 0.8870165360197977, microF1 = 0.9073978451361498, macroF1 = 0.5985210980985066\n",
            "training accuracy = 0.8867152649171578, microF1 = 0.9072518431144555, macroF1 = 0.5957602850253765\n",
            "training accuracy = 0.8866864646179523, microF1 = 0.9072660438276391, macroF1 = 0.5961154427596626\n",
            "training accuracy = 0.8863725732935656, microF1 = 0.9069833440079891, macroF1 = 0.5992224159621247\n",
            "training accuracy = 0.8869888347385559, microF1 = 0.9074664712464788, macroF1 = 0.5996490191105033\n",
            "\n",
            "epoch = 30, training_loss = -16.72321423140588, validation_loss =-15.83385127352685, training_acc = 0.887119666068658, validation_acc =0.7882913121288804\n",
            "training accuracy = 0.8885456883823603, microF1 = 0.909046631653599, macroF1 = 0.615267488115032\n",
            "training accuracy = 0.8895021311784989, microF1 = 0.9094890918520884, macroF1 = 0.5958997857171517\n",
            "training accuracy = 0.8896459720479357, microF1 = 0.9100167190228401, macroF1 = 0.5944935682628533\n",
            "training accuracy = 0.8895702227227313, microF1 = 0.9100759657529771, macroF1 = 0.600811452395296\n",
            "training accuracy = 0.8900081001469451, microF1 = 0.9103916357129739, macroF1 = 0.6042762737185887\n",
            "training accuracy = 0.8878349423972104, microF1 = 0.9082463504451359, macroF1 = 0.6019254477918998\n",
            "training accuracy = 0.8877505525214526, microF1 = 0.9079744312212072, macroF1 = 0.602826557343703\n",
            "training accuracy = 0.8874143894273527, microF1 = 0.9076293142569123, macroF1 = 0.6005850318487718\n",
            "training accuracy = 0.8873279079578368, microF1 = 0.9075119734654618, macroF1 = 0.5979533857508459\n",
            "training accuracy = 0.8874343130619469, microF1 = 0.9076684351304116, macroF1 = 0.5962786985998767\n",
            "training accuracy = 0.8871502945283641, microF1 = 0.9073988490656171, macroF1 = 0.5965966317545824\n",
            "training accuracy = 0.8866575754206387, microF1 = 0.9072100400648062, macroF1 = 0.5980541451345645\n",
            "training accuracy = 0.8862221938175112, microF1 = 0.9068208488360192, macroF1 = 0.5992057260706285\n",
            "training accuracy = 0.8859782254890323, microF1 = 0.9066041876618008, macroF1 = 0.5976736651864861\n",
            "\n",
            "epoch = 31, training_loss = -17.30994208162183, validation_loss =-16.393223477393082, training_acc = 0.8859004298188352, validation_acc =0.7948736200726106\n",
            "training accuracy = 0.8956685324348218, microF1 = 0.9146493986768515, macroF1 = 0.5929194984221073\n",
            "training accuracy = 0.891741175833329, microF1 = 0.9102156266090483, macroF1 = 0.5854216157353603\n",
            "training accuracy = 0.8922991254946636, microF1 = 0.9112679047107312, macroF1 = 0.5857481073075353\n",
            "training accuracy = 0.8920122399711706, microF1 = 0.9112813709771961, macroF1 = 0.5878902041072339\n",
            "training accuracy = 0.8931063180038691, microF1 = 0.9124194818075081, macroF1 = 0.5882005209854495\n",
            "training accuracy = 0.8927089069658265, microF1 = 0.9121667495410561, macroF1 = 0.5899720069307144\n",
            "training accuracy = 0.8916145282034652, microF1 = 0.911151842995577, macroF1 = 0.5895178219766898\n",
            "training accuracy = 0.8912516435280514, microF1 = 0.9109176696959904, macroF1 = 0.5894075922896491\n",
            "training accuracy = 0.8913328664369302, microF1 = 0.9109953259593826, macroF1 = 0.5941254418583091\n",
            "training accuracy = 0.8907503977735759, microF1 = 0.910455210320097, macroF1 = 0.5962960037094837\n",
            "training accuracy = 0.8913690054940835, microF1 = 0.9109141981034045, macroF1 = 0.5967909957969136\n",
            "training accuracy = 0.8916377895993518, microF1 = 0.9110766623141348, macroF1 = 0.5986796351129012\n",
            "training accuracy = 0.891814384380057, microF1 = 0.9111459386150713, macroF1 = 0.5992275319794571\n",
            "training accuracy = 0.892115518474368, microF1 = 0.9114272017270636, macroF1 = 0.59935533787672\n",
            "\n",
            "epoch = 32, training_loss = -17.907178596942284, validation_loss =-16.944621626863775, training_acc = 0.8919542364377355, validation_acc =0.7944440252203154\n",
            "training accuracy = 0.896501411973909, microF1 = 0.9154573948216095, macroF1 = 0.5934258095939144\n",
            "training accuracy = 0.89459163743744, microF1 = 0.9131083956590229, macroF1 = 0.6021783746576554\n",
            "training accuracy = 0.8949564057355889, microF1 = 0.913997548522251, macroF1 = 0.6126691823523484\n",
            "training accuracy = 0.8943898628934561, microF1 = 0.9131103242336492, macroF1 = 0.6012061128007947\n",
            "training accuracy = 0.895690839336438, microF1 = 0.9140188293203363, macroF1 = 0.6035451511550547\n",
            "training accuracy = 0.8957667486913176, microF1 = 0.9141419744845751, macroF1 = 0.6057810109849089\n",
            "training accuracy = 0.8935028140271095, microF1 = 0.9123244968961481, macroF1 = 0.6062370614910191\n",
            "training accuracy = 0.8927919354814337, microF1 = 0.9117341020231725, macroF1 = 0.6102020441028319\n",
            "training accuracy = 0.8931264235890892, microF1 = 0.9118399549140653, macroF1 = 0.608895862083064\n",
            "training accuracy = 0.8935493049764046, microF1 = 0.912288757030756, macroF1 = 0.6117633823805512\n",
            "training accuracy = 0.8932493203903028, microF1 = 0.9120457706950396, macroF1 = 0.6111352749612218\n",
            "training accuracy = 0.893351215486133, microF1 = 0.9122364945823921, macroF1 = 0.6085916289856206\n",
            "training accuracy = 0.8929326239029339, microF1 = 0.9119538533652489, macroF1 = 0.6059985269105418\n",
            "training accuracy = 0.8927309982773903, microF1 = 0.9117083169891259, macroF1 = 0.6051870121743361\n",
            "\n",
            "epoch = 33, training_loss = -18.505818684895832, validation_loss =-17.540708364899626, training_acc = 0.8926613730892998, validation_acc =0.7971313084222414\n",
            "training accuracy = 0.9001781565239342, microF1 = 0.9177013986607573, macroF1 = 0.5936959797448453\n",
            "training accuracy = 0.8986515860902525, microF1 = 0.9166941622641033, macroF1 = 0.5866955313807019\n",
            "training accuracy = 0.8973740030747276, microF1 = 0.9158465368749413, macroF1 = 0.5930449462657393\n",
            "training accuracy = 0.8966770046726795, microF1 = 0.9147076395877605, macroF1 = 0.5976508907694265\n",
            "training accuracy = 0.8961190309646252, microF1 = 0.9141852998324033, macroF1 = 0.6012001977172868\n",
            "training accuracy = 0.8960460348301508, microF1 = 0.9143021594135546, macroF1 = 0.606279800083384\n",
            "training accuracy = 0.8961435742596392, microF1 = 0.9144743449836211, macroF1 = 0.6057931404599833\n",
            "training accuracy = 0.895834260909656, microF1 = 0.914070807239906, macroF1 = 0.607758824115353\n",
            "training accuracy = 0.8955313568270029, microF1 = 0.913823957458812, macroF1 = 0.607419793064447\n",
            "training accuracy = 0.8958350466621859, microF1 = 0.9140503209460175, macroF1 = 0.609570867541263\n",
            "training accuracy = 0.8951295377190575, microF1 = 0.9133746754981468, macroF1 = 0.610159793788481\n",
            "training accuracy = 0.8946713615545203, microF1 = 0.912911440971789, macroF1 = 0.6110104911087801\n",
            "training accuracy = 0.8949836182324191, microF1 = 0.913165716088222, macroF1 = 0.6082117916897997\n",
            "training accuracy = 0.8952353841374149, microF1 = 0.9134701084261454, macroF1 = 0.6095720665273012\n",
            "\n",
            "epoch = 34, training_loss = -19.091581678882086, validation_loss =-18.101117989451616, training_acc = 0.8948202007120873, validation_acc =0.7941935287826654\n",
            "training accuracy = 0.9019880920430868, microF1 = 0.9188638421717333, macroF1 = 0.5822643856690429\n",
            "training accuracy = 0.9000797117691918, microF1 = 0.9176088918031015, macroF1 = 0.5939388084188012\n",
            "training accuracy = 0.8994508825659956, microF1 = 0.9170157696302499, macroF1 = 0.6071220542937376\n",
            "training accuracy = 0.9009365658264611, microF1 = 0.918098020774478, macroF1 = 0.6122546130553189\n",
            "training accuracy = 0.8998325526417146, microF1 = 0.9173426197847043, macroF1 = 0.6098542023524717\n",
            "training accuracy = 0.9002046671190178, microF1 = 0.917910308635256, macroF1 = 0.6112653365337155\n",
            "training accuracy = 0.9004538053917582, microF1 = 0.9179140848021691, macroF1 = 0.6125880333186655\n",
            "training accuracy = 0.8992610061995678, microF1 = 0.9167868822773115, macroF1 = 0.6112831501872639\n",
            "training accuracy = 0.8987330081948842, microF1 = 0.9164331502499166, macroF1 = 0.6107044033483505\n",
            "training accuracy = 0.8987950683093802, microF1 = 0.9164856231608651, macroF1 = 0.6129083013941494\n",
            "training accuracy = 0.8990754387254053, microF1 = 0.9169264449499814, macroF1 = 0.6147101901813152\n",
            "training accuracy = 0.8984044013000725, microF1 = 0.9163305493371181, macroF1 = 0.6162720975818697\n",
            "training accuracy = 0.8987071309541185, microF1 = 0.9165608205346771, macroF1 = 0.6156849325189588\n",
            "training accuracy = 0.8984709674777304, microF1 = 0.9163570301920008, macroF1 = 0.6153727255482256\n",
            "\n",
            "epoch = 35, training_loss = -19.462250942217114, validation_loss =-18.147398879847575, training_acc = 0.8987334096318966, validation_acc =0.7919360869188812\n",
            "training accuracy = 0.9043286189601641, microF1 = 0.9208616617565578, macroF1 = 0.6365740197720334\n",
            "training accuracy = 0.9044306354235692, microF1 = 0.9212795323033777, macroF1 = 0.6186762193968652\n",
            "training accuracy = 0.9026561770527116, microF1 = 0.9201180887715918, macroF1 = 0.6152230942089691\n",
            "training accuracy = 0.9001284580607345, microF1 = 0.9180678341338168, macroF1 = 0.6148123496396634\n",
            "training accuracy = 0.8996005374612921, microF1 = 0.9174243899197416, macroF1 = 0.6148255028656116\n",
            "training accuracy = 0.9003768908795411, microF1 = 0.9178924160800187, macroF1 = 0.6194641357269659\n",
            "training accuracy = 0.9012717943611296, microF1 = 0.9185712233215959, macroF1 = 0.6188218260890832\n",
            "training accuracy = 0.9012602136873143, microF1 = 0.91867223146418, macroF1 = 0.6224001790553514\n",
            "training accuracy = 0.9012129566719976, microF1 = 0.9185143567960059, macroF1 = 0.6245506063084273\n",
            "training accuracy = 0.9013565238825275, microF1 = 0.9186925670421637, macroF1 = 0.6225147540544003\n",
            "training accuracy = 0.9012672924141333, microF1 = 0.9186819151119138, macroF1 = 0.6235106128533361\n",
            "training accuracy = 0.9013483946022889, microF1 = 0.9188273599689859, macroF1 = 0.6212912720241821\n",
            "training accuracy = 0.9012314372042741, microF1 = 0.9187348645144849, macroF1 = 0.6205542849311115\n",
            "training accuracy = 0.9005551539171921, microF1 = 0.9180838103087371, macroF1 = 0.6172152506516178\n",
            "\n",
            "epoch = 36, training_loss = -19.523576041677153, validation_loss =-18.20154894012766, training_acc = 0.9005984503543267, validation_acc =0.792857361248404\n",
            "training accuracy = 0.9000122394462899, microF1 = 0.9174835340036225, macroF1 = 0.6315030014762486\n",
            "training accuracy = 0.8989216285980113, microF1 = 0.9160025211316226, macroF1 = 0.6220517722861978\n",
            "training accuracy = 0.8991517142179142, microF1 = 0.9168287771073107, macroF1 = 0.6205418151502656\n",
            "training accuracy = 0.8995043305606685, microF1 = 0.9169531392454399, macroF1 = 0.616796222540053\n",
            "training accuracy = 0.8990143517681831, microF1 = 0.9166900864534224, macroF1 = 0.6200238723151053\n",
            "training accuracy = 0.8992383660778372, microF1 = 0.9169198310859326, macroF1 = 0.6192889639571247\n",
            "training accuracy = 0.8999901366368572, microF1 = 0.917419424224662, macroF1 = 0.6150490638277711\n",
            "training accuracy = 0.8998534549430967, microF1 = 0.9175604597874063, macroF1 = 0.6156564735057246\n",
            "training accuracy = 0.9010373586598929, microF1 = 0.9185296519022117, macroF1 = 0.6175160813582667\n",
            "training accuracy = 0.9008896665074613, microF1 = 0.9183498257961114, macroF1 = 0.6147619040442859\n",
            "training accuracy = 0.9011444362361024, microF1 = 0.9185276649714553, macroF1 = 0.6148551765176155\n",
            "training accuracy = 0.9009846224297551, microF1 = 0.9183750191356399, macroF1 = 0.617071152948704\n",
            "training accuracy = 0.9011571008806194, microF1 = 0.9185481244270756, macroF1 = 0.6180194306284498\n",
            "training accuracy = 0.9015339298168336, microF1 = 0.9188074396575416, macroF1 = 0.6164382383718068\n",
            "\n",
            "epoch = 37, training_loss = -19.59889295256834, validation_loss =-18.256272660088293, training_acc = 0.9010981512592724, validation_acc =0.7949787172685562\n",
            "training accuracy = 0.906460774326235, microF1 = 0.9226766742293739, macroF1 = 0.6250799340943306\n",
            "training accuracy = 0.9066307597780313, microF1 = 0.9232754718772992, macroF1 = 0.6368045922302682\n",
            "training accuracy = 0.9072000928819337, microF1 = 0.9240556386724343, macroF1 = 0.629418066676826\n",
            "training accuracy = 0.9065135400101414, microF1 = 0.9233697900987997, macroF1 = 0.6285175244132712\n",
            "training accuracy = 0.9059642031700341, microF1 = 0.9229728168145822, macroF1 = 0.622504677362442\n",
            "training accuracy = 0.9054978437490027, microF1 = 0.9223680363684329, macroF1 = 0.6227606623948432\n",
            "training accuracy = 0.9045358662174136, microF1 = 0.9216694704683633, macroF1 = 0.6219729191389364\n",
            "training accuracy = 0.9044120620268081, microF1 = 0.9213861361616461, macroF1 = 0.6217902949809897\n",
            "training accuracy = 0.9043790035580637, microF1 = 0.9212698645768265, macroF1 = 0.6219895456234162\n",
            "training accuracy = 0.904157838371119, microF1 = 0.9213210552323619, macroF1 = 0.6258662384413081\n",
            "training accuracy = 0.9036606671364147, microF1 = 0.9208136119801598, macroF1 = 0.6237974647240432\n",
            "training accuracy = 0.9036038888581931, microF1 = 0.9208513474159562, macroF1 = 0.6224123921268142\n",
            "training accuracy = 0.9029578040484858, microF1 = 0.9202884998037505, macroF1 = 0.622669635518691\n",
            "training accuracy = 0.9030878611960406, microF1 = 0.9203825067061545, macroF1 = 0.6218287085294063\n",
            "\n",
            "epoch = 38, training_loss = -19.654193229282026, validation_loss =-18.29415425566054, training_acc = 0.9027183788078165, validation_acc =0.7936152545951091\n",
            "training accuracy = 0.90081639545251, microF1 = 0.9186405764621568, macroF1 = 0.5876717832194495\n",
            "training accuracy = 0.8999309870332065, microF1 = 0.9173733838026568, macroF1 = 0.6084765779046157\n",
            "training accuracy = 0.8999557538140673, microF1 = 0.9168215979081635, macroF1 = 0.6131045422449133\n",
            "training accuracy = 0.9010098092206026, microF1 = 0.9176267612925305, macroF1 = 0.6216294740336986\n",
            "training accuracy = 0.9003904742856543, microF1 = 0.9173016030804535, macroF1 = 0.621492868870287\n",
            "training accuracy = 0.901435013122267, microF1 = 0.9185149027204828, macroF1 = 0.6258276803341423\n",
            "training accuracy = 0.9020094938118108, microF1 = 0.9189963781535462, macroF1 = 0.6213832502418316\n",
            "training accuracy = 0.9014094380974951, microF1 = 0.9185894956635335, macroF1 = 0.6206048619536897\n",
            "training accuracy = 0.9022804583129135, microF1 = 0.9191584385018875, macroF1 = 0.620063181541274\n",
            "training accuracy = 0.9018875481785513, microF1 = 0.918823449067372, macroF1 = 0.6180489348368274\n",
            "training accuracy = 0.9017419045191774, microF1 = 0.9187623726051849, macroF1 = 0.617225416961439\n",
            "training accuracy = 0.9019267731383386, microF1 = 0.9190389193670097, macroF1 = 0.618211689927991\n",
            "training accuracy = 0.9021563544417124, microF1 = 0.9192034944557792, macroF1 = 0.6152910179864975\n",
            "training accuracy = 0.9025364554605153, microF1 = 0.9196820077168784, macroF1 = 0.6181334709454117\n",
            "\n",
            "epoch = 39, training_loss = -19.708216250966913, validation_loss =-18.3778991305951, training_acc = 0.9025860038814977, validation_acc =0.7968214948976458\n",
            "training accuracy = 0.8990245469687053, microF1 = 0.915377601823119, macroF1 = 0.6070473344339772\n",
            "training accuracy = 0.9027918912234617, microF1 = 0.919524898973402, macroF1 = 0.6043760842771949\n",
            "training accuracy = 0.9001172729578863, microF1 = 0.9174565474292056, macroF1 = 0.6064337127763243\n",
            "training accuracy = 0.8994909868879216, microF1 = 0.9166721243416123, macroF1 = 0.6122155176728442\n",
            "training accuracy = 0.8999299142245956, microF1 = 0.9172530366471319, macroF1 = 0.6092828168599942\n",
            "training accuracy = 0.9001956816135329, microF1 = 0.9173799203086604, macroF1 = 0.6066204425129558\n",
            "training accuracy = 0.900483045739056, microF1 = 0.917662478638883, macroF1 = 0.6100407015562179\n",
            "training accuracy = 0.9013228272663983, microF1 = 0.9185311576233905, macroF1 = 0.6094674458277667\n",
            "training accuracy = 0.9012101965788486, microF1 = 0.9185756640890437, macroF1 = 0.6125290930263595\n",
            "training accuracy = 0.9013881453533172, microF1 = 0.9187285623608897, macroF1 = 0.6141586054391325\n",
            "training accuracy = 0.901498672422787, microF1 = 0.9189650170909169, macroF1 = 0.6162680986694533\n",
            "training accuracy = 0.9014327843363945, microF1 = 0.9189905117832463, macroF1 = 0.6169560875377142\n",
            "training accuracy = 0.9010784176619188, microF1 = 0.9187644930465914, macroF1 = 0.6152833831543305\n",
            "training accuracy = 0.9012007022253541, microF1 = 0.918839518033937, macroF1 = 0.6156993737903493\n",
            "\n",
            "epoch = 40, training_loss = -19.764425998700855, validation_loss =-18.410699549409532, training_acc = 0.9014426495868719, validation_acc =0.7917213100828274\n",
            "training accuracy = 0.9035299053515375, microF1 = 0.9216636859736445, macroF1 = 0.6423914921789572\n",
            "training accuracy = 0.9016965807362333, microF1 = 0.919862940862789, macroF1 = 0.6330242206592526\n",
            "training accuracy = 0.9038692126306999, microF1 = 0.9211252259711086, macroF1 = 0.628953758221905\n",
            "training accuracy = 0.9012646101253704, microF1 = 0.9186979902016291, macroF1 = 0.623022468727761\n",
            "training accuracy = 0.9020786754662842, microF1 = 0.919211587546447, macroF1 = 0.6213150351492699\n",
            "training accuracy = 0.9029674788640075, microF1 = 0.9201557281460067, macroF1 = 0.6235333452498796\n",
            "training accuracy = 0.9030103332054054, microF1 = 0.9202772336430924, macroF1 = 0.6256291119772905\n",
            "training accuracy = 0.9039365551994051, microF1 = 0.9207894987812278, macroF1 = 0.6227000008544165\n",
            "training accuracy = 0.9041326806069335, microF1 = 0.920946970040729, macroF1 = 0.6213098021044039\n",
            "training accuracy = 0.903853778398811, microF1 = 0.9208075116411429, macroF1 = 0.622656823253845\n",
            "training accuracy = 0.9045855065285348, microF1 = 0.9213221104749802, macroF1 = 0.6210476568723121\n",
            "training accuracy = 0.9047746790380541, microF1 = 0.9215848107895792, macroF1 = 0.6211152894313532\n",
            "training accuracy = 0.9043623236931542, microF1 = 0.9212693479878318, macroF1 = 0.6210714396442234\n",
            "training accuracy = 0.9041855060001093, microF1 = 0.921078967831084, macroF1 = 0.6218340631239352\n",
            "\n",
            "epoch = 41, training_loss = -19.844063919434433, validation_loss =-18.47084106366659, training_acc = 0.9043107938983285, validation_acc =0.7915865738925765\n",
            "training accuracy = 0.8988313572998066, microF1 = 0.9176828788657039, macroF1 = 0.6200640139008909\n",
            "training accuracy = 0.9023265328682364, microF1 = 0.9196833096765094, macroF1 = 0.6228301440917571\n",
            "training accuracy = 0.9022304960253705, microF1 = 0.9194892506959738, macroF1 = 0.6058879444450327\n",
            "training accuracy = 0.9025073453471745, microF1 = 0.9198500839151509, macroF1 = 0.6057273466027712\n",
            "training accuracy = 0.9020827938676735, microF1 = 0.9194011330756634, macroF1 = 0.6046513991462784\n",
            "training accuracy = 0.9026491022713024, microF1 = 0.9199140003461564, macroF1 = 0.6111001152966988\n",
            "training accuracy = 0.9030929875924634, microF1 = 0.9200522549437, macroF1 = 0.6156099244823993\n",
            "training accuracy = 0.9028976671506059, microF1 = 0.9199291621838706, macroF1 = 0.6127143979778118\n",
            "training accuracy = 0.9031715412680512, microF1 = 0.9203449116743674, macroF1 = 0.6154580778206405\n",
            "training accuracy = 0.903358966081994, microF1 = 0.9203378124868455, macroF1 = 0.6181034984400788\n",
            "training accuracy = 0.902491662179581, microF1 = 0.9195623812405235, macroF1 = 0.6189060909635767\n",
            "training accuracy = 0.9023279287294811, microF1 = 0.919395490455003, macroF1 = 0.6189969008289078\n",
            "training accuracy = 0.9024107704555218, microF1 = 0.9192785591925628, macroF1 = 0.618163572572337\n",
            "training accuracy = 0.9032460376051368, microF1 = 0.9199977637805978, macroF1 = 0.6169921417084282\n",
            "\n",
            "epoch = 42, training_loss = -19.89386643085283, validation_loss =-18.538762613670112, training_acc = 0.9031248820659143, validation_acc =0.7938426528674696\n",
            "training accuracy = 0.9011592050941282, microF1 = 0.9174363953966663, macroF1 = 0.5949818220939136\n",
            "training accuracy = 0.9039067507680819, microF1 = 0.9200633210655708, macroF1 = 0.6114073262939382\n",
            "training accuracy = 0.9026249668021927, microF1 = 0.9193128982251892, macroF1 = 0.6105748714565643\n",
            "training accuracy = 0.9026364279898409, microF1 = 0.9193413122296014, macroF1 = 0.6151012921560179\n",
            "training accuracy = 0.9031144513916856, microF1 = 0.9198874564267066, macroF1 = 0.6205477951101858\n",
            "training accuracy = 0.9023796608584465, microF1 = 0.9195054736876005, macroF1 = 0.6189672752841768\n",
            "training accuracy = 0.9019536760116109, microF1 = 0.919313473680883, macroF1 = 0.6162064840650631\n",
            "training accuracy = 0.9022758972285443, microF1 = 0.9195730079356389, macroF1 = 0.6157406711402227\n",
            "training accuracy = 0.9025012518620302, microF1 = 0.9197658047767284, macroF1 = 0.6143684837525466\n",
            "training accuracy = 0.9022489220610809, microF1 = 0.9196004080171477, macroF1 = 0.6133367365076579\n",
            "training accuracy = 0.9022544534200012, microF1 = 0.9195871592355928, macroF1 = 0.6135815836649429\n",
            "training accuracy = 0.9022595584452663, microF1 = 0.9195086680339389, macroF1 = 0.613045303453848\n",
            "training accuracy = 0.902418382785282, microF1 = 0.919722660183092, macroF1 = 0.6122383176854977\n",
            "training accuracy = 0.9026328338093749, microF1 = 0.9199254651991909, macroF1 = 0.6118235481964069\n",
            "\n",
            "epoch = 43, training_loss = -19.954761111859195, validation_loss =-18.592083724503663, training_acc = 0.9028533678971414, validation_acc =0.7944281130884461\n",
            "training accuracy = 0.9034515781159346, microF1 = 0.9221403518219893, macroF1 = 0.6191829151527957\n",
            "training accuracy = 0.9025625107915921, microF1 = 0.9202863851610876, macroF1 = 0.6154474578365409\n",
            "training accuracy = 0.9015679391404946, microF1 = 0.9196316622016313, macroF1 = 0.6197475377740478\n",
            "training accuracy = 0.9021331680807908, microF1 = 0.9198172164306303, macroF1 = 0.6110653277407414\n",
            "training accuracy = 0.9034387705457467, microF1 = 0.920569869386863, macroF1 = 0.6112681724501892\n",
            "training accuracy = 0.904258928310533, microF1 = 0.9213039320366838, macroF1 = 0.6120922802147054\n",
            "training accuracy = 0.9042726281352048, microF1 = 0.9211537068597834, macroF1 = 0.6119153653659486\n",
            "training accuracy = 0.904513298197186, microF1 = 0.9210726478101955, macroF1 = 0.6140918580184503\n",
            "training accuracy = 0.9040499082441871, microF1 = 0.9207854085064533, macroF1 = 0.613181084016522\n",
            "training accuracy = 0.9032032670866353, microF1 = 0.9202764470059895, macroF1 = 0.6127353571243923\n",
            "training accuracy = 0.9034005863009595, microF1 = 0.920409592412923, macroF1 = 0.6137444331648088\n",
            "training accuracy = 0.9028783462669225, microF1 = 0.9200339231008116, macroF1 = 0.6146719056814463\n",
            "training accuracy = 0.9030116216085783, microF1 = 0.9200606752777325, macroF1 = 0.6140459254570756\n",
            "training accuracy = 0.9027392112177035, microF1 = 0.9198044291298121, macroF1 = 0.613890863597107\n",
            "\n",
            "epoch = 44, training_loss = -20.013494550567312, validation_loss =-18.650363784475424, training_acc = 0.903143320710144, validation_acc =0.795402512162078\n",
            "training accuracy = 0.908247066303373, microF1 = 0.9250586452185084, macroF1 = 0.6044441457357224\n",
            "training accuracy = 0.9090663255256646, microF1 = 0.9244868376674845, macroF1 = 0.6192063050329075\n",
            "training accuracy = 0.9087471864447333, microF1 = 0.9240629797280199, macroF1 = 0.6219237080270709\n",
            "training accuracy = 0.9085129727210571, microF1 = 0.9240925514049231, macroF1 = 0.617027337415262\n",
            "training accuracy = 0.9074242769960014, microF1 = 0.9232019441170798, macroF1 = 0.6224124321057206\n",
            "training accuracy = 0.9068518214241041, microF1 = 0.9228911569023918, macroF1 = 0.6204299841898421\n",
            "training accuracy = 0.9065846081179736, microF1 = 0.9226217801753814, macroF1 = 0.6232650847906929\n",
            "training accuracy = 0.9065313419213887, microF1 = 0.9227032022228405, macroF1 = 0.6241794941057293\n",
            "training accuracy = 0.9064358094828564, microF1 = 0.9227610117110843, macroF1 = 0.6228248736220149\n",
            "training accuracy = 0.9061535833578448, microF1 = 0.9226102712799724, macroF1 = 0.6188013175112227\n",
            "training accuracy = 0.9061850418053384, microF1 = 0.9226850189982492, macroF1 = 0.6201286151629302\n",
            "training accuracy = 0.9058980851318982, microF1 = 0.9223839909470348, macroF1 = 0.6225291452000236\n",
            "training accuracy = 0.9058196448478343, microF1 = 0.9223222095554505, macroF1 = 0.6217573106540499\n",
            "training accuracy = 0.9052841902828328, microF1 = 0.9218649007824739, macroF1 = 0.6194657124320514\n",
            "\n",
            "epoch = 45, training_loss = -20.072416580829422, validation_loss =-18.71032561469324, training_acc = 0.9052462972294357, validation_acc =0.7947450585007856\n",
            "training accuracy = 0.9009642863436427, microF1 = 0.918272990129042, macroF1 = 0.6256448387556098\n",
            "training accuracy = 0.9042347223951699, microF1 = 0.9208483310891077, macroF1 = 0.6232970085146368\n",
            "training accuracy = 0.9057188634342656, microF1 = 0.922240956368112, macroF1 = 0.6211245648716627\n",
            "training accuracy = 0.9068147401187779, microF1 = 0.9231456523934516, macroF1 = 0.6222394421494769\n",
            "training accuracy = 0.9060824046399206, microF1 = 0.922339667170433, macroF1 = 0.621763033216407\n",
            "training accuracy = 0.9063129666998972, microF1 = 0.9225670384406497, macroF1 = 0.6253594865057971\n",
            "training accuracy = 0.9052224376561211, microF1 = 0.9218959424668834, macroF1 = 0.6227571032915763\n",
            "training accuracy = 0.9050687861359207, microF1 = 0.921703758244813, macroF1 = 0.6261620680427632\n",
            "training accuracy = 0.9052722002595401, microF1 = 0.9219068057256231, macroF1 = 0.6238424278421493\n",
            "training accuracy = 0.9051806131141804, microF1 = 0.9219577196841287, macroF1 = 0.6228864875591776\n",
            "training accuracy = 0.9049222240403495, microF1 = 0.9216821252639529, macroF1 = 0.6221970178650081\n",
            "training accuracy = 0.9046243693798561, microF1 = 0.9214108109835283, macroF1 = 0.6203622795079163\n",
            "training accuracy = 0.9049393395462861, microF1 = 0.9217702874352964, macroF1 = 0.6209925101080811\n",
            "training accuracy = 0.9042321776854925, microF1 = 0.9212188221483021, macroF1 = 0.6204181133930634\n",
            "\n",
            "epoch = 46, training_loss = -20.132204350736952, validation_loss =-18.756437340962517, training_acc = 0.904371619658276, validation_acc =0.7945702873142028\n",
            "training accuracy = 0.9043495938271293, microF1 = 0.9230045084271472, macroF1 = 0.6251218925249507\n",
            "training accuracy = 0.9055635838289233, microF1 = 0.9231838205195776, macroF1 = 0.6103716952153191\n",
            "training accuracy = 0.9058592450804617, microF1 = 0.9231826077583406, macroF1 = 0.6188662264348684\n",
            "training accuracy = 0.9064181251637881, microF1 = 0.9237699666574261, macroF1 = 0.6189727443095887\n",
            "training accuracy = 0.9048783768206836, microF1 = 0.9222748843528744, macroF1 = 0.6235020852854839\n",
            "training accuracy = 0.9042508855160714, microF1 = 0.921709589395682, macroF1 = 0.6198743911181802\n",
            "training accuracy = 0.9040946014793642, microF1 = 0.9214357307751982, macroF1 = 0.6202669191899929\n",
            "training accuracy = 0.9046284441164403, microF1 = 0.922049310077659, macroF1 = 0.6192936622404546\n",
            "training accuracy = 0.9048851459467584, microF1 = 0.9222290219055926, macroF1 = 0.6192906800287687\n",
            "training accuracy = 0.9043111585774838, microF1 = 0.9217100377986516, macroF1 = 0.6168293674967175\n",
            "training accuracy = 0.9037726783480461, microF1 = 0.9210636915522793, macroF1 = 0.6145624901290692\n",
            "training accuracy = 0.9042755674408802, microF1 = 0.9214946752781259, macroF1 = 0.613658573707528\n",
            "training accuracy = 0.9042709865152349, microF1 = 0.9215270534564387, macroF1 = 0.6156499778086197\n",
            "training accuracy = 0.903980618562142, microF1 = 0.9212377502770164, macroF1 = 0.6186839139873035\n",
            "\n",
            "epoch = 47, training_loss = -20.19247785876297, validation_loss =-18.82027631936614, training_acc = 0.9037618470455604, validation_acc =0.7941186534722073\n",
            "training accuracy = 0.9067326293137913, microF1 = 0.9218520579568987, macroF1 = 0.6292452528637852\n",
            "training accuracy = 0.9053055287886043, microF1 = 0.9210288618401712, macroF1 = 0.6377681459618225\n",
            "training accuracy = 0.9063304146728931, microF1 = 0.9222915083740658, macroF1 = 0.6322854855382639\n",
            "training accuracy = 0.904467412636455, microF1 = 0.920797741049768, macroF1 = 0.6328418529636121\n",
            "training accuracy = 0.9047519599644482, microF1 = 0.92089907817519, macroF1 = 0.6331401413898801\n",
            "training accuracy = 0.9044042393606028, microF1 = 0.9204993258850425, macroF1 = 0.6279320075929873\n",
            "training accuracy = 0.9034174725536567, microF1 = 0.9196460159534401, macroF1 = 0.6276943721056569\n",
            "training accuracy = 0.9044367704993682, microF1 = 0.9205103031436067, macroF1 = 0.626579869105839\n",
            "training accuracy = 0.9046616631541532, microF1 = 0.9208260787720524, macroF1 = 0.6255706866933665\n",
            "training accuracy = 0.9054067494581954, microF1 = 0.9216390082331686, macroF1 = 0.6237993192270233\n",
            "training accuracy = 0.9054656244968539, microF1 = 0.9216127191639668, macroF1 = 0.6249279405480324\n",
            "training accuracy = 0.9053049192105336, microF1 = 0.9216032261054073, macroF1 = 0.6233055628823823\n",
            "training accuracy = 0.9055796336318429, microF1 = 0.9219014787535642, macroF1 = 0.6227252034090481\n",
            "training accuracy = 0.9058767103262171, microF1 = 0.9222750110186184, macroF1 = 0.6224003277315162\n",
            "\n",
            "epoch = 48, training_loss = -20.253519503931, validation_loss =-18.88720189910574, training_acc = 0.9056987706705124, validation_acc =0.7949362482700926\n",
            "training accuracy = 0.9066567021330362, microF1 = 0.9218064618151744, macroF1 = 0.6103623096763758\n",
            "training accuracy = 0.9038985416208402, microF1 = 0.9203945316228832, macroF1 = 0.6316179470786228\n",
            "training accuracy = 0.9053854085120646, microF1 = 0.9216234290025437, macroF1 = 0.6273341855831407\n",
            "training accuracy = 0.9056322874150334, microF1 = 0.9218955931998124, macroF1 = 0.6229234595882491\n",
            "training accuracy = 0.9056660310449846, microF1 = 0.9220022330085568, macroF1 = 0.6151712318456413\n",
            "training accuracy = 0.9063582085566643, microF1 = 0.9227805710129863, macroF1 = 0.6169300265399963\n",
            "training accuracy = 0.9060528122614345, microF1 = 0.9225962448122605, macroF1 = 0.6138907301229304\n",
            "training accuracy = 0.9058863018630827, microF1 = 0.9224027283553464, macroF1 = 0.6193493267913132\n",
            "training accuracy = 0.905642715049532, microF1 = 0.9220227727505501, macroF1 = 0.6216339350034118\n",
            "training accuracy = 0.9063061780253117, microF1 = 0.9226248826437422, macroF1 = 0.6220028865592764\n",
            "training accuracy = 0.9059631486434405, microF1 = 0.922412432170918, macroF1 = 0.6229274905108182\n",
            "training accuracy = 0.9056179501898132, microF1 = 0.9221632987652276, macroF1 = 0.6230781366911001\n",
            "training accuracy = 0.9060707121981838, microF1 = 0.9225784446337412, macroF1 = 0.6248011256013051\n",
            "training accuracy = 0.906006977625077, microF1 = 0.9224959761939118, macroF1 = 0.6217733236545601\n",
            "\n",
            "epoch = 49, training_loss = -20.319492228662025, validation_loss =-18.92686122225732, training_acc = 0.9057014089019172, validation_acc =0.7952029704985469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM(\n",
              "  (wordembed): Embedding(24138, 100)\n",
              "  (for_charembed): forLSTM(\n",
              "    (charembed): Embedding(71, 71)\n",
              "    (lstm): LSTM(71, 25, batch_first=True, bidirectional=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (bilstm): LSTM(150, 100, batch_first=True, bidirectional=True)\n",
              "  (linear): Linear(in_features=200, out_features=20, bias=True)\n",
              "  (crfmodule): CRFmodule()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oRK0YoQWaqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "outputId": "695def70-8da2-4afc-9d25-92e51b52a86a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PERFORMANCE ON Train DATA\n",
            "MicroF1 = 0.93000374866634 \n",
            "Accuracy = 0.9880861513954801\n",
            "------------Classification Report-------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art      0.912     0.767     0.833       296\n",
            "         eve      0.846     0.827     0.837       226\n",
            "         geo      0.923     0.958     0.940     29240\n",
            "         gpe      0.975     0.961     0.968     12058\n",
            "         nat      0.775     0.827     0.800       133\n",
            "         org      0.887     0.850     0.868     15803\n",
            "         per      0.934     0.920     0.927     13121\n",
            "         tim      0.947     0.951     0.949     15767\n",
            "\n",
            "   micro avg      0.929     0.931     0.930     86644\n",
            "   macro avg      0.900     0.883     0.890     86644\n",
            "weighted avg      0.929     0.931     0.930     86644\n",
            "\n",
            "PERFORMANCE ON Validation DATA\n",
            "MicroF1 = 0.8143543471148381 \n",
            "Accuracy = 0.9615875092870846\n",
            "------------Classification Report-------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art      0.500     0.171     0.255       105\n",
            "         eve      0.423     0.282     0.338        78\n",
            "         geo      0.828     0.870     0.848      9724\n",
            "         gpe      0.939     0.921     0.930      4210\n",
            "         nat      0.524     0.440     0.478        50\n",
            "         org      0.645     0.656     0.650      5187\n",
            "         per      0.803     0.740     0.770      4457\n",
            "         tim      0.884     0.866     0.875      5254\n",
            "\n",
            "   micro avg      0.815     0.814     0.814     29065\n",
            "   macro avg      0.693     0.618     0.643     29065\n",
            "weighted avg      0.815     0.814     0.813     29065\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F6DWpN_VP9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16f74ad-bfcf-4913-af90-c3b2c9a4be5d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PERFORMANCE ON Test DATA\n",
            "MicroF1 = 0.816718054128126\n",
            "Accuracy = 0.9620807270545624\n",
            "------------Classification Report-------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art      0.414     0.118     0.183       102\n",
            "         eve      0.417     0.345     0.377        87\n",
            "         geo      0.838     0.877     0.857      9912\n",
            "         gpe      0.931     0.917     0.924      4168\n",
            "         nat      0.478     0.400     0.436        55\n",
            "         org      0.651     0.656     0.654      5205\n",
            "         per      0.801     0.748     0.774      4406\n",
            "         tim      0.879     0.862     0.870      5275\n",
            "\n",
            "   micro avg      0.817     0.816     0.817     29210\n",
            "   macro avg      0.676     0.615     0.634     29210\n",
            "weighted avg      0.816     0.816     0.816     29210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_79k6ok9O_q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}