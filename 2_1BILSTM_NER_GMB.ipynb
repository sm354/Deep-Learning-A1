{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "2.1BILSTM_NER_GMB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sm354/COL870-Assignment-1/blob/main/2_1BILSTM_NER_GMB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp14M1xlCZRT",
        "outputId": "688600e7-da09-4b08-e791-513f0516dca5"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=ebd87a0e13d17c5e026e1e624b002aee6650791cfae1b1d3cdbd96517e91a4b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.5 GB  |     Proc size: 4.1 GB\n",
            "GPU RAM Free: 585MB | Used: 14524MB | Util  96% | Total     15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Toj8wCvvypN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "if torch.cuda.is_available():  \n",
        "  device = \"cuda:0\" \n",
        "else:  \n",
        "  device = \"cpu\"  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9M1uW9_xHfE",
        "outputId": "3c003580-6630-40ae-b723-300bd182bcbc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCOcV-RtvypX"
      },
      "source": [
        "# reading text file in python and making list of sentences (list of lists) and list of tags(list of lists)\n",
        "def load_data(datapath):\n",
        "    all_words = []\n",
        "    all_tags = []\n",
        "    with open(datapath) as f:\n",
        "        lines = f.readlines()\n",
        "        sent_num = 0\n",
        "        for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "            if(line == \"\\n\"):\n",
        "                sent_num+=1\n",
        "            else:\n",
        "                line_sep = line.split(sep = \" \")\n",
        "                all_words.append(line_sep[0])\n",
        "                all_tags.append(line_sep[3][:-1])\n",
        "                \n",
        "    words = list(set(all_words))\n",
        "    tags = list(set(all_tags))\n",
        "\n",
        "    vocab = {}\n",
        "    vocab['<pad>'] = 0 # for padding input sequences\n",
        "    for i, word in enumerate(words):\n",
        "        vocab[word] = i+1\n",
        "        \n",
        "    nertags = {}\n",
        "    nertags['padtag'] = 0\n",
        "    for i,nertag in enumerate(tags):\n",
        "        nertags[nertag] = i+1\n",
        "\n",
        "    train_sent = []\n",
        "    train_tags = []\n",
        "    with open(datapath) as f:\n",
        "        lines = f.readlines()\n",
        "        sent_num = 0\n",
        "        sentence = []\n",
        "        tag = []\n",
        "        for line in lines[1:]: #1: so that the first blank line isn't taken into account\n",
        "            if(line == \"\\n\"):\n",
        "                sent_num+=1\n",
        "                train_sent.append(sentence)\n",
        "                train_tags.append(tag)\n",
        "                sentence = []\n",
        "                tag = []\n",
        "            else:\n",
        "                line_sep = line.split(sep = \" \")\n",
        "                sentence.append(vocab[line_sep[0]])\n",
        "                tag.append(nertags[line_sep[3][:-1]])\n",
        "\n",
        "    # padding the sentences at the end\n",
        "    seq_maxlen = max(len(x) for x in train_sent)\n",
        "    x_lengths = [len(x) for x in train_sent]\n",
        "    Xtrain = []\n",
        "    Ytrain = []\n",
        "    for sent, tags in zip(train_sent, train_tags):\n",
        "        length_toappend = seq_maxlen - len(sent)\n",
        "        Xtrain.append(sent+[0]*length_toappend)\n",
        "        Ytrain.append(tags+[0]*length_toappend)\n",
        "\n",
        "\n",
        "    Xtrain = torch.Tensor(Xtrain)\n",
        "    Ytrain = torch.Tensor(Ytrain)\n",
        "    x_lengths = torch.Tensor(x_lengths)\n",
        "    # print(Xtrain.shape, Ytrain.shape, x_lengths.shape)\n",
        "    \n",
        "    return Xtrain, Ytrain, x_lengths, vocab, nertags"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZT58V3Avypa"
      },
      "source": [
        "### Training Data\n",
        "### using dataloader to make data batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPFYsfyNvypb"
      },
      "source": [
        "traindatapath = \"/content/drive/MyDrive/Q2_DL/train.txt\"\n",
        "devdatapath = \"/content/drive/MyDrive/Q2_DL/dev.txt\"\n",
        "\n",
        "Xtrain, Ytrain, x_trainlengths, vocab, nertags = load_data(traindatapath)\n",
        "Xdev, Ydev, x_devlengths, _, _ = load_data(devdatapath)\n",
        "\n",
        "traindataset = TensorDataset(Xtrain, Ytrain, x_trainlengths)\n",
        "Trainloader = DataLoader(traindataset, batch_size= 128, shuffle=True)\n",
        "\n",
        "devdataset = TensorDataset(Xdev, Ydev, x_devlengths)\n",
        "Devloader = DataLoader(devdataset, batch_size = 128)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jnQHNBS_XTR"
      },
      "source": [
        "# print(next(iter(Devloader))[0].shape)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMzf8Y1Bvypc"
      },
      "source": [
        "# BiLSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4KBzpL-vypc"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_size, hidden_size, total_words, num_class, pretrained = False, pretrained_embed = None):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.wordembed = nn.Embedding(total_words, embedding_size) #weights initiallized from std normal dist, randomly\n",
        "        if(pretrained == True):\n",
        "            self.wordembed.weight = nn.Parameter(pretrained_embed) #pretrained embeds have size (total_words, embedding_size)\n",
        "\n",
        "        self.bilstm = nn.LSTM(embedding_size,hidden_size, bidirectional = True, batch_first = True)\n",
        "        self.linear = nn.Linear(2*hidden_size, num_class) # 2 because forward and backward concatenate\n",
        "\n",
        "    def forward(self, x, xlengths):\n",
        "        out = self.wordembed(x) # x is of size(batchsize, seq_len), out is of size (batchsize, seq_len, embedding_size = 100)\n",
        "        \n",
        "#         out = pack_padded_sequence(out, xlengths, batch_first=True, enforce_sorted=False)\n",
        "        \n",
        "        out, (h,c) = self.bilstm(out) #'out' has dimension(batchsize, seq_len, hidden_size)\n",
        "        \n",
        "#         out, out_lengths = pad_packed_sequence(out, batch_first=True)\n",
        "#         assert(out.shape[-1] == self.hidden_size)\n",
        "#         print(out.shape)\n",
        "\n",
        "        out = self.linear(out) #now 'out' has dimension(batchsize, seq_len, num_class)\n",
        "\n",
        "        out = F.softmax(out, dim=2) # take the softmax across the dimension num_class, 'out' has dimension(batchsize, seq_len, num_class)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "        "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6byqGo9vypd"
      },
      "source": [
        "model = BiLSTM(embedding_size = 100, hidden_size = 100, total_words = len(vocab), num_class = 18, pretrained = False).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01) \n",
        "lossfunction = nn.CrossEntropyLoss()\n",
        "\n",
        "def calcloss(model, loader):\n",
        "    model.eval()\n",
        "    validloss = 0\n",
        "    i = 0\n",
        "    for step, (X, Y, xlen) in enumerate(loader):\n",
        "        ypred = model(X.long().to(device), xlen.to(device)).permute(0, 2, 1)\n",
        "        vloss = lossfunction(ypred.to('cpu'), Y.type(torch.LongTensor))\n",
        "        validloss+=vloss\n",
        "        i+=1\n",
        "\n",
        "    model.train()\n",
        "    return validloss/i"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMnSjcL1vypd"
      },
      "source": [
        "# print(model)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "QgudoA7Mvypd",
        "outputId": "e70338f7-72e6-446e-bf0e-764c9efea845"
      },
      "source": [
        "# Model is ready now we have to train using cross entropy loss\n",
        "num_epochs = 100\n",
        "trainloss = []\n",
        "validloss = []\n",
        "# validloss = []\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for step, (Xbatch, Ybatch, xbatch_len) in enumerate(Trainloader):\n",
        "        #make gradients 0\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #get output from model and claculate loss\n",
        "        ypred = model(Xbatch.long().to(device), xbatch_len.to(device)).permute(0, 2, 1)\n",
        "        # print(ypred.shape, Ybatch.shape)\n",
        "        \n",
        "        loss = lossfunction(ypred.to('cpu'), Ybatch.type(torch.LongTensor)) #Ybatch has dimension (batchsize, seqlen), ypred has dimension(batchsize, num_classes, seqlen)\n",
        "        \n",
        "        #backward and step\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 5) # clip gradient to 5\n",
        "        optimizer.step()\n",
        "    \n",
        "    vloss = calcloss(model, Devloader)\n",
        "    trainloss.append(loss)\n",
        "    validloss.append(vloss)\n",
        "    print('epoch = {}, training_loss = {}, validation_loss = {}'.format(epoch, trainloss[-1], validloss[-1]))        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch = 0, training_loss = 2.206904411315918, validation_loss = 2.2933318614959717\n",
            "epoch = 1, training_loss = 2.182199478149414, validation_loss = 2.2774016857147217\n",
            "epoch = 2, training_loss = 2.167578935623169, validation_loss = 2.2742362022399902\n",
            "epoch = 3, training_loss = 2.1907167434692383, validation_loss = 2.272693395614624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b29fa41ba771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#get output from model and claculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxbatch_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# print(ypred.shape, Ybatch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-6d494769339d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xlengths)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         out = pack_padded_sequence(out, xlengths, batch_first=True, enforce_sorted=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#'out' has dimension(batchsize, seq_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         out, out_lengths = pad_packed_sequence(out, batch_first=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "XTjqszDbvype",
        "outputId": "b117c819-bce8-45c0-b046-dc64d0d66976"
      },
      "source": [
        "print(trainloss)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-79bc4946ebac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainloss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "KJ0IjhNavype",
        "outputId": "bd0a0a4d-56d7-4c29-eb15-5c36a685cd0e"
      },
      "source": [
        "plt.plot(trainloss)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-06151338d936>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainloss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kuOxKLJ2jvT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}